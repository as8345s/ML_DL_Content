{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecc95133-e0f8-4044-9844-4b20a11a7961",
   "metadata": {},
   "source": [
    "<h1>Transfer Learning</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cce4e68-af03-4f1e-85ed-711c9457fb9d",
   "metadata": {},
   "source": [
    "In diesem Abschnitt wird erklärt, was Transfer-Learning ist und was es damit Aufsicht hat.\n",
    "\n",
    "Es ist einfach in wenigen Worten erklärt. <br>\n",
    "Wir nehmen ein Model, das für ein Problem trainiert wurde und nutzen es um ein ähnliches Problem zu lösen.\n",
    "\n",
    "Ein Model, das z. B. mit Millionen von Daten trainiert wurde, um verschiedene Objekte, Klasse, usw., zu erkennen, erzielt gute Performance auf solchen Daten. Das Model kann z. B. Tiere und Früchte erkenne, dabei hat es aber nie eine Birne gesehen.\n",
    "\n",
    "Wir nehmen das Model und trainieren nur die letzte (oder paar letzten) Layers, um es an unser Problem anzupassen. <br>\n",
    "=> Das Ereknnen einer Birne.\n",
    "\n",
    "Eine Birne hat ähnliche Merkmale wie ein Apfel, was z. B. von dem Pre-Trained Model genutzt wurde. Mit ein paar Trainingsschritten kann es dann auch einen Apfel erkenne.\n",
    "\n",
    "Ein anderes Beispiel wäre, das Model wurde mit vielen Daten darauf trainiert, PKWs zu erkennen. Dasselbe Model kann dazu benutzt werden, LKWs zu erkennen, mit ein paar Änderungen des letzten Layers.\n",
    "- Beim Trainieren sind die Weights der anderen Layers statisch und werden sich nicht ändern.\n",
    "- Der Vorteil ist, dass bei dieser Art des Trainings weniger Rechenleistung und Zeit nötig ist, um die richtigen Weights des Models zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dd891b-204b-4eb8-b04a-4435a2511ac0",
   "metadata": {},
   "source": [
    "Hier wird ein Model aus dem Tensorflow Hub geladen und darauf trainiert Blumen zu erkennen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7e489d-7eeb-4dfc-9b07-261b0ec224ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f6b73d-0c25-4b53-8f79-a28abc77a16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Conten Coming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41bf6f64-747a-4026-8dfa-a4bf8902bc26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "89988d4d-bc2d-4826-932e-eead0c23ec9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import PIL\n",
    "import cv2   \n",
    "import pathlib\n",
    "import tensorflow_hub as hub\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2a7630-b299-4be7-a683-64fb40ca335d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hole Dataset\n",
    "# - Siehe Tensorflow: https://www.tensorflow.org/datasets/catalog/tf_flowers\n",
    "url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=url, cache_dir='./data/datasets/tf_flowers', untar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d6fcb16-42c1-4351-b13d-90a99f9bce7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/hub\n",
    "# - Model: https://www.kaggle.com/models/google/mobilenet-v2   \"mobilenet_v2\"\n",
    "# - Füge noch dritte Dimension ein, wegen dem Dataset.  \n",
    "\n",
    "# mobilenet_v2/classification/4 => Normales Model\n",
    "# Wir Brauchen ein Model ohne das letzte Layer.\n",
    "#    mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\"\n",
    "mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"  # feature_vector => Model ohne letzte Layer.\n",
    "\n",
    "# Lade das Model so:\n",
    "# - trainable: Weights sind statisch. \n",
    "mobile = hub.KerasLayer(mobilenet_v2, input_shape=(224,224)+(3,), trainable=False)\n",
    "\n",
    "#   mobile = tf.keras.applications.MobileNetV2(input_shape=(224,224)+(3,), )\n",
    "# - Im Hub sind noch andere gute Modelle. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7d9985c4-67ca-4092-98a0-f5500ca7e4bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Zeige Zusammenfassung des Models. \n",
    "#mobile.summary() # Nur bei Modellen wie  mobilenet_v2 =\"https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b1f4137-4a18-42d8-b5da-e017b3d65507",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Das Beispiel mit den Blumen ist aus dem Notebook Data-Argumentation.\n",
    "\n",
    "url      = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"  # Dataset.\n",
    "data_dir = pathlib.Path(data_dir)                                   # Dataset Pfad. \n",
    "flowers  = ['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']  # Klassen\n",
    "\n",
    "# Erstelle Pfade.\n",
    "list_flowers = {}\n",
    "for i in flowers:\n",
    "    list_flowers[i] = list(data_dir.glob(f\"{i}/*.jpg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4a9f5e6-a2ef-43e6-b1b8-fbb22bebf08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_flowers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fef2ae81-de55-4a58-adcd-343d8fdd389a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('data/datasets/tf_flowers/datasets/flower_photos/daisy/100080576_f52e8ee070_n.jpg')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_flowers['daisy'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c796a6fa-aa0e-41fe-be67-f822f451be94",
   "metadata": {},
   "source": [
    "Wenn alle Pfade gesetzt sind, können wir das Dataset mit X, y erstellen. <br>\n",
    "Dabei muss die Größer der Bilder geändert werden, dann die Bilder normalisieren, und zum Schluss die Labels codieren. \n",
    "- Achte dabei das die Bilder die richtige Größe haben. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b90af345-088e-4e00-9928-041450c2aee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Dataset.:\n",
    "X_data = [] # Blumen.\n",
    "y_data = [] # Labels. \n",
    "\n",
    "# Lese Bilder und ändere Größe.\n",
    "for key, items in list_flowers.items():\n",
    "\n",
    "    for item in items:\n",
    "        img = cv2.resize( cv2.imread(item), (224, 224))\n",
    "        X_data.append(img)\n",
    "        y_data.append(key)\n",
    "\n",
    "name_dict = {'daisy':0, 'dandelion':1, 'roses':2, 'sunflowers':3, 'tulips':4 }\n",
    "y_data_new = [name_dict[item]  for item in y_data]  # Liste mit Labels. \n",
    "\n",
    "# Als Numpy.\n",
    "X_data = np.array(X_data)\n",
    "del y_data\n",
    "y_data = np.array(y_data_new)\n",
    "del y_data_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5bcc9e98-a557-482c-9f01-6bdf92c2dc08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "062ca47c-a96d-476b-91a8-0878bc1c28d2",
   "metadata": {},
   "source": [
    "Teile wie üblich Dataset in Train- und Testset auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f089eade-4611-42b4-9179-7b2d4bb46716",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_data, y_data, test_size=.2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acddb193-cebe-461f-ab38-db452e804e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalisiere\n",
    "X_train_sc = X_train / 255\n",
    "X_test_sc  = X_test / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d7c344-757d-41b4-92cb-399edf3b1bcf",
   "metadata": {},
   "source": [
    "Jetzt haben wir die Layers des Models und können es für das Training nutzt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ec4c0e2d-b779-4066-b1ac-1bc7d041c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Model\n",
    "\n",
    "# Wrapper- damit die Klasse übereinstimmt.\n",
    "# - tensorflow_hub.keras_layer.KerasLayer\n",
    "\n",
    "class CustomHubLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, hub_url, input_shape, trainable=False):\n",
    "        super(CustomHubLayer, self).__init__()\n",
    "        self.hub_layer = hub.KerasLayer(hub_url, input_shape=input_shape, trainable=trainable)\n",
    "    \n",
    "    def call(self, inputs):\n",
    "        return self.hub_layer(inputs)\n",
    "\n",
    "model_url = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/4\"\n",
    "mobile    = CustomHubLayer(model_url, (244,244,3), trainable=False)\n",
    "\n",
    "my_model = tf.keras.Sequential([\n",
    "    mobile, # Enthählt bereits alle Layer die wir brauchen.\n",
    "    # Füge Layers, etc., hinzu.\n",
    "    tf.keras.layers.Dense(5)  # 5 Klassen\n",
    "])\n",
    "\n",
    "my_model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics   = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f6146ee4-6705-4c77-ba7d-c2b048d477c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "WARNING:tensorflow:From C:\\Users\\Alexander\\anaconda3\\envs\\my_tensorflow_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Alexander\\anaconda3\\envs\\my_tensorflow_env\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:184: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 191ms/step - accuracy: 0.5882 - loss: 1.0451\n",
      "Epoch 2/3\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 196ms/step - accuracy: 0.8638 - loss: 0.4075\n",
      "Epoch 3/3\n",
      "\u001b[1m92/92\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 202ms/step - accuracy: 0.8957 - loss: 0.3282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e2cef34490>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainiere Model. \n",
    "my_model.fit(X_train_sc, y_train, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d162073c-e9cb-496d-b0bb-ac331c5422a1",
   "metadata": {},
   "source": [
    "Nach nur 3 Epochen erzielt das Model beim Trainieren eine bessere Genauigkeit als ein Model, deren Weights nicht angepasst wurden. Mit dieser Methode kann Zeit und Rechenleistung gespart werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7989a94a-6ad4-4a90-8c22-c6ba829f80fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m23/23\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 198ms/step - accuracy: 0.8561 - loss: 0.3660\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.359163761138916, 0.8610354065895081]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.evaluate(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3aa2f7-873f-4a91-a873-f00f7c9a3ac0",
   "metadata": {},
   "source": [
    "Achte darauf, dass die Klassen beim Erstellen eines sequenziellen Models übereinstimmen. <br>\n",
    "Sonst müssen vorher noch einige Schritte durchlaufen werden."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
