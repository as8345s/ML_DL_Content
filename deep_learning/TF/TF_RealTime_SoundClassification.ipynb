{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dfbd45e8-a762-4d64-8feb-a84291d82949",
   "metadata": {},
   "source": [
    "<h1>Real Time Audio Klassifizierung</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddd91e95-4133-4424-9ea2-7798ab2e9c49",
   "metadata": {},
   "source": [
    "Hier wollen wir ein Model erstellen, dass Sound klassifizieren soll. Dan soll das Model in Echtzeit Klassifizierungen durchführen.\n",
    "\n",
    "Als Startpunkt orientieren wir uns an dem Notebook TF_Audio.\n",
    "\n",
    "Als zusätzliche Aufgabe sollen die betroffenen stellen der Sounds markiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad31194-8810-4d7d-bedf-779def5c12ea",
   "metadata": {},
   "source": [
    "Um den Anfang zu machen, wollen wir als Ziel ein Model trainieren, dass Wörter erkennen soll.:\n",
    "- Ein ASR Model (Automatic-speech-recognition)\n",
    "\n",
    "Als Dataset nutzen wir:\n",
    "> Speech Commands dataset (Warden, 2018) <br>\n",
    "> https://www.tensorflow.org/datasets/catalog/speech_commands [Letzter Zugriff: 5.09.2024]\n",
    "\n",
    "Dieses Dataset enthält folgende Wörter im Audioformat: \"down\", \"go\", \"left\", \"no\", \"right\", \"stop\", \"up\" und \"yes\" <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ea44b9ba-7045-4fd3-9b03-854cd9a8a8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "import IPython\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c139afb-777b-4673-ba98-b00e5e747426",
   "metadata": {},
   "source": [
    "Lade Dataset herunter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ed01ce-d3bf-4b07-a0e6-a00728990163",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = 'data/mini_speech_commands'\n",
    "\n",
    "data_dir = pathlib.Path(DATASET_PATH)\n",
    "if not data_dir.exists():\n",
    "  tf.keras.utils.get_file(\n",
    "      'mini_speech_commands.zip',\n",
    "      origin=\"http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip\",\n",
    "      extract=True,\n",
    "      cache_dir='.', cache_subdir='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c453618a-51e0-43df-ae2c-7c23a99b4d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kommandos: ['down' 'go' 'left' 'no' 'right' 'stop' 'up' 'yes']\n"
     ]
    }
   ],
   "source": [
    "# Dataset enthält Ordner mit Audiodateien.\n",
    "commands = np.array(tf.io.gfile.listdir(str(data_dir)))\n",
    "\n",
    "commands = commands[(commands != 'README.md') & (commands != '.DS_Store')]\n",
    "print(f'Kommandos: {commands}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e31b51c3-f6e9-49f1-b7aa-520e97606168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8000 files belonging to 8 classes.\n",
      "Using 6400 files for training.\n",
      "Using 1600 files for validation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<_BatchDataset element_spec=(TensorSpec(shape=(None, 16000, None), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Erstelle Dataset # \n",
    "train_ds, val_ds = tf.keras.utils.audio_dataset_from_directory(\n",
    "    directory=data_dir,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    seed=0,\n",
    "    output_sequence_length=16000,\n",
    "    subset='both')\n",
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "879f0641-b0a3-495e-8017-341459d3c6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['down', 'go', 'left', 'no', 'right', 'stop', 'up', 'yes']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_names = train_ds.class_names\n",
    "train_ds.class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbeb26d-e447-4c6f-b54b-6a3b19c9957e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b8d67a-29c8-4945-bf06-8c90a85c7dab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62bacc1-ee22-4165-a575-2c02814df0f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29438930-c97e-40a1-90bf-01e447bf07bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
