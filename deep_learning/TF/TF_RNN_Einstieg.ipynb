{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "912326dd-33c2-4ebc-8d75-201e08afab70",
   "metadata": {},
   "source": [
    "<h1>RNN - Einstieg</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83394ed-ba97-4c24-badc-a37c7197fd52",
   "metadata": {},
   "source": [
    "RNN steht für Recurrent Neural Network und beinhaltet verschiedene Varianten.\n",
    "\n",
    "Der Hauptunterschied zu normale Netze und CNNs ist das RNNs eine Art Gedächtnis aufweisen. <br>\n",
    "Das Vanilla-RNN leidet deutlich unter dem Vanishing-Gradient Problem, mehr dazu später.\n",
    "\n",
    "RNNs sind sehr gut dafür geeignet mit Daten zu arbeiten die eine bestimmte Sequenz aufweisen, wie das Vorhersagen des nächsten Wortes eines Satzes basierend auf den schon geschriebenen Wörter => Autovervollständigung.\n",
    "\n",
    "Das Gedächtnis entsteht dadurch, das der Output zum Input geführt wird- um es einfach auszudrücken.\n",
    "\n",
    "Use-Cases sind z B.:\n",
    "- NLP\n",
    "- Übersetzungen\n",
    "- Autovervollständigung\n",
    "- NER (Named Entity Recognition)\n",
    "- Semantische Analysen von Texten"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80904453-354a-4003-b8df-a863dd6b7223",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: RNN Use-Case Beispiele.\n",
    "\n",
    "<img src=\"./data/img/1_rnn.PNG\" height=800 width=600>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae945969-51f1-4eff-b7ff-129173c7f445",
   "metadata": {},
   "source": [
    "Wieso nutzt man keine normalen Netze für diese Probleme? <br>\n",
    "Alle diese genannten Probleme sind <u>Sequential-Modelling-Problems,</u> weil die <u>Sequenz</u> wichtig ist.\n",
    "\n",
    "Eine Sequenz ist z. B.: \"How are you\", was sich von \"Are you how\" unterscheidet. Für uns Menschen ist das deutlich sichtbar.\n",
    "\n",
    "Weitere Issues mit normale Netzen:\n",
    "- Wie viele Output-Neuronen?\n",
    "- Zu viele Berechnungen, da bei Texten ein Vokabular benutzt wird (Siehe Text in numerischer Darstellung).<br>\n",
    "  Für 30.000 Wörter ist ein Vektor der Größe 30.000 notwendig + Output Größe. <br>\n",
    "  Vokabular:  how: [0, 0, 1, ...], are: [0, 1, 0, ...], ... (On-Hot Encoding)\n",
    "- Keine geteilten Parameter: mehrere Deutungen von Texten.\n",
    "\n",
    "Bei Texten ist die Inputreihenfolge von Wörtern auch entscheidend, nicht wie bei normalen Features wie Eigenschaften, um etwas zu klassifizieren."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88ea755-69e5-45e1-84e9-0255a7192081",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: Vanilla-RNN Veranschaulichung. Kontext / Memory.\n",
    "\n",
    "<img src=\"./data/img/2_rnn.PNG\" height=800 width=600>\n",
    "\n",
    "\n",
    "<i>Abb3</i>: NER Beispiel.\n",
    "\n",
    "<img src=\"./data/img/3_rnn.PNG\" height=750 width=550>\n",
    "\n",
    "\n",
    "<i>Abb4</i>: ENR Training. \n",
    "\n",
    "<img src=\"./data/img/5_rnn.PNG\" height=700 width=400>\n",
    "\n",
    "\n",
    "<i>Abb5</i>: Generische Darstellung von RNN. \n",
    "\n",
    "<img src=\"./data/img/4_rnn.PNG\" height=160 width=80>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9903ccf-6d0f-4ab8-b8e8-c286a76c18ed",
   "metadata": {},
   "source": [
    "Wie in der Abbildung 2 zusehen ist, wird der Output des Layers wieder zum Input geleitet. Bei Texten kann dann so ein gewisser Kontext mitgenommen werden => die vorherigen Wörter haben einen Einfluss.\n",
    "- Der Zustand wird mitgenommen.\n",
    "\n",
    "Das Training eines RNNs für NER würde so aussehen.:\n",
    "- Nehme Text markiere Namen <br>\n",
    "  \"Bob told me David is home\" => [1, 0, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d236317-3706-4961-9446-22bda67a6172",
   "metadata": {},
   "source": [
    "Wir haben gesehen wie ein einfaches ERN trainiert wird, wie funktioniert das aber bei einer Übersetzung?\n",
    "- Hier müssen alle Wörter vorhanden sein, damit eine Vorhersage gemacht werden kann. Da jedes Wort die Bedeutung und Übersetzung verändert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e358a78-f8e3-498e-aedc-f59f18cbb6b2",
   "metadata": {},
   "source": [
    "<i>Abb5</i>: Übersetzung: Encoder und Decoder.\n",
    "\n",
    "<img src=\"./data/img/6_rnn.PNG\" height=700 width=500>\n",
    "\n",
    "- In diesem Beispiel Single-Layer.\n",
    "\n",
    "\n",
    "<i>Abb7</i>: Deep RNN.\n",
    "\n",
    "<img src=\"./data/img/7_rnn.PNG\" height=600 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b85090-d477-4971-b913-babb79a41290",
   "metadata": {},
   "source": [
    "<h2>Arten von RNN (3)</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb1acd58-8ee0-43db-aed9-ea5c98c902e4",
   "metadata": {},
   "source": [
    "RNN Typen.:\n",
    "- Many-to-Many\n",
    "- Many-to-One\n",
    "- One-to-Many"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a0a7b9-ea47-4ab6-9419-6bc934854159",
   "metadata": {},
   "source": [
    "Many-to-Many:<br>\n",
    "Viele Inputs und viele Outputs => x(n) und ý(n). Ein Beispiel dafür wäre ENR oder Übersetzungen.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf56b08b-5ee4-4150-9744-96a625dfc5c7",
   "metadata": {},
   "source": [
    "<i>Abb8</i>: ENR, Many-to-Many.\n",
    "\n",
    "<img src=\"./data/img/8_rnn.PNG\" height=600 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80bf8fa2-ba55-40e0-8356-b2e81420d1c2",
   "metadata": {},
   "source": [
    "Many-to-One:<br>\n",
    "Viele Inputs liefern am Ende ein Output. <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d4aa26-f2c6-42a2-879c-e6ca03ecc493",
   "metadata": {},
   "source": [
    "<i>Abb9</i>: Many-to-One.\n",
    "\n",
    "<img src=\"./data/img/9_rnn.PNG\" height=600 width=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffb1479-e7e6-452f-bc10-aeeaffc90001",
   "metadata": {},
   "source": [
    "One-to-Many: <br>\n",
    "Für eine Eingabe gibt es viele Outputs. Ein Beispiel dafür wäre Musikgeneration- mit einem gegebenen Seed oder Sample soll eine Melodie generiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c329ab1-b8a2-4247-a590-2017b4ea06c1",
   "metadata": {},
   "source": [
    "<i>Abb10</i>: One-to-Many.\n",
    "\n",
    "<img src=\"./data/img/10_rnn.PNG\" height=600 width=400>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8893db-d51f-4711-a856-e3376fe9df87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84e76d1-8b48-4ab1-b59f-71bc0743b750",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f382063-2fce-4a17-8463-798105f1fcdb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ba3924-e9d0-43fb-acce-6b399bf11b6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daa8cc8-8922-45fa-8559-c13f9ede4912",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
