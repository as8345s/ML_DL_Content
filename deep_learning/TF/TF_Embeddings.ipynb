{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1864e6fd-5c3f-471c-9323-ac9af5dc3a5e",
   "metadata": {},
   "source": [
    "<h1>Einfaches Word Embedding</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ec3632b-08fb-4072-9431-eb39d0df1989",
   "metadata": {},
   "source": [
    "Word Embeddings sind eine Form der Repräsentation von Wörtern in Zahlen, mit dem ein Model trainiert werden kann, um NLP Aufgaben zu lösen.\n",
    "\n",
    "Mit Embeddings können Relationen gut abgebildet werden. <br>\n",
    "Eine Methode Embeddings zu erstellen ist, durch Trainieren eines Models, das uns am Ende Embeddings liefert.\n",
    "- Erstelle Fake-Problem, um eventuell Embeddings zu bekommen, die die Wörter gut repräsentiert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec1673-b11d-405f-81e2-6e1c9714c88f",
   "metadata": {},
   "source": [
    "Als Einstieg in die Thematik sollen mittels einfachen Reviews Embeddings erstellt werden.  <br>\n",
    "Das Prinzip ist einfach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39b8297-1092-43b0-9720-58b034804221",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9912f4f7-a106-4085-92bc-713c65ce6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Content coming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd56ec7-0650-4284-b649-296b78ce9a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8efa8ca9-ba0f-418f-afff-c720734d5828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "## Achte auf Versionen, wenn import error ## \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67badb92-1fea-40a5-bf49-3bd3da34a847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mögliche Reviews:\n",
    "reviews = ['nice food',\n",
    "        'amazing restaurant',\n",
    "        'too good',\n",
    "        'just loved it!',\n",
    "        'will go again',\n",
    "        'horrible food',\n",
    "        'never go there',\n",
    "        'poor service',\n",
    "        'poor quality',\n",
    "        'needs improvement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8b50741-07ae-45de-b87e-a49a31443f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positiver oder negativer Review. \n",
    "y_truth = np.array([1,1,1,1,1,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab9142b-3444-423c-9a88-c7fe30c7cc6d",
   "metadata": {},
   "source": [
    "Als Erstes muss das Vokabular erstellt werden. Jedes Wort bekommt eine Zahl, Relationen können damit nicht abgebildet werden.\n",
    "\n",
    "Keras liefert eine Methode, mit dem das einfach umsetzbar ist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "86eef94d-7f97-4e51-8980-fa95231fdeb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 1, 1]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input Text | n\n",
    "# - Hat auch Filterfunktion. \n",
    "one_hot(\"eins zwei drei\", 10)  # Vokabular Größe n, hier 10."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ea501f-6fb1-4614-97d7-39e55992f479",
   "metadata": {},
   "source": [
    "Damit bekommt jedes Wort eine Zahl.\n",
    "\n",
    "Damit erstellen wir eine On-Hot-Encode Matrix. <br>\n",
    "Diese Vektoren werden später für die Multiplikation benötigt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0695bc94-d3b0-419d-ab28-f24df9aa5d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[5, 9],\n",
       " [1, 1],\n",
       " [1, 7],\n",
       " [1, 8, 7],\n",
       " [4, 4, 9],\n",
       " [4, 9],\n",
       " [1, 4, 4],\n",
       " [1, 1],\n",
       " [1, 7],\n",
       " [2, 6]]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Einfach als Liste.\n",
    "ohe_review = [one_hot(wort, 10)  for wort in reviews ]\n",
    "ohe_review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae0236-337d-4800-bb31-b5096cd4a017",
   "metadata": {},
   "source": [
    "Das neurale Netz hat eine feste Größe, um eine verschiedene Anzahl von Wörtern (in einem Satz) zu verarbeiten, wird Padding angewendet, um den Rest mit Nullen zu füllen.\n",
    "\n",
    "Dabei kann Keras uns auch wieder helfen, es schnell und sauber umzusetzen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "29150d8e-6e7f-40a9-a2b7-d49b94b9f870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5, 9, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 7, 0, 0, 0],\n",
       "       [1, 8, 7, 0, 0],\n",
       "       [4, 4, 9, 0, 0],\n",
       "       [4, 9, 0, 0, 0],\n",
       "       [1, 4, 4, 0, 0],\n",
       "       [1, 1, 0, 0, 0],\n",
       "       [1, 7, 0, 0, 0],\n",
       "       [2, 6, 0, 0, 0]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Keras übernimmt Padding.\n",
    "# - Als Input: Review, Max. Länge des Satzes, Padding Typ. \n",
    "ohe_review_pad = tf.keras.preprocessing.sequence.pad_sequences(\\\n",
    "               ohe_review, maxlen=5, padding='post')\n",
    "ohe_review_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0ae8b9e-847b-4748-8236-5a2217a7e301",
   "metadata": {},
   "source": [
    "Der Rest wurde mit Nullen aufgefüllt. \n",
    "\n",
    "Für die Embeddings muss jetzt eine Vektorgröße festgelegt werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a433bdc7-05d8-44a3-b678-414ac7213ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vektorgröße:\n",
    "vec_size = 6\n",
    "\n",
    "# Model:\n",
    "# - Siehe: https://www.tensorflow.org/api_docs/python/tf/keras/layers/Embedding\n",
    "model = tf.keras.Sequential([\n",
    "    # Vokabulargröße | Vektorgröße  | Name\n",
    "    tf.keras.layers.Embedding(10, vec_size, name=\"emb_1\"),   # Embedding Layer\n",
    "    tf.keras.layers.Flatten(),  # Flattern der Vektoren (10 x 6).\n",
    "    tf.keras.layers.Dense(units=1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss      = 'binary_crossentropy',\n",
    "    metrics   = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b368805e-0905-4515-bc19-5407a1ba8c06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 586ms/step - accuracy: 0.5000 - loss: 0.6879\n",
      "Epoch 2/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.6874\n",
      "Epoch 3/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.6869\n",
      "Epoch 4/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.5000 - loss: 0.6863\n",
      "Epoch 5/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.5000 - loss: 0.6858\n",
      "Epoch 6/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5000 - loss: 0.6852\n",
      "Epoch 7/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.5000 - loss: 0.6847\n",
      "Epoch 8/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5000 - loss: 0.6842\n",
      "Epoch 9/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.5000 - loss: 0.6836\n",
      "Epoch 10/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6000 - loss: 0.6831\n",
      "Epoch 11/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6000 - loss: 0.6825\n",
      "Epoch 12/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.6000 - loss: 0.6820\n",
      "Epoch 13/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.6000 - loss: 0.6814\n",
      "Epoch 14/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7000 - loss: 0.6809\n",
      "Epoch 15/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.7000 - loss: 0.6803\n",
      "Epoch 16/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6798\n",
      "Epoch 17/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8000 - loss: 0.6792\n",
      "Epoch 18/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6787\n",
      "Epoch 19/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6781\n",
      "Epoch 20/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6776\n",
      "Epoch 21/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8000 - loss: 0.6770\n",
      "Epoch 22/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6765\n",
      "Epoch 23/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6759\n",
      "Epoch 24/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6754\n",
      "Epoch 25/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8000 - loss: 0.6748\n",
      "Epoch 26/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6742\n",
      "Epoch 27/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8000 - loss: 0.6737\n",
      "Epoch 28/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6731\n",
      "Epoch 29/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8000 - loss: 0.6725\n",
      "Epoch 30/30\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8000 - loss: 0.6719\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x23ae0429670>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(ohe_review_pad, y_truth, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79be50e6-9990-4402-ac4c-197f138fc1f1",
   "metadata": {},
   "source": [
    "Die Embeddings, die wir brauchen, befinden sich in dem Model selber. <br>\n",
    "Die Paramter des Models liefern und die Embeddings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ca35521f-f6b9-4dec-b749-1a99c58262de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 6)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape:\n",
    "# - 10 x 6, da Vokabular 10, und Vektoren 6\n",
    "model.get_layer('emb_1').get_weights()[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b6af000-f661-4ed6-8630-e7af8105f5e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.02474366, -0.01315731,  0.05202236,  0.05083236,  0.01970943,\n",
       "         0.0130841 ],\n",
       "       [-0.01235311, -0.02102912,  0.0289436 , -0.0417017 ,  0.00227888,\n",
       "        -0.03530249],\n",
       "       [-0.04241379,  0.06800491, -0.07429703, -0.02135566, -0.06956505,\n",
       "        -0.0467282 ],\n",
       "       [-0.00316672,  0.02847575, -0.03855437,  0.03098381,  0.04959041,\n",
       "         0.01081797],\n",
       "       [-0.02940091,  0.04991698,  0.0132518 ,  0.05584835,  0.01868395,\n",
       "         0.00743334],\n",
       "       [ 0.06993849, -0.02619599,  0.00109671, -0.00600368,  0.06285763,\n",
       "         0.07592013],\n",
       "       [-0.02836825, -0.06181736,  0.00733179,  0.02542896,  0.06179117,\n",
       "         0.0617546 ],\n",
       "       [-0.00230336, -0.01995786, -0.07054552, -0.0401079 , -0.0379667 ,\n",
       "        -0.00589087],\n",
       "       [ 0.0043019 ,  0.05722755, -0.0754992 ,  0.01301988, -0.01062768,\n",
       "        -0.01128125],\n",
       "       [-0.01832882, -0.01759908,  0.00890784, -0.02409432, -0.06345172,\n",
       "        -0.02548134]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('emb_1').get_weights()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c110dd6-40cc-4101-a4de-fb0a807ffd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "emb = model.get_layer('emb_1').get_weights()[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34516e3b-9de5-44a1-8ac1-d68b8d9ecfc8",
   "metadata": {},
   "source": [
    "Jetzt können wir uns die Embeddings für bestimmte Wörter anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87b97bc6-c27e-4b36-9416-252bc52656be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02836825, -0.06181736,  0.00733179,  0.02542896,  0.06179117,\n",
       "        0.0617546 ], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nice:6, amazing: 4\n",
    "emb[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8780c451-6fc9-40df-82bf-b72dc5036d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02940091,  0.04991698,  0.0132518 ,  0.05584835,  0.01868395,\n",
       "        0.00743334], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f69899c2-4c4f-47cd-8282-2fe8beaac135",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.06993849, -0.02619599,  0.00109671, -0.00600368,  0.06285763,\n",
       "        0.07592013], dtype=float32)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poor: 5\n",
    "emb[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52906759-d315-409f-997e-b0c2a398afb4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66e243d6-5537-4ece-9ba3-7f1fa70eeaa8",
   "metadata": {},
   "source": [
    "<h2>Word2Vec - Gensim</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9960280-42f1-4f33-8706-7de17beff940",
   "metadata": {},
   "source": [
    "Word2Vec ist ein anderer Ansatz, um Wörter numerisch darzustellen.\n",
    "\n",
    "Es  teilt sich in zwei Methoden auf:<br>\n",
    "- CBOW: Continues Bag of Words.\n",
    "- Skip Gram\n",
    "\n",
    "Bei CBOW wird ein Text genommen und mit einem Fenster der Größe n-Worte über den Text gefahren. Dabei ist das Fake-Problem, die Wörter für die Lücken im Text vorherzusagen.\n",
    "\n",
    "Skip-Gram macht genau das Gegenteil, es ist ein Wort gegeben, und das Model muss Wörter passend zum Kontext vorhersagen. \n",
    "\n",
    "Kontext: die Wörter die sich in der Umgebung der Lücke befinden.\n",
    "\n",
    "Word2Vec ist eine Self-Supervised-Learning Methode, da es zu Beginn keine X und y Werte gibt, nur einen Text.  \n",
    "- Aus dem Text: X und y Daten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc833131-5227-4210-8a2b-1ce3277d8d79",
   "metadata": {},
   "source": [
    "Für die Anwendung nutzen wir ein Dataset wo es um Produktbeschreibungen geht.\n",
    "\n",
    "Dataset: reviews_Cell_Phones_and_Accessories_5\n",
    ">https://www.kaggle.com/datasets/zainabhaddad/reviews-cell-phones-and-accessories-5 [Letzter Zurgiff: 18.06.2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa3e34e5-5579-466e-b119-f73cfbf64236",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A30TL5EWN6DFXT</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>christina</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>They look good and stick good! I just don't li...</td>\n",
       "      <td>4</td>\n",
       "      <td>Looks Good</td>\n",
       "      <td>1400630400</td>\n",
       "      <td>05 21, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASY55RVNIL0UD</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>emily l.</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These stickers work like the review says they ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Really great product.</td>\n",
       "      <td>1389657600</td>\n",
       "      <td>01 14, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A2TMXE2AFO7ONB</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>Erica</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>These are awesome and make my phone look so st...</td>\n",
       "      <td>5</td>\n",
       "      <td>LOVE LOVE LOVE</td>\n",
       "      <td>1403740800</td>\n",
       "      <td>06 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AWJ0WZQYMYFQ4</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>JM</td>\n",
       "      <td>[4, 4]</td>\n",
       "      <td>Item arrived in great time and was in perfect ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute!</td>\n",
       "      <td>1382313600</td>\n",
       "      <td>10 21, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ATX7CZYFXI1KW</td>\n",
       "      <td>120401325X</td>\n",
       "      <td>patrice m rogoza</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>awesome! stays on, and looks great. can be use...</td>\n",
       "      <td>5</td>\n",
       "      <td>leopard home button sticker for iphone 4s</td>\n",
       "      <td>1359849600</td>\n",
       "      <td>02 3, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin      reviewerName helpful  \\\n",
       "0  A30TL5EWN6DFXT  120401325X         christina  [0, 0]   \n",
       "1   ASY55RVNIL0UD  120401325X          emily l.  [0, 0]   \n",
       "2  A2TMXE2AFO7ONB  120401325X             Erica  [0, 0]   \n",
       "3   AWJ0WZQYMYFQ4  120401325X                JM  [4, 4]   \n",
       "4   ATX7CZYFXI1KW  120401325X  patrice m rogoza  [2, 3]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  They look good and stick good! I just don't li...        4   \n",
       "1  These stickers work like the review says they ...        5   \n",
       "2  These are awesome and make my phone look so st...        5   \n",
       "3  Item arrived in great time and was in perfect ...        4   \n",
       "4  awesome! stays on, and looks great. can be use...        5   \n",
       "\n",
       "                                     summary  unixReviewTime   reviewTime  \n",
       "0                                 Looks Good      1400630400  05 21, 2014  \n",
       "1                      Really great product.      1389657600  01 14, 2014  \n",
       "2                             LOVE LOVE LOVE      1403740800  06 26, 2014  \n",
       "3                                      Cute!      1382313600  10 21, 2013  \n",
       "4  leopard home button sticker for iphone 4s      1359849600   02 3, 2013  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.read_json('./data/datasets/reviewCellPhones.zip', lines=True, compression='zip')\n",
    "review_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5b8f39-4bd8-447a-99f3-31a714928a33",
   "metadata": {},
   "source": [
    "Unser Ziel ist es Embeddings zu erstellen, deswegen interessieren wir uns nur für die Spalte \"reviewText\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "dbd65cb9-72b8-4bc5-8321-25da422a53a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194439,)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df = review_df['reviewText']\n",
    "text_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2edd1f7-6157-4890-a479-71a1be51aaf8",
   "metadata": {},
   "source": [
    "Im nächsten Schritt bereiten wir die Daten vor, indem wir den Text filtern.\n",
    "- Text sollte keine Zeichen haben wie !, //, usw.\n",
    "- Der Text sollte nur Wörter haben, die man gut nutzen kann, Wörter wie \"can't\" müssen verändert oder entfernt werden.\n",
    "\n",
    "Das Vorverarbeiten, etc., kann mit Funktionen und Libraries durchgeführt werden. <br>\n",
    "Hier nutzen wir gensim. Siehe: https://pypi.org/project/gensim/ [Letzter Zurgiff: 18.06.2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3fd26335-f662-43bc-b582-eacc062accf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [they, look, good, and, stick, good, just, don...\n",
       "1    [these, stickers, work, like, the, review, say...\n",
       "2    [these, are, awesome, and, make, my, phone, lo...\n",
       "3    [item, arrived, in, great, time, and, was, in,...\n",
       "4    [awesome, stays, on, and, looks, great, can, b...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Es entfernt Wörter, die zu kurz oder zu lang sind. Der Text wird dabei in Lower-Case umgewandelt.\n",
    "# - Mit Pandas kann die Funktion einfach auf alle Zellen angewendet werden. \n",
    "text_df = text_df.apply(gensim.utils.simple_preprocess)\n",
    "text_df.head()  # Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d172b6d1-e6a4-4544-a201-c22413e65752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Gensim Model.\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=10,   # Fenster \n",
    "    min_count=2, # Satz muss min. 2 Wörter haben. \n",
    "    workers=3    # CPU Worker\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef7b56-d938-47dc-bd19-c358e5cb11b5",
   "metadata": {},
   "source": [
    "Dann brauchen wir wieder ein Vokabular. \n",
    "- Gensim hilft dabei auch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e2df5140-e7d7-46cd-b0ab-5506f89a6bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(text_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6ae748ba-30cc-408e-941f-ee8482dec8f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73808871, 100642770)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total_examples: 194439\n",
    "# - Oder durch model.corpus_count\n",
    "model.train(text_df, total_examples=194439, epochs=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce7f038-e4fa-48d3-a8f6-dfcbc9ef0350",
   "metadata": {},
   "source": [
    "Danach kann das Model mit save(...) gespeichert werden, um es später zu nutzen. \n",
    "\n",
    "Eine weitere nette Sache die man mit Gensim machen kann, ist sich die ähnlichen Wörter ausgeben zu lassen. \n",
    "- Dabei weisen die Embeddings Ähnlichkeiten auf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf4d8454-2a8f-4d67-8737-92056fc30bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.8170683979988098),\n",
       " ('great', 0.7875612378120422),\n",
       " ('nice', 0.7136105895042419),\n",
       " ('fantastic', 0.7091127038002014),\n",
       " ('excellent', 0.6294456720352173),\n",
       " ('superb', 0.6257697939872742),\n",
       " ('exceptional', 0.6123889684677124),\n",
       " ('awesome', 0.5947822332382202),\n",
       " ('outstanding', 0.5888533592224121),\n",
       " ('terrific', 0.5848925709724426)]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd99ba5-9bac-4024-9572-d3385b6ab361",
   "metadata": {},
   "source": [
    "Beispiel mit einem anderen Dataset: meta_Sports_and_Outdoors\n",
    "\n",
    "> https://snap.stanford.edu/data/amazon/productGraph/categoryFiles/ [Letzer Zugriff: 18.06.2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d7f77cb4-7b98-4409-a7c7-6b1cdc455eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model, text_df, review_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0504653a-4e74-4291-89ee-44fcb299c337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>overall</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "      <th>reviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AIXZKN4ACSKI</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>David Briner</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This came in on time and I am veru happy with ...</td>\n",
       "      <td>5</td>\n",
       "      <td>Woks very good</td>\n",
       "      <td>1390694400</td>\n",
       "      <td>01 26, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A1L5P841VIO02V</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jason A. Kramer</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>I had a factory Glock tool that I was using fo...</td>\n",
       "      <td>5</td>\n",
       "      <td>Works as well as the factory tool</td>\n",
       "      <td>1328140800</td>\n",
       "      <td>02 2, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB2W04NI4OEAD</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>J. Fernald</td>\n",
       "      <td>[2, 2]</td>\n",
       "      <td>If you don't have a 3/32 punch or would like t...</td>\n",
       "      <td>4</td>\n",
       "      <td>It's a punch, that's all.</td>\n",
       "      <td>1330387200</td>\n",
       "      <td>02 28, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A148SVSWKTJKU6</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Jusitn A. Watts \"Maverick9614\"</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>This works no better than any 3/32 punch you w...</td>\n",
       "      <td>4</td>\n",
       "      <td>It's a punch with a Glock logo.</td>\n",
       "      <td>1328400000</td>\n",
       "      <td>02 5, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AAAWJ6LW9WMOO</td>\n",
       "      <td>1881509818</td>\n",
       "      <td>Material Man</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>I purchased this thinking maybe I need a speci...</td>\n",
       "      <td>4</td>\n",
       "      <td>Ok,tool does what a regular punch does.</td>\n",
       "      <td>1366675200</td>\n",
       "      <td>04 23, 2013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       reviewerID        asin                    reviewerName helpful  \\\n",
       "0    AIXZKN4ACSKI  1881509818                    David Briner  [0, 0]   \n",
       "1  A1L5P841VIO02V  1881509818                 Jason A. Kramer  [1, 1]   \n",
       "2   AB2W04NI4OEAD  1881509818                      J. Fernald  [2, 2]   \n",
       "3  A148SVSWKTJKU6  1881509818  Jusitn A. Watts \"Maverick9614\"  [0, 0]   \n",
       "4   AAAWJ6LW9WMOO  1881509818                    Material Man  [0, 0]   \n",
       "\n",
       "                                          reviewText  overall  \\\n",
       "0  This came in on time and I am veru happy with ...        5   \n",
       "1  I had a factory Glock tool that I was using fo...        5   \n",
       "2  If you don't have a 3/32 punch or would like t...        4   \n",
       "3  This works no better than any 3/32 punch you w...        4   \n",
       "4  I purchased this thinking maybe I need a speci...        4   \n",
       "\n",
       "                                   summary  unixReviewTime   reviewTime  \n",
       "0                           Woks very good      1390694400  01 26, 2014  \n",
       "1        Works as well as the factory tool      1328140800   02 2, 2012  \n",
       "2                It's a punch, that's all.      1330387200  02 28, 2012  \n",
       "3          It's a punch with a Glock logo.      1328400000   02 5, 2012  \n",
       "4  Ok,tool does what a regular punch does.      1366675200  04 23, 2013  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_df =pd.read_json(\"http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Sports_and_Outdoors_5.json.gz\", lines=True)\n",
    "text_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56176707-dfae-46b1-8632-ce02ee74f68b",
   "metadata": {},
   "source": [
    "Auch hier ändert sich das Vorgehen nicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5bc654a3-c582-4d70-929c-919115fa7804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [this, came, in, on, time, and, am, veru, happ...\n",
       "1    [had, factory, glock, tool, that, was, using, ...\n",
       "2    [if, you, don, have, punch, or, would, like, t...\n",
       "3    [this, works, no, better, than, any, punch, yo...\n",
       "4    [purchased, this, thinking, maybe, need, speci...\n",
       "Name: reviewText, dtype: object"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Wähle Text aus.\n",
    "review_text = text_df['reviewText'] \n",
    "# Filtere Text\n",
    "review_text = review_text.apply(gensim.utils.simple_preprocess)\n",
    "review_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "405805b1-68e8-4313-8c8c-22002f03f9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Gensim Model.\n",
    "model = gensim.models.Word2Vec(\n",
    "    window=8,    # Fenster \n",
    "    min_count=2, # Satz muss min. 2 Wörter haben. \n",
    "    workers=4    # CPU Worker\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6e12b0cb-6016-4285-9e3a-ed617b07bf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Erstelle Vokabular.\n",
    "model.build_vocab(review_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e962ff52-e3ae-4dec-b5ea-d69b4f823d32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "296337"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.corpus_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "979ddd40-8be5-426b-93d7-6bbfffc3d3c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109606952, 145795842)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Trainiere.\n",
    "model.train(review_text, total_examples=296337, epochs=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "026baf9b-191d-4d5b-b562-538e34565a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('decent', 0.8598130941390991),\n",
       " ('great', 0.7914591431617737),\n",
       " ('nice', 0.7311326265335083),\n",
       " ('fantastic', 0.7098391056060791),\n",
       " ('terrific', 0.6529357433319092),\n",
       " ('excellent', 0.6398428678512573),\n",
       " ('reasonable', 0.6331174373626709),\n",
       " ('superb', 0.630240797996521),\n",
       " ('awesome', 0.627801775932312),\n",
       " ('wonderful', 0.6105560064315796)]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('good')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a46d77a8-0eec-4162-8051-b6c11d74014f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3634112"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity(w1=\"slow\",   w2='steady')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
