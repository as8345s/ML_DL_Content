{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1599fa2-58e3-4d56-9a64-02a5faa2da47",
   "metadata": {},
   "source": [
    "<h1>Tensorflow Datasets und Pipeline</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1c4974-ea0b-4743-a226-756c1f192e5c",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "Siehe: https://www.tensorflow.org/guide/data [Letzter Zugriff: 19.06.2024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ba5bac9-36ab-4f96-b1c7-14250d02a091",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5525a71e-a489-481f-9ad7-bfb70d982ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# // Content Coming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80dbe121-ae9f-4694-9ad2-5a57f65ec102",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c8482dcb-d57a-4b32-a1f0-cd9ef3a39d55",
   "metadata": {},
   "source": [
    "Mit den Datasets von Tensorflow sind einige Dinge möglich, hier werden die Einzelheiten gezeigt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "0f737b1c-6498-4a27-a9cd-befd342925d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9fc2d8-1243-4af2-b7fe-ec09616c25f1",
   "metadata": {},
   "source": [
    "<h2>Basics</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d4767f-6380-4ba3-8b97-8e6af142f5b5",
   "metadata": {},
   "source": [
    "Die Dataset Struktur von Tensorflow bietet viele Möglichkeiten für ETL. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "aa1797cd-953e-4f49-9512-668727fa5bca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset:\n",
    "data = np.array(range(20))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c6b824db-7eb5-4629-83ea-a918eca88c88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "        13,  14,  15,  16,  17,  18,  19, -10, -50, 200, 400])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Füge Dataset negative  und große Werte hinzu. \n",
    "data = np.append(data, [-10, -50, 200, 400])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fea7ff2e-8048-40c5-baec-f83a566d0e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_TensorSliceDataset element_spec=TensorSpec(shape=(), dtype=tf.int32, name=None)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TF Dataset.:\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(data)\n",
    "tf_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0043858-697a-442a-adbd-5069e9c6c085",
   "metadata": {},
   "source": [
    "Durch dieses Dataset kann jetzt iteriert werden. <br>\n",
    "Um wieder eine Zahl als Numpy zu bekommen, wird die Methode .numpy() angewendet.\n",
    "\n",
    "Durch das einfache Iterieren kann man sich schnell die Daten anschauen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7d69f805-e85c-42f6-b1f4-5479b1718cb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "-10\n",
      "-50\n",
      "-10\n",
      "-50\n",
      "200\n",
      "400\n"
     ]
    }
   ],
   "source": [
    "for i in tf_dataset:\n",
    "    #print(i)  # Ausgabe: tf.Tensor(0, shape=(), dtype=int32), ...\n",
    "    print(i.numpy())  # Ausgabe: 0, ...\n",
    "\n",
    "    # Oder direkt als Numpy mit: tf_dataset.as_numpy_iterator()\n",
    "\n",
    "    # Oder nehme nur die ersten 5  mit tf_dataset.take(5):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae95375-52b8-4a88-8f30-b8b116cbb831",
   "metadata": {},
   "source": [
    "Ein Dataset kann durch ein Lambda oder eine separate Funktion gefiltert werden. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1d922bdd-72f3-4ba9-b522-272d510109d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset(dataset):\n",
    "    for i in dataset.as_numpy_iterator():\n",
    "        print(i)\n",
    "\n",
    "def do_op(x):\n",
    "    return x*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d5a400e3-0169-4632-9bc6-c865542e0ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lambda:\n",
    "tf_dataset = tf_dataset.filter(lambda x: ( (x>0) & (x<70) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8ef16bec-b766-4810-ad12-2adb7f04c188",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "print_dataset(tf_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "514918bf-ac31-461c-95e0-a44ea9865bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wende weitere Operation an.\n",
    "tf_dataset  = tf_dataset.filter(lambda x:  x>9)\n",
    "tf_dataset2 = tf_dataset.map(lambda x: x*2)\n",
    "tf_dataset3 = tf_dataset.map(do_op)  # Mit Funktion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "34548145-d569-47a2-b10d-4c9ff67997e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "22\n",
      "24\n",
      "26\n",
      "28\n",
      "30\n",
      "32\n",
      "34\n",
      "36\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "print_dataset(tf_dataset2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf9ab62-42b0-4c07-b759-ea7a429cd1e5",
   "metadata": {},
   "source": [
    "Die Daten können auch gemischt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "99fd3c4a-d0c1-4089-82c7-86503e35773c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n",
      "26\n",
      "22\n",
      "28\n",
      "32\n",
      "34\n",
      "36\n",
      "30\n",
      "20\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "tf_dataset2_shuffled = tf_dataset2.shuffle(3)  # Um ganzes Dataset zu mischen, gebe Länge des Datasets an.\n",
    "print_dataset(tf_dataset2_shuffled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "f57d067b-94c5-42ae-b7ea-2c1de02a4847",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20 22]\n",
      "[24 26]\n",
      "[28 30]\n",
      "[32 34]\n",
      "[36 38]\n"
     ]
    }
   ],
   "source": [
    "# Batching\n",
    "for i in tf_dataset2.batch(2):\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a947abff-ce03-422a-ab3b-948ce494f43f",
   "metadata": {},
   "source": [
    "<h2>TF Input Pipeline</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745c91e9-6df6-43f4-be9d-923a86ef5d79",
   "metadata": {},
   "source": [
    "Als Pipeline geht alles in einer Zeile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "28586619-5c5b-4657-94e5-0f7fd2798114",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(data)  # Erstelle Dataset.\n",
    "# TF Input Pipeline:\n",
    "# - Variable bei Lambda muss sich immer unterscheiden.\n",
    "dataset = tf_dataset.filter(lambda x: ((x>0) & (x<70))).filter(lambda y: y>9).map(lambda z: z*2).shuffle(7).batch(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce010f96-5492-4bc1-bce2-84dd7408bcd2",
   "metadata": {},
   "source": [
    "Jetzt wenden wir das ganze auf Bilder an."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "83f5e6b0-439b-408d-8fb1-ca625f4a3db8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from http://download.tensorflow.org/example_images/flower_photos.tgz\n",
      "\u001b[1m228813984/228813984\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# Hole Dataset\n",
    "# - Siehe Tensorflow: https://www.tensorflow.org/datasets/catalog/tf_flowers\n",
    "url = \"http://download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=url, cache_dir='./data/datasets/tf_flowers', untar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "195619fe-11be-4e9a-8a36-3fe7fd410323",
   "metadata": {},
   "source": [
    "Bei einem Verzeichnis, von wo wir die Bilder laden wollen, sind die Unterverzeichnisse mit den Klassen beschriftet. \n",
    "\n",
    "\n",
    "Verzeichnisstruktur: <br>\n",
    "<i>tf_flowers/</i>:   Wo alle Bilder sind. <br>\n",
    "<i>tf_flowers/<-Klasse->/ </i>: Klassen der Bilder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "b096b17e-4fa7-4229-a8b6-287b46aa4d26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.data.ops.shuffle_op._ShuffleDataset"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_dict = {'daisy':0, 'dandelion':1, 'roses':2, 'sunflowers':3, 'tulips':4 }\n",
    "\n",
    "img_data = tf.data.Dataset.list_files('./data/datasets/tf_flowers/*/*')\n",
    "img_data = img_dada.shuffle(len(img_dada))\n",
    "type(img_data)  # Bilder noch nicht geladen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "5ab28b35-0178-46a1-b83e-024618433f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\tulips\\\\16265883604_92be82b973.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\dandelion\\\\461632542_0387557eff.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\roses\\\\14019883858_e5d2a0ec10_n.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\sunflowers\\\\184683023_737fec5b18.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\daisy\\\\5110107234_12ddc0206b_m.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\tulips\\\\8628453641_6f87755815_m.jpg', shape=(), dtype=string)\n",
      "tf.Tensor(b'.\\\\data\\\\datasets\\\\tf_flowers\\\\tulips\\\\14103897845_7986002615.jpg', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for i in img_data.take(7):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24905b6a-1a2b-4e7f-95c5-c07e8c79c799",
   "metadata": {},
   "source": [
    "Dann teilen wir die Daten auf in Train- und Testset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "4ef93a67-55da-45c7-8611-d07f301d358b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Z. B. so:\n",
    "len_dataset = len(img_data)\n",
    "train_set = img_data.take(int(len_dataset*0.8)) # Nehme x-Elemente.\n",
    "test_set  = img_data.skip(int(len_dataset*0.8)) # Nehme die Elemente nach x-Elementen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca1a5b0-a28b-4d00-a1b1-bb8343341a82",
   "metadata": {},
   "source": [
    "Für jede dieser Klassen brauchen wir ein Label. Dafür gibt es mehrere Wege. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d969226d-bdbc-4470-bcac-bd19d603eb45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'tulips', shape=(), dtype=string)\n",
      "tf.Tensor(b'tulips', shape=(), dtype=string)\n",
      "tf.Tensor(b'roses', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "# So könnte man die Labels finden.\n",
    "for i in img_data.take(3):\n",
    "    print(tf.strings.split(i.numpy(), '\\\\')[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "326b0da3-6e2e-4d49-9165-4136c65f061a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2936"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2970b549-878b-49d8-a7ed-93844eeb5bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibt Label zurück.\n",
    "def extract_label(path) :\n",
    "    return tf.strings.split(path, '\\\\')[4] \n",
    "    \n",
    "# Lade Bild und transformiere.\n",
    "def load_img(path):\n",
    "    label = extract_label(path)\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [150, 150])\n",
    "    return img, label\n",
    "\n",
    "def scale(img, label):\n",
    "    return img/255, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "090049ac-ad13-4ef6-915a-376c55b4ef67",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: b'roses'\n",
      "img: [[[ 68.011665  77.011665  84.011665]\n",
      "  [ 71.085     79.305     86.695   ]\n",
      "  [ 69.918335  78.78834   85.85333 ]\n",
      "  ...\n",
      "  [115.41501  129.        75.935005]\n",
      "  [117.33     130.11      79.72    ]\n",
      "  [114.10168  129.27168   75.881676]]\n",
      "\n",
      " [[ 65.        74.34      82.83    ]\n",
      "  [ 63.095     73.265     81.755   ]\n",
      "  [ 67.72333   76.918335  84.166664]\n",
      "  ...\n",
      "  [118.16666  128.16666   75.47498 ]\n",
      "  [118.085    126.425     77.255   ]\n",
      "  [118.05999  126.39999   75.51331 ]]\n",
      "\n",
      " [[ 64.10833   73.15833   82.15833 ]\n",
      "  [ 65.45      74.5       83.5     ]\n",
      "  [ 67.308334  77.941666  84.566666]\n",
      "  ...\n",
      "  [118.358315 128.13333   75.141655]\n",
      "  [119.475    123.85      76.375   ]\n",
      "  [118.1      121.20835   73.71663 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 94.891655 138.86665   79.87499 ]\n",
      "  [ 93.07498  134.07498   76.07498 ]\n",
      "  [ 90.900024 134.90002   74.30001 ]\n",
      "  ...\n",
      "  [ 83.93332  111.43335   88.600006]\n",
      "  [ 80.07498  102.57498   87.07498 ]\n",
      "  [ 73.216675  89.92508   85.783325]]\n",
      "\n",
      " [[ 95.666664 136.66667   78.666664]\n",
      "  [ 90.32999  134.32999   73.5     ]\n",
      "  [ 91.333336 134.83333   74.      ]\n",
      "  ...\n",
      "  [ 83.82999  108.48996   87.02498 ]\n",
      "  [ 79.24498   97.81995   86.15997 ]\n",
      "  [ 72.96501   87.81668   82.82666 ]]\n",
      "\n",
      " [[ 93.8583   135.83333   77.50832 ]\n",
      "  [ 88.109985 132.5       72.30499 ]\n",
      "  [ 89.94332  133.44331   72.609985]\n",
      "  ...\n",
      "  [ 79.38663   99.21658   83.06991 ]\n",
      "  [ 76.609985  89.829956  83.41498 ]\n",
      "  [ 70.87499   78.45332   77.66828 ]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for img, label in train_set.map(load_img).take(1):\n",
    "    print(f'Label: {label}\\nimg: {img} \\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6342877f-ac2a-4c46-9896-a737b2603c41",
   "metadata": {},
   "source": [
    "Als Pipeline:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "a869bddf-bea2-4e00-b564-01ce9f94ce39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Als Pipeline:\n",
    "trainset = train_set.map(load_img).map(scale).take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "b70d60d1-47dd-457c-a44c-45691ba1c9ff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: b'roses'\n",
      "img: [[[0.9980065  0.9980065  0.9980065 ]\n",
      "  [0.9968824  0.9968824  0.9968824 ]\n",
      "  [0.9901634  0.9901634  0.9901634 ]\n",
      "  ...\n",
      "  [0.98984313 0.98984313 0.98984313]\n",
      "  [0.9980392  0.9980392  0.9980392 ]\n",
      "  [0.9993463  0.9993463  0.9993463 ]]\n",
      "\n",
      " [[0.99698037 0.99698037 0.99698037]\n",
      "  [0.9941176  0.9941176  0.9941176 ]\n",
      "  [0.99190855 0.99190855 0.99190855]\n",
      "  ...\n",
      "  [0.9912549  0.9912549  0.9912549 ]\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [0.9993463  0.9993463  0.9993463 ]]\n",
      "\n",
      " [[0.99983656 0.99983656 0.99983656]\n",
      "  [0.9998039  0.9998039  0.9998039 ]\n",
      "  [0.99359477 0.99359477 0.99359477]\n",
      "  ...\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [0.9993463  0.9993463  0.9993463 ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.9962419  0.9962419  0.9962419 ]\n",
      "  [0.99980384 0.99980384 0.99980384]\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  ...\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[0.9993464  0.9993464  0.9993464 ]\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [0.99517643 0.99517643 0.99517643]\n",
      "  ...\n",
      "  [0.9969804  0.9969804  0.9969804 ]\n",
      "  [0.9969804  0.9969804  0.9969804 ]\n",
      "  [1.         1.         1.        ]]\n",
      "\n",
      " [[0.99800646 0.99800646 0.99800646]\n",
      "  [0.99607843 0.99607843 0.99607843]\n",
      "  [0.9918889  0.9918889  0.9918889 ]\n",
      "  ...\n",
      "  [0.99839216 0.99839216 0.99839216]\n",
      "  [0.99839216 0.99839216 0.99839216]\n",
      "  [1.         1.         1.        ]]] \n",
      "\n",
      "Label: b'dandelion'\n",
      "img: [[[0.12171242 0.20681046 0.10654902]\n",
      "  [0.1254902  0.21568628 0.10823528]\n",
      "  [0.11849672 0.21522875 0.10215686]\n",
      "  ...\n",
      "  [0.1495424  0.2299348  0.1312419 ]\n",
      "  [0.14199997 0.2400392  0.1263137 ]\n",
      "  [0.1474641  0.23766017 0.12785625]]\n",
      "\n",
      " [[0.12326797 0.20836602 0.10810458]\n",
      "  [0.12796079 0.21815687 0.11070588]\n",
      "  [0.12189542 0.21862745 0.10555556]\n",
      "  ...\n",
      "  [0.15581691 0.23620932 0.13751642]\n",
      "  [0.14498039 0.2430196  0.12929411]\n",
      "  [0.14901961 0.23921569 0.12941177]]\n",
      "\n",
      " [[0.12326797 0.20836602 0.10810458]\n",
      "  [0.12882352 0.2190196  0.11156862]\n",
      "  [0.1245098  0.22124182 0.10816993]\n",
      "  ...\n",
      "  [0.14869277 0.23954253 0.13758174]\n",
      "  [0.14450976 0.24254899 0.12882349]\n",
      "  [0.14313726 0.23333333 0.12352941]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.05267974 0.10366013 0.03699346]\n",
      "  [0.05313726 0.10411765 0.03745098]\n",
      "  [0.06078431 0.11176471 0.04509804]\n",
      "  ...\n",
      "  [0.0820261  0.1330065  0.06633983]\n",
      "  [0.07843138 0.12941177 0.0627451 ]\n",
      "  [0.07843138 0.12941177 0.0627451 ]]\n",
      "\n",
      " [[0.05682354 0.10780393 0.04113727]\n",
      "  [0.05776472 0.10874511 0.04207844]\n",
      "  [0.05941176 0.11039215 0.04372548]\n",
      "  ...\n",
      "  [0.08137246 0.13235286 0.06568618]\n",
      "  [0.07831371 0.12929411 0.06262743]\n",
      "  [0.07394768 0.12492806 0.0582614 ]]\n",
      "\n",
      " [[0.06037908 0.11135947 0.0446928 ]\n",
      "  [0.06156861 0.11254901 0.04588234]\n",
      "  [0.05653596 0.10751635 0.04084968]\n",
      "  ...\n",
      "  [0.07843138 0.12941177 0.0627451 ]\n",
      "  [0.07643125 0.12741165 0.06074498]\n",
      "  [0.06614374 0.11712413 0.05045746]]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Iteriere:\n",
    "for img, label in trainset.take(2):\n",
    "    print(f'Label: {label}\\nimg: {img} \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22c5df4-f817-4e1e-9ae0-a00c97be621f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145ee1be-4a95-462e-acf7-829ff87fbb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b809d18c-8482-4662-8a95-c42e1c2ecc6c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
