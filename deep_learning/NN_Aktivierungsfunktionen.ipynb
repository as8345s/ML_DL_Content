{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "173dff46-1160-4156-9a77-36e37d97af3d",
   "metadata": {},
   "source": [
    "<h1>Aktivierungsfunktionen in neuralen Netzen</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b11e7c-77c9-46f8-bb51-52fc08fab379",
   "metadata": {},
   "source": [
    "Aktivierungsfunktionen sind kleinere Funktionen, die ein Neuron hat, die einen Output generieren.\n",
    "\n",
    "Jeder Neuron hat zu Beginn zufällig initialisierte Weights (Gewichte). Das Ziel ist es, diese Weights so anzupassen, dass der Fehler, der am Ende berechnet wird (Loss, total Error) minimal wird. Dieser Vorgang ist das Training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23938dcf-af42-4847-8c43-df6f6dbdf4ab",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: Eingabe der Features in ein einziges Neuron. \n",
    "\n",
    "<img src=\"./img/nn_1.PNG\" width=600 hight=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cebee82-47b3-4c6f-bda1-204c577f09c5",
   "metadata": {},
   "source": [
    "Die Funktion wandeln das Ergebnis der Summe in eine andere Zahl um, wie z. B. die Zahl 50 in 0,5.\n",
    "\n",
    "Mit einer Sigmoidfunktion am Ende des Netzes können die Zahlen in den Bereich von 0 bis 1 umgewandelt werden. Dadurch eine es viel einfacher eine Entscheidung zu treffen, wenn alles über 0,5 als Positiv gewertet wird => Neuron ist aktiviert. \n",
    "\n",
    "Kleinere Zahlen sind besser für ein Netzwerk geeignet als sehr große Zahlen. \n",
    "\n",
    "Es gibt viele dieser Funktionen, die unterschiedliche Aufgabe haben. Eine Funktion, die linear ist, gibt den Output so weiter wie dieser angekommen ist, mit anderen Worten, genau das Ergebnis der Summe.\n",
    "\n",
    "Die Berechnung der linearen Outputs ist weit weniger aufwendig als bei den andere Funktion, wo verschiedene mathematische Operationen ausgeführt werden müssen. Frameworks wie PyTorch, Tensorflow, usw. haben diese Algorithmen effizient passend zur Hardware implementiert, oder nutzen speziele Libraries wo dies schon erledigt wurde. Die Berechnungen müssen sehr effizient laufen, da es sehr viele Neuronen und Layers in einem Netzwerk gibt. Eine langsame Berechnung verlängert das Training.  \n",
    "In C++ könnte man z. B. Intrinsics nutzen, um effizient die Vektorisierung der CPU zu verwenden.\n",
    "\n",
    "Daher ist es wichtig zu verstehen, welche Auswirkungen verschiedenen Funktionen haben, und welche Funktionen wo besser eingesetzt werden sollten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873d47af-a6e8-4f34-a880-74e37b0308e1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d11c5c-f44b-47dc-bc13-c01d1b4ebd8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0010124c-10b3-4cff-8951-0b251ea62e81",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5c0f83-2033-4b3d-b8f6-490c64e71256",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b14d19-c8b9-4b65-9ebe-5c8e01460a32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
