{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5465b81-b364-4369-b8d8-e7d921814906",
   "metadata": {},
   "source": [
    "<h1>Kostenfunktion - Gradientenabstieg</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c5276-664b-48a0-8f3d-67c614b88b71",
   "metadata": {},
   "source": [
    "Loss oder auch Kostenfunkton ist ein sehr wichtiger Bestandteil, wenn es um Deep-Learning und Maschine-Learning geht. Durch das Berechnen der Abweichung des Ergebnisses von der Wahrheit (y_predicted und y_true), kann festgestellt werden wie falsch die prediction ist.\n",
    "\n",
    "Beim Trainieren soll diese Abweichung möglichst minimiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec39b0b-17a2-4a85-a200-f4150f3725d6",
   "metadata": {},
   "source": [
    "Um diese Abweichung zu berechnen gibt es verschiedene Funktionen. Die Funktion MSE ist z. B. sehr bekannt. \n",
    "\n",
    "Es ist ein interessantes Thema, für das es auch viele gute Artikel zum Nachlesen gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113a1e7-a61d-4180-8445-971b8f89f5a0",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: Eingabe der Features in ein einziges Neuron. Jedes Neuron hat 2 Komponente.\n",
    "\n",
    "<img src=\"./img/nn_1.PNG\" width=600 hight=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab02a8-e44a-4ea9-9bed-1e604b39e975",
   "metadata": {},
   "source": [
    "Das Netz startet mit einer bestimmten Initialisierung der Gewichte, wie in der Abbildung 1 zusehen ist. Diese können mit 1 starten, oder mit jeder anderen beliebigen Zahl. Bias wird oft mit 0 initialisiert. In der Erstes Epoche (oder Batch) performt das Netz sehr schlecht, erst nach der Erfassung des Fehlers und deren Reduzierung durch das Finden des Minimums, verbessert sich die Genauigkeit durch das Anpassen dieser Gewichte.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05f858-0be9-4af4-9bbc-88cc323e1b8d",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: MSE und MAE.\n",
    "\n",
    "<img src=\"./img/nn_5.PNG\" width=600 hight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3225e3-44b6-4f8f-8d6c-6e2732e166c6",
   "metadata": {},
   "source": [
    "MSE ist z. B. nützlich, wenn es negative Werte gibt.\n",
    "\n",
    "Es gibt viele Kostenfunktionen für verschiedene Einsätze. Frameworks wie Tensorflow bieten eine gute Übersicht der verfügbaren Kostenfunktionen, die während des Trainings genutzt werden können.\n",
    ">https://www.tensorflow.org/api_docs/python/tf/keras/losses [Letzter Zugriff: 24.06.2024]\n",
    "\n",
    "\n",
    "Wie auch bei den Aktivierungsfunktionen können diese einfach in Python umgesetzt werden, wenn man der Formel folgt.\n",
    "\n",
    "Einige dieser Kostenfunktionen haben Parameter die eingestellt werden könne. Die Funktion Log-Loss, auch genannt Binary-Crossentropy, hat solche Parameter\n",
    "\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy [Letzter Zugriff: 24.06.2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544b165-68c4-466f-a205-6c15c1d38cc9",
   "metadata": {},
   "source": [
    "Der Einsatz von Log-Loss findet Platz bei Klassifizierungsproblemen, wo der Output des Netzes eine Wahrscheinlichkeit für eine Klasse ist. \n",
    "Dabei befinden sich die Werte zwichen 0 und 1 (Output ist Binär). Bei Multiclass-Klassifizierungen und der Aktivierungsfunktion Softmax wird Log-Loss ebenfalls eingesetzt.  \n",
    "\n",
    "Die Formel für Log-Loss ist (Binär): <br>\n",
    "\n",
    "$\n",
    "- \\frac{1}{n} \\ \\sum_{i=0}^{n} y_i \\log(\\hat{y}_i) + (1 - y_i) * log(1 - \\hat{y}_i)\n",
    "$\n",
    "\n",
    "Basierend auf der Funktion soll der Fehler minimiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bae93-2092-48b7-966c-61aa674033a4",
   "metadata": {},
   "source": [
    "<h2>Kostenfunktion als Code</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e46b5d-132e-41fb-822c-767fdba910c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc4ca00-3e0d-4d84-bb74-229e9a633a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 0, 1, 0, 1]\n",
    "y_pred = [0.5, 0.3, 0.7, 0.2, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db74182-106b-4647-b1c0-5771f692ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit Numpy einfach umsetzbar. \n",
    "def MSE_1(y_pred:np.array, y_true:np.array):\n",
    "    return np.mean( np.square(y_pred - y_true) )\n",
    "\n",
    "# Ohne Numpy\n",
    "def MSE_2(y_pred, y_true):\n",
    "    tot_error = 0\n",
    "\n",
    "    for yp, yt in zip(y_pred, y_true):\n",
    "        tot_error = tot_error + (float(yt) - yp)**2\n",
    "\n",
    "    return (1 / len(y_pred)) * tot_error\n",
    "\n",
    "\n",
    "# Log-Loss:\n",
    "# - Mit Numpy\n",
    "def logloss(y_pred, y_true):\n",
    "    # Weil log(0) nicht definiert ist => Wert nah bei 0 nehmen.\n",
    "    eps = 1e-15\n",
    "    y_pred = [max(i, eps)    for i in y_pred ]\n",
    "    y_pred = [min(i, 1-eps)  for i in y_pred ]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return -np.mean(\\\n",
    "        y_true * np.log(y_pred) + (1-y_true) * np.log(1 - y_pred ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66fed53f-4f16-475a-919f-c6d3cf30053f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10200000000000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_1(np.array(y_true), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4eb1a8-4d46-4b06-ab64-893e579c3a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10200000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c702992-8374-4050-bc60-4e1bb74ff934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37055683421316593"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(np.array(y_pred), np.array(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8c4a7-7cd5-401c-8267-b26e296a3bfd",
   "metadata": {},
   "source": [
    "<h1>Gradientenabstieg</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e44286-40fc-45fa-8baf-842277ec35ba",
   "metadata": {},
   "source": [
    "Gradientenabstieg ist einer der wichtigsten und elementaren Konzepte in DL, um überhaupt das Model zu optimieren. Durch den Abstieg Richtung Minimum soll der Gesamtfehler minimiert und die Weights optimiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c210e17-ae84-4f27-b713-6dcc6a0b706a",
   "metadata": {},
   "source": [
    "<i>Abb3</i>: Finde die Parameter.\n",
    "\n",
    "<img src=\"./img/nn_6.PNG\" width=400 hight=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae5f52-35ef-4ed6-878a-d112dd93afaf",
   "metadata": {},
   "source": [
    "In einem Netzwerk wollen wir die richtigen Parameter finden, als die w's und b's. \n",
    "\n",
    "In der Abbildung 3 sehen wir zwei einfache Tabelle, was sind aber die Parameter?\n",
    "\n",
    "In der Tabelle 1: <br>\n",
    "$\n",
    "y = X * w1 + b \\ = \\ X * 2 + 0\n",
    "$\n",
    "\n",
    "Es ist einfach zu erkennen.\n",
    "\n",
    "Was ist mit der Tabelle 2? Durch direktes Hinschauen geht das nicht, besonders nicht, wenn es sehr viele Parameter gibt.\n",
    "\n",
    "Durch das Gradientenverfahren können die Parameter gefunden werden => w1 = 0.34 und b = -0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f8c50-f97a-4e70-8861-5f575d8b3b36",
   "metadata": {},
   "source": [
    "<i>Abb4</i>: Epoche und total-error (Beispielhaft).\n",
    "\n",
    "<img src=\"./img/nn_7.PNG\" width=600 hight=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940300ab-f017-4896-a9b6-3d8de2f0e73e",
   "metadata": {},
   "source": [
    "Während des Forwardpasses werden die einzelnen Samples dem Netzwerk übergeben, Stück für Stück. Nach jedem Sample wird der Fehler mit einer bestimmten Kostenfunktion, z. B. Log-Loss, berechnet. <br>\n",
    "Am Ende wird der Total-Error berechnet, was uns als Loss angezeigt wird, z. B. als Log-Loss.\n",
    "\n",
    "Durch Backpropagation sollen die Parameter mit dem gegebenen Fehler angepasst werden. Es sind mehrere Epochen nötig, um Log-Loss zu reduzieren und um die passenden Weights zu finden.\n",
    "\n",
    "Das ändert/update der Weights sieht so aussehen:<br>\n",
    "$\n",
    "w1 = w1 - Schrittweite * PartielleAbleitung_w1\n",
    "$\n",
    "\n",
    "Jetzt werden die <b>Ableitungen</b> der Funktionen wichtig. Um die Steigung an einem Punkt zu bekommen, wird die Ableitung der Funktion benötigt. Der Punkt wird dann in die Ableitung eingesetzt und herauskommt die Steigung. <br>\n",
    "=> Wie ändert sich der Gesamt-Loss bei einer veränderung eines w's.\n",
    "\n",
    "Dabei wird die Schrittweite richtung Minimum auch als Learning-rate oder lr bezeichnet. \n",
    "- Bei großen Schritten könnte das Minimum überschritten werden => man kommt nie ans Ziel und spring immer umher.\n",
    "- Bei einem zu kleinen Wert dauert es lange, bis das Minimum erreicht ist.\n",
    "\n",
    "Für die anderen w's und das b ist das Vorgehen gleich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6258481-e2cb-4049-bc15-999d752aaeec",
   "metadata": {},
   "source": [
    "Deswegen ist es wichtig, sich mit der Thematik auseinander zusetzen.\n",
    "\n",
    "Nach der Anpassung der Weights, wird der Vorgang fortgeführt bis das gewünschte Ergebnis da ist, z. B. wenn Loss sehr niedrig ist oder sich die w's nicht mehr stark verändern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7634634-9ca0-45e3-91be-c5133c133ace",
   "metadata": {},
   "source": [
    "<h2>Code</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a9fb85-a27d-406b-98f8-3383b669d912",
   "metadata": {},
   "source": [
    "Als Versuchsbeispiel nehmen wir ein kleines Dataset wo es darum geht eine Versicherung abzuschließen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e30cf04b-1526-4bfc-b40a-fc824f7b6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51106ca9-7b58-461c-a8f3-e4ec55bdc086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility  bought_insurance\n",
       "0   0.22              1                 0\n",
       "1   0.25              0                 0\n",
       "2   0.47              1                 1\n",
       "3   0.52              0                 0\n",
       "4   0.46              1                 1\n",
       "5   0.56              1                 1\n",
       "6   0.55              0                 0\n",
       "7   0.60              0                 1\n",
       "8   0.62              1                 1\n",
       "9   0.61              1                 1\n",
       "10  0.18              1                 0\n",
       "11  0.28              1                 0\n",
       "12  0.27              0                 0\n",
       "13  0.29              0                 0\n",
       "14  0.49              1                 1\n",
       "15  0.55              1                 1\n",
       "16  0.25              0                 1\n",
       "17  0.58              1                 1\n",
       "18  0.19              0                 0\n",
       "19  0.18              1                 0\n",
       "20  0.21              1                 0\n",
       "21  0.26              0                 0\n",
       "22  0.40              1                 1\n",
       "23  0.45              1                 1\n",
       "24  0.50              1                 1\n",
       "25  0.54              1                 1\n",
       "26  0.23              1                 0\n",
       "27  0.46              1                 0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Dataset\n",
    "data_df = pd.read_csv('./data/data.csv')\n",
    "data_df['age'] = data_df['age'] / 100\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d675642-b563-438c-a8b3-52de0ad32245",
   "metadata": {},
   "source": [
    "Durch ein überschaubares Dataset und ein kleines Netz kann das Verfahren einfach implementiert werden.\n",
    "\n",
    "Wir haben 2 Neuronen als Input und 1 Neuron als Output. \n",
    "\n",
    "Als Erstes probieren wir es mit Keras aus und lassen uns die Weigts ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd42ea2f-9739-4296-8010-07c644d3e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=(2,), \\\n",
    "                          kernel_initializer='ones', bias_initializer='zeros', activation='sigmoid', name=\"L1a2\")\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss     ='binary_crossentropy', # Log-Loss\n",
    "    metrics  = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "789f2a44-4b8c-48d4-b7ee-25759a3b2328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_df.drop(['bought_insurance'], axis='columns')\n",
    "y = data_df['bought_insurance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e3e1f45-647e-439f-9cd7-95952e151cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.7143\n",
      "Epoch 2/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7143\n",
      "Epoch 3/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7143\n",
      "Epoch 4/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7143\n",
      "Epoch 5/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7143\n",
      "Epoch 6/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7143\n",
      "Epoch 7/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7143\n",
      "Epoch 8/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7143\n",
      "Epoch 9/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7143\n",
      "Epoch 10/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7143\n",
      "Epoch 11/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7143\n",
      "Epoch 12/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7143\n",
      "Epoch 13/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7143\n",
      "Epoch 14/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7143\n",
      "Epoch 15/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7143\n",
      "Epoch 16/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7143\n",
      "Epoch 17/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7143\n",
      "Epoch 18/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7143\n",
      "Epoch 19/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7143\n",
      "Epoch 20/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7143\n",
      "Epoch 21/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7143\n",
      "Epoch 22/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7143\n",
      "Epoch 23/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7143\n",
      "Epoch 24/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7143\n",
      "Epoch 25/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7143\n",
      "Epoch 26/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7143\n",
      "Epoch 27/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7143\n",
      "Epoch 28/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7143\n",
      "Epoch 29/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7143\n",
      "Epoch 30/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7143\n",
      "Epoch 31/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7143\n",
      "Epoch 32/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7143\n",
      "Epoch 33/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7143\n",
      "Epoch 34/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7143\n",
      "Epoch 35/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7143\n",
      "Epoch 36/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7143\n",
      "Epoch 37/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7143\n",
      "Epoch 38/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7143\n",
      "Epoch 39/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7143\n",
      "Epoch 40/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7143\n",
      "Epoch 41/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7143\n",
      "Epoch 42/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7143\n",
      "Epoch 43/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7143\n",
      "Epoch 44/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7143\n",
      "Epoch 45/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7143\n",
      "Epoch 46/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7143\n",
      "Epoch 47/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7143\n",
      "Epoch 48/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7143\n",
      "Epoch 49/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5642 - accuracy: 0.7143\n",
      "Epoch 50/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7143\n",
      "Epoch 51/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7143\n",
      "Epoch 52/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5640 - accuracy: 0.7143\n",
      "Epoch 53/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7143\n",
      "Epoch 54/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7143\n",
      "Epoch 55/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7143\n",
      "Epoch 56/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7143\n",
      "Epoch 57/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7143\n",
      "Epoch 58/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7143\n",
      "Epoch 59/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7143\n",
      "Epoch 60/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7143\n",
      "Epoch 61/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7143\n",
      "Epoch 62/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7143\n",
      "Epoch 63/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7143\n",
      "Epoch 64/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7143\n",
      "Epoch 65/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7143\n",
      "Epoch 66/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7143\n",
      "Epoch 67/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7143\n",
      "Epoch 68/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7143\n",
      "Epoch 69/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7143\n",
      "Epoch 70/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7143\n",
      "Epoch 71/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5630 - accuracy: 0.7143\n",
      "Epoch 72/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7143\n",
      "Epoch 73/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5629 - accuracy: 0.7143\n",
      "Epoch 74/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7143\n",
      "Epoch 75/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7143\n",
      "Epoch 76/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7143\n",
      "Epoch 77/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7143\n",
      "Epoch 78/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7143\n",
      "Epoch 79/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7143\n",
      "Epoch 80/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7143\n",
      "Epoch 81/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5624 - accuracy: 0.7143\n",
      "Epoch 82/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7143\n",
      "Epoch 83/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7143\n",
      "Epoch 84/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7143\n",
      "Epoch 85/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7143\n",
      "Epoch 86/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7143\n",
      "Epoch 87/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7143\n",
      "Epoch 88/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7143\n",
      "Epoch 89/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7143\n",
      "Epoch 90/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7143\n",
      "Epoch 91/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7143\n",
      "Epoch 92/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7143\n",
      "Epoch 93/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7143\n",
      "Epoch 94/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7143\n",
      "Epoch 95/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5617 - accuracy: 0.7143\n",
      "Epoch 96/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7143\n",
      "Epoch 97/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7143\n",
      "Epoch 98/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7143\n",
      "Epoch 99/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7143\n",
      "Epoch 100/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5614 - accuracy: 0.7143\n",
      "Epoch 101/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7143\n",
      "Epoch 102/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7143\n",
      "Epoch 103/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7143\n",
      "Epoch 104/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7143\n",
      "Epoch 105/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7143\n",
      "Epoch 106/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7143\n",
      "Epoch 107/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7143\n",
      "Epoch 108/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7143\n",
      "Epoch 109/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7143\n",
      "Epoch 110/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7143\n",
      "Epoch 111/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7143\n",
      "Epoch 112/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7143\n",
      "Epoch 113/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5607 - accuracy: 0.7143\n",
      "Epoch 114/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7143\n",
      "Epoch 115/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7143\n",
      "Epoch 116/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7143\n",
      "Epoch 117/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7143\n",
      "Epoch 118/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7143\n",
      "Epoch 119/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7143\n",
      "Epoch 120/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7143\n",
      "Epoch 121/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7143\n",
      "Epoch 122/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7143\n",
      "Epoch 123/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.7143\n",
      "Epoch 124/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7143\n",
      "Epoch 125/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7143\n",
      "Epoch 126/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7143\n",
      "Epoch 127/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7143\n",
      "Epoch 128/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7143\n",
      "Epoch 129/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7143\n",
      "Epoch 130/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7143\n",
      "Epoch 131/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7143\n",
      "Epoch 132/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7143\n",
      "Epoch 133/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.7143\n",
      "Epoch 134/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7143\n",
      "Epoch 135/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7143\n",
      "Epoch 136/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7143\n",
      "Epoch 137/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7143\n",
      "Epoch 138/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7143\n",
      "Epoch 139/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7143\n",
      "Epoch 140/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7143\n",
      "Epoch 141/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7143\n",
      "Epoch 142/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7143\n",
      "Epoch 143/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7143\n",
      "Epoch 144/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7143\n",
      "Epoch 145/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7143\n",
      "Epoch 146/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7143\n",
      "Epoch 147/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7143\n",
      "Epoch 148/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7143\n",
      "Epoch 149/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7143\n",
      "Epoch 150/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7143\n",
      "Epoch 151/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7143\n",
      "Epoch 152/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7143\n",
      "Epoch 153/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7143\n",
      "Epoch 154/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7143\n",
      "Epoch 155/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7143\n",
      "Epoch 156/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7143\n",
      "Epoch 157/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7143\n",
      "Epoch 158/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7143\n",
      "Epoch 159/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7143\n",
      "Epoch 160/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7143\n",
      "Epoch 161/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7143\n",
      "Epoch 162/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7143\n",
      "Epoch 163/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7143\n",
      "Epoch 164/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7143\n",
      "Epoch 165/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7143\n",
      "Epoch 166/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5579 - accuracy: 0.7143\n",
      "Epoch 167/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7143\n",
      "Epoch 168/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7143\n",
      "Epoch 169/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7143\n",
      "Epoch 170/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7143\n",
      "Epoch 171/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7143\n",
      "Epoch 172/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7143\n",
      "Epoch 173/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7143\n",
      "Epoch 174/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7143\n",
      "Epoch 175/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7143\n",
      "Epoch 176/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7143\n",
      "Epoch 177/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7143\n",
      "Epoch 178/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7143\n",
      "Epoch 179/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7143\n",
      "Epoch 180/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7143\n",
      "Epoch 181/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5571 - accuracy: 0.7143\n",
      "Epoch 182/2500\n",
      "1/1 [==============================] - 0s 986us/step - loss: 0.5570 - accuracy: 0.7143\n",
      "Epoch 183/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5569 - accuracy: 0.7143\n",
      "Epoch 184/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7143\n",
      "Epoch 185/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7143\n",
      "Epoch 186/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7143\n",
      "Epoch 187/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7143\n",
      "Epoch 188/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7143\n",
      "Epoch 189/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7143\n",
      "Epoch 190/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7143\n",
      "Epoch 191/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7143\n",
      "Epoch 192/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7143\n",
      "Epoch 193/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7143\n",
      "Epoch 194/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7143\n",
      "Epoch 195/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7143\n",
      "Epoch 196/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7143\n",
      "Epoch 197/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7143\n",
      "Epoch 198/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7143\n",
      "Epoch 199/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7143\n",
      "Epoch 200/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7143\n",
      "Epoch 201/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7143\n",
      "Epoch 202/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7143\n",
      "Epoch 203/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7143\n",
      "Epoch 204/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7143\n",
      "Epoch 205/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7143\n",
      "Epoch 206/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7143\n",
      "Epoch 207/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7143\n",
      "Epoch 208/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5556 - accuracy: 0.7143\n",
      "Epoch 209/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7143\n",
      "Epoch 210/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7143\n",
      "Epoch 211/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7143\n",
      "Epoch 212/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7143\n",
      "Epoch 213/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7143\n",
      "Epoch 214/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7143\n",
      "Epoch 215/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5552 - accuracy: 0.7143\n",
      "Epoch 216/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7143\n",
      "Epoch 217/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7143\n",
      "Epoch 218/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7143\n",
      "Epoch 219/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7143\n",
      "Epoch 220/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7143\n",
      "Epoch 221/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7143\n",
      "Epoch 222/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7143\n",
      "Epoch 223/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7143\n",
      "Epoch 224/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7143\n",
      "Epoch 225/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7143\n",
      "Epoch 226/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7143\n",
      "Epoch 227/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7143\n",
      "Epoch 228/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7143\n",
      "Epoch 229/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7143\n",
      "Epoch 230/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7143\n",
      "Epoch 231/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7143\n",
      "Epoch 232/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7143\n",
      "Epoch 233/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7143\n",
      "Epoch 234/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7143\n",
      "Epoch 235/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7143\n",
      "Epoch 236/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7143\n",
      "Epoch 237/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7143\n",
      "Epoch 238/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7143\n",
      "Epoch 239/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7143\n",
      "Epoch 240/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7143\n",
      "Epoch 241/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7143\n",
      "Epoch 242/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7143\n",
      "Epoch 243/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5538 - accuracy: 0.7143\n",
      "Epoch 244/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7143\n",
      "Epoch 245/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7143\n",
      "Epoch 246/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7143\n",
      "Epoch 247/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7143\n",
      "Epoch 248/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7143\n",
      "Epoch 249/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5534 - accuracy: 0.7143\n",
      "Epoch 250/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7143\n",
      "Epoch 251/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7143\n",
      "Epoch 252/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5533 - accuracy: 0.7143\n",
      "Epoch 253/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5532 - accuracy: 0.7143\n",
      "Epoch 254/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7143\n",
      "Epoch 255/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7143\n",
      "Epoch 256/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7143\n",
      "Epoch 257/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5530 - accuracy: 0.7143\n",
      "Epoch 258/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7143\n",
      "Epoch 259/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7143\n",
      "Epoch 260/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7143\n",
      "Epoch 261/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7143\n",
      "Epoch 262/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7143\n",
      "Epoch 263/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7143\n",
      "Epoch 264/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7143\n",
      "Epoch 265/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7143\n",
      "Epoch 266/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7143\n",
      "Epoch 267/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7143\n",
      "Epoch 268/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7143\n",
      "Epoch 269/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7143\n",
      "Epoch 270/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7143\n",
      "Epoch 271/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7143\n",
      "Epoch 272/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7143\n",
      "Epoch 273/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7143\n",
      "Epoch 274/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7143\n",
      "Epoch 275/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7143\n",
      "Epoch 276/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7143\n",
      "Epoch 277/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5520 - accuracy: 0.7143\n",
      "Epoch 278/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7143\n",
      "Epoch 279/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7143\n",
      "Epoch 280/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7143\n",
      "Epoch 281/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7143\n",
      "Epoch 282/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7143\n",
      "Epoch 283/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7143\n",
      "Epoch 284/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7143\n",
      "Epoch 285/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7143\n",
      "Epoch 286/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5515 - accuracy: 0.7143\n",
      "Epoch 287/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7143\n",
      "Epoch 288/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7143\n",
      "Epoch 289/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7143\n",
      "Epoch 290/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7143\n",
      "Epoch 291/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7143\n",
      "Epoch 292/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5512 - accuracy: 0.7143\n",
      "Epoch 293/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7143\n",
      "Epoch 294/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7143\n",
      "Epoch 295/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7143\n",
      "Epoch 296/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7143\n",
      "Epoch 297/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7143\n",
      "Epoch 298/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7143\n",
      "Epoch 299/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7143\n",
      "Epoch 300/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7143\n",
      "Epoch 301/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5507 - accuracy: 0.7143\n",
      "Epoch 302/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7143\n",
      "Epoch 303/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7143\n",
      "Epoch 304/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7143\n",
      "Epoch 305/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7143\n",
      "Epoch 306/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7143\n",
      "Epoch 307/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7143\n",
      "Epoch 308/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7143\n",
      "Epoch 309/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7143\n",
      "Epoch 310/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5502 - accuracy: 0.7143\n",
      "Epoch 311/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7143\n",
      "Epoch 312/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7143\n",
      "Epoch 313/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7143\n",
      "Epoch 314/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7143\n",
      "Epoch 315/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7143\n",
      "Epoch 316/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7143\n",
      "Epoch 317/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7143\n",
      "Epoch 318/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7143\n",
      "Epoch 319/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7143\n",
      "Epoch 320/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7143\n",
      "Epoch 321/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7143\n",
      "Epoch 322/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7143\n",
      "Epoch 323/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7143\n",
      "Epoch 324/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7143\n",
      "Epoch 325/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7143\n",
      "Epoch 326/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7143\n",
      "Epoch 327/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7143\n",
      "Epoch 328/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7143\n",
      "Epoch 329/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7143\n",
      "Epoch 330/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7143\n",
      "Epoch 331/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7143\n",
      "Epoch 332/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7143\n",
      "Epoch 333/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7143\n",
      "Epoch 334/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7143\n",
      "Epoch 335/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7143\n",
      "Epoch 336/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7143\n",
      "Epoch 337/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7143\n",
      "Epoch 338/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7143\n",
      "Epoch 339/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7143\n",
      "Epoch 340/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7143\n",
      "Epoch 341/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7143\n",
      "Epoch 342/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7143\n",
      "Epoch 343/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7143\n",
      "Epoch 344/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7143\n",
      "Epoch 345/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7143\n",
      "Epoch 346/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7143\n",
      "Epoch 347/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7143\n",
      "Epoch 348/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7143\n",
      "Epoch 349/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7143\n",
      "Epoch 350/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7143\n",
      "Epoch 351/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7143\n",
      "Epoch 352/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7143\n",
      "Epoch 353/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5480 - accuracy: 0.7143\n",
      "Epoch 354/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7143\n",
      "Epoch 355/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7143\n",
      "Epoch 356/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7143\n",
      "Epoch 357/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7143\n",
      "Epoch 358/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5477 - accuracy: 0.7143\n",
      "Epoch 359/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7143\n",
      "Epoch 360/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7143\n",
      "Epoch 361/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7143\n",
      "Epoch 362/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7143\n",
      "Epoch 363/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7143\n",
      "Epoch 364/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7143\n",
      "Epoch 365/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7143\n",
      "Epoch 366/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5473 - accuracy: 0.7143\n",
      "Epoch 367/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5473 - accuracy: 0.7143\n",
      "Epoch 368/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7143\n",
      "Epoch 369/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7143\n",
      "Epoch 370/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7143\n",
      "Epoch 371/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7143\n",
      "Epoch 372/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7143\n",
      "Epoch 373/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7143\n",
      "Epoch 374/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7143\n",
      "Epoch 375/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7143\n",
      "Epoch 376/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7143\n",
      "Epoch 377/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7143\n",
      "Epoch 378/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7143\n",
      "Epoch 379/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7143\n",
      "Epoch 380/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7143\n",
      "Epoch 381/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7143\n",
      "Epoch 382/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7143\n",
      "Epoch 383/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7143\n",
      "Epoch 384/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7143\n",
      "Epoch 385/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7143\n",
      "Epoch 386/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7143\n",
      "Epoch 387/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7143\n",
      "Epoch 388/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7143\n",
      "Epoch 389/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7143\n",
      "Epoch 390/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7143\n",
      "Epoch 391/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7143\n",
      "Epoch 392/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7143\n",
      "Epoch 393/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7143\n",
      "Epoch 394/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7143\n",
      "Epoch 395/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7143\n",
      "Epoch 396/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7143\n",
      "Epoch 397/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7143\n",
      "Epoch 398/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5457 - accuracy: 0.7143\n",
      "Epoch 399/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5456 - accuracy: 0.7143\n",
      "Epoch 400/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7143\n",
      "Epoch 401/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7143\n",
      "Epoch 402/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7143\n",
      "Epoch 403/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7143\n",
      "Epoch 404/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7143\n",
      "Epoch 405/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7143\n",
      "Epoch 406/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7143\n",
      "Epoch 407/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5452 - accuracy: 0.7857\n",
      "Epoch 408/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7857\n",
      "Epoch 409/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7857\n",
      "Epoch 410/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7857\n",
      "Epoch 411/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7857\n",
      "Epoch 412/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7857\n",
      "Epoch 413/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7857\n",
      "Epoch 414/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7857\n",
      "Epoch 415/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7857\n",
      "Epoch 416/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7857\n",
      "Epoch 417/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7857\n",
      "Epoch 418/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7857\n",
      "Epoch 419/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7857\n",
      "Epoch 420/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5446 - accuracy: 0.7857\n",
      "Epoch 421/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7857\n",
      "Epoch 422/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7857\n",
      "Epoch 423/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7857\n",
      "Epoch 424/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7857\n",
      "Epoch 425/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7857\n",
      "Epoch 426/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7857\n",
      "Epoch 427/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7857\n",
      "Epoch 428/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7857\n",
      "Epoch 429/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5441 - accuracy: 0.7857\n",
      "Epoch 430/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7857\n",
      "Epoch 431/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7857\n",
      "Epoch 432/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7857\n",
      "Epoch 433/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7857\n",
      "Epoch 434/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7857\n",
      "Epoch 435/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7857\n",
      "Epoch 436/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7857\n",
      "Epoch 437/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5437 - accuracy: 0.7857\n",
      "Epoch 438/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7857\n",
      "Epoch 439/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7857\n",
      "Epoch 440/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7857\n",
      "Epoch 441/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7857\n",
      "Epoch 442/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7857\n",
      "Epoch 443/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7857\n",
      "Epoch 444/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7857\n",
      "Epoch 445/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7857\n",
      "Epoch 446/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7857\n",
      "Epoch 447/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7857\n",
      "Epoch 448/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7857\n",
      "Epoch 449/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7857\n",
      "Epoch 450/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7857\n",
      "Epoch 451/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7857\n",
      "Epoch 452/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7857\n",
      "Epoch 453/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7857\n",
      "Epoch 454/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7857\n",
      "Epoch 455/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7857\n",
      "Epoch 456/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7857\n",
      "Epoch 457/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7857\n",
      "Epoch 458/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7857\n",
      "Epoch 459/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7857\n",
      "Epoch 460/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7857\n",
      "Epoch 461/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7857\n",
      "Epoch 462/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7857\n",
      "Epoch 463/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7857\n",
      "Epoch 464/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7857\n",
      "Epoch 465/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7857\n",
      "Epoch 466/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7857\n",
      "Epoch 467/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7857\n",
      "Epoch 468/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7857\n",
      "Epoch 469/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7857\n",
      "Epoch 470/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7857\n",
      "Epoch 471/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7857\n",
      "Epoch 472/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7857\n",
      "Epoch 473/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7857\n",
      "Epoch 474/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5418 - accuracy: 0.7857\n",
      "Epoch 475/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7857\n",
      "Epoch 476/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7857\n",
      "Epoch 477/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7857\n",
      "Epoch 478/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7857\n",
      "Epoch 479/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7857\n",
      "Epoch 480/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7857\n",
      "Epoch 481/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7857\n",
      "Epoch 482/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7857\n",
      "Epoch 483/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7857\n",
      "Epoch 484/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7857\n",
      "Epoch 485/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7857\n",
      "Epoch 486/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7857\n",
      "Epoch 487/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7857\n",
      "Epoch 488/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7857\n",
      "Epoch 489/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7857\n",
      "Epoch 490/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7857\n",
      "Epoch 491/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7857\n",
      "Epoch 492/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7857\n",
      "Epoch 493/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7857\n",
      "Epoch 494/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7857\n",
      "Epoch 495/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7857\n",
      "Epoch 496/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7857\n",
      "Epoch 497/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7857\n",
      "Epoch 498/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7857\n",
      "Epoch 499/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7857\n",
      "Epoch 500/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7857\n",
      "Epoch 501/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7857\n",
      "Epoch 502/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7857\n",
      "Epoch 503/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7857\n",
      "Epoch 504/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7857\n",
      "Epoch 505/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7857\n",
      "Epoch 506/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7857\n",
      "Epoch 507/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7857\n",
      "Epoch 508/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7857\n",
      "Epoch 509/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7857\n",
      "Epoch 510/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7857\n",
      "Epoch 511/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7857\n",
      "Epoch 512/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7857\n",
      "Epoch 513/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7857\n",
      "Epoch 514/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7857\n",
      "Epoch 515/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7857\n",
      "Epoch 516/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7857\n",
      "Epoch 517/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7857\n",
      "Epoch 518/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7857\n",
      "Epoch 519/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7857\n",
      "Epoch 520/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5395 - accuracy: 0.7857\n",
      "Epoch 521/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7857\n",
      "Epoch 522/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7857\n",
      "Epoch 523/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7857\n",
      "Epoch 524/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5393 - accuracy: 0.7857\n",
      "Epoch 525/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7857\n",
      "Epoch 526/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7857\n",
      "Epoch 527/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7857\n",
      "Epoch 528/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7857\n",
      "Epoch 529/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7857\n",
      "Epoch 530/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7857\n",
      "Epoch 531/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7857\n",
      "Epoch 532/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7857\n",
      "Epoch 533/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7857\n",
      "Epoch 534/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7857\n",
      "Epoch 535/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7857\n",
      "Epoch 536/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7857\n",
      "Epoch 537/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7857\n",
      "Epoch 538/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7857\n",
      "Epoch 539/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7857\n",
      "Epoch 540/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7857\n",
      "Epoch 541/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7857\n",
      "Epoch 542/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7857\n",
      "Epoch 543/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7857\n",
      "Epoch 544/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7857\n",
      "Epoch 545/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7857\n",
      "Epoch 546/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7857\n",
      "Epoch 547/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7857\n",
      "Epoch 548/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7857\n",
      "Epoch 549/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7857\n",
      "Epoch 550/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7857\n",
      "Epoch 551/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7857\n",
      "Epoch 552/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7857\n",
      "Epoch 553/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7857\n",
      "Epoch 554/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7857\n",
      "Epoch 555/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7857\n",
      "Epoch 556/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7857\n",
      "Epoch 557/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7857\n",
      "Epoch 558/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7857\n",
      "Epoch 559/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7857\n",
      "Epoch 560/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7857\n",
      "Epoch 561/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7857\n",
      "Epoch 562/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7857\n",
      "Epoch 563/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7857\n",
      "Epoch 564/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7857\n",
      "Epoch 565/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5373 - accuracy: 0.7857\n",
      "Epoch 566/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7857\n",
      "Epoch 567/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7857\n",
      "Epoch 568/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7857\n",
      "Epoch 569/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7857\n",
      "Epoch 570/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7857\n",
      "Epoch 571/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7857\n",
      "Epoch 572/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7857\n",
      "Epoch 573/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7857\n",
      "Epoch 574/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7857\n",
      "Epoch 575/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7857\n",
      "Epoch 576/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7857\n",
      "Epoch 577/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7857\n",
      "Epoch 578/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7857\n",
      "Epoch 579/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7857\n",
      "Epoch 580/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7857\n",
      "Epoch 581/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7857\n",
      "Epoch 582/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7857\n",
      "Epoch 583/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7857\n",
      "Epoch 584/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7857\n",
      "Epoch 585/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7857\n",
      "Epoch 586/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7857\n",
      "Epoch 587/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7857\n",
      "Epoch 588/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5361 - accuracy: 0.7857\n",
      "Epoch 589/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7857\n",
      "Epoch 590/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7857\n",
      "Epoch 591/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7857\n",
      "Epoch 592/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7857\n",
      "Epoch 593/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7857\n",
      "Epoch 594/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7857\n",
      "Epoch 595/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7857\n",
      "Epoch 596/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7857\n",
      "Epoch 597/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7857\n",
      "Epoch 598/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7857\n",
      "Epoch 599/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7857\n",
      "Epoch 600/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7857\n",
      "Epoch 601/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7857\n",
      "Epoch 602/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7857\n",
      "Epoch 603/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7857\n",
      "Epoch 604/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7857\n",
      "Epoch 605/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7857\n",
      "Epoch 606/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7857\n",
      "Epoch 607/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7857\n",
      "Epoch 608/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7857\n",
      "Epoch 609/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7857\n",
      "Epoch 610/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7857\n",
      "Epoch 611/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7857\n",
      "Epoch 612/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7857\n",
      "Epoch 613/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7857\n",
      "Epoch 614/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7857\n",
      "Epoch 615/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7857\n",
      "Epoch 616/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7857\n",
      "Epoch 617/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7857\n",
      "Epoch 618/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7857\n",
      "Epoch 619/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7857\n",
      "Epoch 620/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7857\n",
      "Epoch 621/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7857\n",
      "Epoch 622/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7857\n",
      "Epoch 623/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7857\n",
      "Epoch 624/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7857\n",
      "Epoch 625/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7857\n",
      "Epoch 626/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7857\n",
      "Epoch 627/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7857\n",
      "Epoch 628/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7857\n",
      "Epoch 629/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7857\n",
      "Epoch 630/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7857\n",
      "Epoch 631/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7857\n",
      "Epoch 632/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7857\n",
      "Epoch 633/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7857\n",
      "Epoch 634/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7857\n",
      "Epoch 635/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7857\n",
      "Epoch 636/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7857\n",
      "Epoch 637/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5337 - accuracy: 0.7857\n",
      "Epoch 638/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5337 - accuracy: 0.7857\n",
      "Epoch 639/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7857\n",
      "Epoch 640/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7857\n",
      "Epoch 641/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7857\n",
      "Epoch 642/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7857\n",
      "Epoch 643/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7857\n",
      "Epoch 644/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7857\n",
      "Epoch 645/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7857\n",
      "Epoch 646/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7857\n",
      "Epoch 647/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7857\n",
      "Epoch 648/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7857\n",
      "Epoch 649/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7857\n",
      "Epoch 650/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5331 - accuracy: 0.7857\n",
      "Epoch 651/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7857\n",
      "Epoch 652/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7857\n",
      "Epoch 653/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7857\n",
      "Epoch 654/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7857\n",
      "Epoch 655/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7857\n",
      "Epoch 656/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7857\n",
      "Epoch 657/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7857\n",
      "Epoch 658/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7857\n",
      "Epoch 659/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7857\n",
      "Epoch 660/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7857\n",
      "Epoch 661/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7857\n",
      "Epoch 662/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7857\n",
      "Epoch 663/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7857\n",
      "Epoch 664/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7857\n",
      "Epoch 665/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7857\n",
      "Epoch 666/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7857\n",
      "Epoch 667/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7857\n",
      "Epoch 668/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7857\n",
      "Epoch 669/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5322 - accuracy: 0.7857\n",
      "Epoch 670/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7857\n",
      "Epoch 671/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7857\n",
      "Epoch 672/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7857\n",
      "Epoch 673/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7857\n",
      "Epoch 674/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7857\n",
      "Epoch 675/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7857\n",
      "Epoch 676/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7857\n",
      "Epoch 677/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7857\n",
      "Epoch 678/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7857\n",
      "Epoch 679/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5317 - accuracy: 0.7857\n",
      "Epoch 680/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5317 - accuracy: 0.7857\n",
      "Epoch 681/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7857\n",
      "Epoch 682/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7857\n",
      "Epoch 683/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7857\n",
      "Epoch 684/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7857\n",
      "Epoch 685/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7857\n",
      "Epoch 686/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7857\n",
      "Epoch 687/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7857\n",
      "Epoch 688/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7857\n",
      "Epoch 689/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7857\n",
      "Epoch 690/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7857\n",
      "Epoch 691/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7857\n",
      "Epoch 692/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7857\n",
      "Epoch 693/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7857\n",
      "Epoch 694/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5310 - accuracy: 0.7857\n",
      "Epoch 695/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7857\n",
      "Epoch 696/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7857\n",
      "Epoch 697/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7857\n",
      "Epoch 698/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7857\n",
      "Epoch 699/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7857\n",
      "Epoch 700/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7857\n",
      "Epoch 701/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7857\n",
      "Epoch 702/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7857\n",
      "Epoch 703/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7857\n",
      "Epoch 704/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7857\n",
      "Epoch 705/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7857\n",
      "Epoch 706/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7857\n",
      "Epoch 707/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7857\n",
      "Epoch 708/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7857\n",
      "Epoch 709/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7857\n",
      "Epoch 710/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7857\n",
      "Epoch 711/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7857\n",
      "Epoch 712/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7857\n",
      "Epoch 713/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7857\n",
      "Epoch 714/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7857\n",
      "Epoch 715/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7857\n",
      "Epoch 716/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7857\n",
      "Epoch 717/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7857\n",
      "Epoch 718/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7857\n",
      "Epoch 719/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7857\n",
      "Epoch 720/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7857\n",
      "Epoch 721/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7857\n",
      "Epoch 722/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7857\n",
      "Epoch 723/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5296 - accuracy: 0.7857\n",
      "Epoch 724/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7857\n",
      "Epoch 725/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7857\n",
      "Epoch 726/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7857\n",
      "Epoch 727/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7857\n",
      "Epoch 728/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7857\n",
      "Epoch 729/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7857\n",
      "Epoch 730/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7857\n",
      "Epoch 731/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7857\n",
      "Epoch 732/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7857\n",
      "Epoch 733/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7857\n",
      "Epoch 734/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7857\n",
      "Epoch 735/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7857\n",
      "Epoch 736/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7857\n",
      "Epoch 737/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7857\n",
      "Epoch 738/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7857\n",
      "Epoch 739/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7857\n",
      "Epoch 740/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7857\n",
      "Epoch 741/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7857\n",
      "Epoch 742/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7857\n",
      "Epoch 743/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7857\n",
      "Epoch 744/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7857\n",
      "Epoch 745/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7857\n",
      "Epoch 746/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7857\n",
      "Epoch 747/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7857\n",
      "Epoch 748/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.8214\n",
      "Epoch 749/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.8214\n",
      "Epoch 750/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8214\n",
      "Epoch 751/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8214\n",
      "Epoch 752/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8214\n",
      "Epoch 753/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8214\n",
      "Epoch 754/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8214\n",
      "Epoch 755/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8214\n",
      "Epoch 756/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8214\n",
      "Epoch 757/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8214\n",
      "Epoch 758/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.8214\n",
      "Epoch 759/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.8214\n",
      "Epoch 760/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.8214\n",
      "Epoch 761/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.8214\n",
      "Epoch 762/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8214\n",
      "Epoch 763/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8214\n",
      "Epoch 764/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5276 - accuracy: 0.8214\n",
      "Epoch 765/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8214\n",
      "Epoch 766/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8214\n",
      "Epoch 767/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8214\n",
      "Epoch 768/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8214\n",
      "Epoch 769/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.8214\n",
      "Epoch 770/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.8214\n",
      "Epoch 771/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8214\n",
      "Epoch 772/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8214\n",
      "Epoch 773/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8214\n",
      "Epoch 774/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8214\n",
      "Epoch 775/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8214\n",
      "Epoch 776/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8214\n",
      "Epoch 777/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8214\n",
      "Epoch 778/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8214\n",
      "Epoch 779/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8214\n",
      "Epoch 780/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8214\n",
      "Epoch 781/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.8214\n",
      "Epoch 782/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.8214\n",
      "Epoch 783/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8214\n",
      "Epoch 784/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8214\n",
      "Epoch 785/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.8214\n",
      "Epoch 786/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5266 - accuracy: 0.8214\n",
      "Epoch 787/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8214\n",
      "Epoch 788/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8214\n",
      "Epoch 789/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8214\n",
      "Epoch 790/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8214\n",
      "Epoch 791/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8214\n",
      "Epoch 792/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.8214\n",
      "Epoch 793/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.8214\n",
      "Epoch 794/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8214\n",
      "Epoch 795/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8214\n",
      "Epoch 796/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.8214\n",
      "Epoch 797/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.8214\n",
      "Epoch 798/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.8214\n",
      "Epoch 799/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.8214\n",
      "Epoch 800/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.8214\n",
      "Epoch 801/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.8214\n",
      "Epoch 802/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5259 - accuracy: 0.8214\n",
      "Epoch 803/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8214\n",
      "Epoch 804/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8214\n",
      "Epoch 805/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8214\n",
      "Epoch 806/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8214\n",
      "Epoch 807/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8214\n",
      "Epoch 808/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8214\n",
      "Epoch 809/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8214\n",
      "Epoch 810/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8214\n",
      "Epoch 811/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8214\n",
      "Epoch 812/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.8214\n",
      "Epoch 813/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8214\n",
      "Epoch 814/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8214\n",
      "Epoch 815/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8214\n",
      "Epoch 816/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.8214\n",
      "Epoch 817/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8214\n",
      "Epoch 818/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8214\n",
      "Epoch 819/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8214\n",
      "Epoch 820/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.8214\n",
      "Epoch 821/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.8214\n",
      "Epoch 822/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8214\n",
      "Epoch 823/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8214\n",
      "Epoch 824/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8214\n",
      "Epoch 825/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8214\n",
      "Epoch 826/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8214\n",
      "Epoch 827/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8214\n",
      "Epoch 828/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8214\n",
      "Epoch 829/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8214\n",
      "Epoch 830/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.8214\n",
      "Epoch 831/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8214\n",
      "Epoch 832/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8214\n",
      "Epoch 833/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8214\n",
      "Epoch 834/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8214\n",
      "Epoch 835/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.8214\n",
      "Epoch 836/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.8214\n",
      "Epoch 837/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.8214\n",
      "Epoch 838/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.8214\n",
      "Epoch 839/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.8214\n",
      "Epoch 840/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.8214\n",
      "Epoch 841/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8214\n",
      "Epoch 842/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8214\n",
      "Epoch 843/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8214\n",
      "Epoch 844/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8214\n",
      "Epoch 845/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5238 - accuracy: 0.8214\n",
      "Epoch 846/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.8214\n",
      "Epoch 847/2500\n",
      "1/1 [==============================] - 0s 972us/step - loss: 0.5238 - accuracy: 0.8214\n",
      "Epoch 848/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8214\n",
      "Epoch 849/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8214\n",
      "Epoch 850/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.8214\n",
      "Epoch 851/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.8214\n",
      "Epoch 852/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.8214\n",
      "Epoch 853/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.8214\n",
      "Epoch 854/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.8214\n",
      "Epoch 855/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.8214\n",
      "Epoch 856/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8214\n",
      "Epoch 857/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8214\n",
      "Epoch 858/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8214\n",
      "Epoch 859/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8214\n",
      "Epoch 860/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8214\n",
      "Epoch 861/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.8214\n",
      "Epoch 862/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.8214\n",
      "Epoch 863/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8214\n",
      "Epoch 864/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8214\n",
      "Epoch 865/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8214\n",
      "Epoch 866/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8214\n",
      "Epoch 867/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8214\n",
      "Epoch 868/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8214\n",
      "Epoch 869/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8214\n",
      "Epoch 870/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8214\n",
      "Epoch 871/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.8214\n",
      "Epoch 872/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.8214\n",
      "Epoch 873/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5226 - accuracy: 0.8214\n",
      "Epoch 874/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8214\n",
      "Epoch 875/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8214\n",
      "Epoch 876/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.8214\n",
      "Epoch 877/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.8214\n",
      "Epoch 878/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8214\n",
      "Epoch 879/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8214\n",
      "Epoch 880/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.8214\n",
      "Epoch 881/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8214\n",
      "Epoch 882/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8214\n",
      "Epoch 883/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8214\n",
      "Epoch 884/2500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5220 - accuracy: 0.8214\n",
      "Epoch 885/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.8214\n",
      "Epoch 886/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.8214\n",
      "Epoch 887/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8214\n",
      "Epoch 888/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8214\n",
      "Epoch 889/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.8571\n",
      "Epoch 890/2500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5218 - accuracy: 0.8571\n",
      "Epoch 891/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8571\n",
      "Epoch 892/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.8571\n",
      "Epoch 893/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.8571\n",
      "Epoch 894/2500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5216 - accuracy: 0.8571\n",
      "Epoch 895/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5215 - accuracy: 0.8571\n",
      "Epoch 896/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.8571\n",
      "Epoch 897/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.8571\n",
      "Epoch 898/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.8571\n",
      "Epoch 899/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.8571\n",
      "Epoch 900/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.8571\n",
      "Epoch 901/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8571\n",
      "Epoch 902/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8571\n",
      "Epoch 903/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.8571\n",
      "Epoch 904/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8571\n",
      "Epoch 905/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.8571\n",
      "Epoch 906/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8571\n",
      "Epoch 907/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.8571\n",
      "Epoch 908/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8571\n",
      "Epoch 909/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8571\n",
      "Epoch 910/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8571\n",
      "Epoch 911/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8571\n",
      "Epoch 912/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8571\n",
      "Epoch 913/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.8571\n",
      "Epoch 914/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.8571\n",
      "Epoch 915/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8571\n",
      "Epoch 916/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8571\n",
      "Epoch 917/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5205 - accuracy: 0.8571\n",
      "Epoch 918/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.8571\n",
      "Epoch 919/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8571\n",
      "Epoch 920/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8571\n",
      "Epoch 921/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8571\n",
      "Epoch 922/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8571\n",
      "Epoch 923/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8571\n",
      "Epoch 924/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.8571\n",
      "Epoch 925/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5202 - accuracy: 0.8571\n",
      "Epoch 926/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8571\n",
      "Epoch 927/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8571\n",
      "Epoch 928/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.8571\n",
      "Epoch 929/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.8571\n",
      "Epoch 930/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8571\n",
      "Epoch 931/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8571\n",
      "Epoch 932/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8571\n",
      "Epoch 933/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.8571\n",
      "Epoch 934/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.8571\n",
      "Epoch 935/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8571\n",
      "Epoch 936/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8571\n",
      "Epoch 937/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8571\n",
      "Epoch 938/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.8571\n",
      "Epoch 939/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.8571\n",
      "Epoch 940/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8571\n",
      "Epoch 941/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.8571\n",
      "Epoch 942/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8571\n",
      "Epoch 943/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8571\n",
      "Epoch 944/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8571\n",
      "Epoch 945/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8571\n",
      "Epoch 946/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8571\n",
      "Epoch 947/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8571\n",
      "Epoch 948/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8571\n",
      "Epoch 949/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8571\n",
      "Epoch 950/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.8571\n",
      "Epoch 951/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.8571\n",
      "Epoch 952/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5189 - accuracy: 0.8571\n",
      "Epoch 953/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8571\n",
      "Epoch 954/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8571\n",
      "Epoch 955/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.8571\n",
      "Epoch 956/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8571\n",
      "Epoch 957/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8571\n",
      "Epoch 958/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8571\n",
      "Epoch 959/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8571\n",
      "Epoch 960/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8571\n",
      "Epoch 961/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8571\n",
      "Epoch 962/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8571\n",
      "Epoch 963/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8571\n",
      "Epoch 964/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8571\n",
      "Epoch 965/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5184 - accuracy: 0.8571\n",
      "Epoch 966/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8571\n",
      "Epoch 967/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8571\n",
      "Epoch 968/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8571\n",
      "Epoch 969/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8571\n",
      "Epoch 970/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8571\n",
      "Epoch 971/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.8571\n",
      "Epoch 972/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8571\n",
      "Epoch 973/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8571\n",
      "Epoch 974/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8571\n",
      "Epoch 975/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5179 - accuracy: 0.8571\n",
      "Epoch 976/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.8571\n",
      "Epoch 977/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8571\n",
      "Epoch 978/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8571\n",
      "Epoch 979/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8571\n",
      "Epoch 980/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8571\n",
      "Epoch 981/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5176 - accuracy: 0.8571\n",
      "Epoch 982/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8571\n",
      "Epoch 983/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8571\n",
      "Epoch 984/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8571\n",
      "Epoch 985/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8571\n",
      "Epoch 986/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8571\n",
      "Epoch 987/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8571\n",
      "Epoch 988/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8571\n",
      "Epoch 989/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8571\n",
      "Epoch 990/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8571\n",
      "Epoch 991/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8571\n",
      "Epoch 992/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8571\n",
      "Epoch 993/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8571\n",
      "Epoch 994/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8571\n",
      "Epoch 995/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8571\n",
      "Epoch 996/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8571\n",
      "Epoch 997/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.8571\n",
      "Epoch 998/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8571\n",
      "Epoch 999/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.8571\n",
      "Epoch 1000/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.8571\n",
      "Epoch 1001/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8571\n",
      "Epoch 1002/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8571\n",
      "Epoch 1003/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8571\n",
      "Epoch 1004/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8571\n",
      "Epoch 1005/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8571\n",
      "Epoch 1006/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8571\n",
      "Epoch 1007/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8571\n",
      "Epoch 1008/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8571\n",
      "Epoch 1009/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8571\n",
      "Epoch 1010/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.8571\n",
      "Epoch 1011/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5163 - accuracy: 0.8571\n",
      "Epoch 1012/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.8571\n",
      "Epoch 1013/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.8571\n",
      "Epoch 1014/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.8571\n",
      "Epoch 1015/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.8571\n",
      "Epoch 1016/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5161 - accuracy: 0.8571\n",
      "Epoch 1017/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.8571\n",
      "Epoch 1018/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.8571\n",
      "Epoch 1019/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 1020/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 1021/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 1022/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.8571\n",
      "Epoch 1023/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.8571\n",
      "Epoch 1024/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8571\n",
      "Epoch 1025/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5157 - accuracy: 0.8571\n",
      "Epoch 1026/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5156 - accuracy: 0.8571\n",
      "Epoch 1027/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8571\n",
      "Epoch 1028/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8571\n",
      "Epoch 1029/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.8571\n",
      "Epoch 1030/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5155 - accuracy: 0.8571\n",
      "Epoch 1031/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8571\n",
      "Epoch 1032/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8571\n",
      "Epoch 1033/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8571\n",
      "Epoch 1034/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8571\n",
      "Epoch 1035/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8571\n",
      "Epoch 1036/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8571\n",
      "Epoch 1037/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8571\n",
      "Epoch 1038/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8571\n",
      "Epoch 1039/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8571\n",
      "Epoch 1040/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8571\n",
      "Epoch 1041/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8571\n",
      "Epoch 1042/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8571\n",
      "Epoch 1043/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8571\n",
      "Epoch 1044/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.8571\n",
      "Epoch 1045/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5148 - accuracy: 0.8571\n",
      "Epoch 1046/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5147 - accuracy: 0.8571\n",
      "Epoch 1047/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8571\n",
      "Epoch 1048/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8929\n",
      "Epoch 1049/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8929\n",
      "Epoch 1050/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8929\n",
      "Epoch 1051/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8929\n",
      "Epoch 1052/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8929\n",
      "Epoch 1053/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8929\n",
      "Epoch 1054/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8929\n",
      "Epoch 1055/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8929\n",
      "Epoch 1056/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8929\n",
      "Epoch 1057/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8929\n",
      "Epoch 1058/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.8929\n",
      "Epoch 1059/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.8929\n",
      "Epoch 1060/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8929\n",
      "Epoch 1061/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8929\n",
      "Epoch 1062/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8929\n",
      "Epoch 1063/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8929\n",
      "Epoch 1064/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8929\n",
      "Epoch 1065/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8929\n",
      "Epoch 1066/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.8929\n",
      "Epoch 1067/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8929\n",
      "Epoch 1068/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8929\n",
      "Epoch 1069/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8929\n",
      "Epoch 1070/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8929\n",
      "Epoch 1071/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.8929\n",
      "Epoch 1072/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8929\n",
      "Epoch 1073/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8929\n",
      "Epoch 1074/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8929\n",
      "Epoch 1075/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8929\n",
      "Epoch 1076/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8929\n",
      "Epoch 1077/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8929\n",
      "Epoch 1078/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8929\n",
      "Epoch 1079/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5133 - accuracy: 0.8929\n",
      "Epoch 1080/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8929\n",
      "Epoch 1081/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8929\n",
      "Epoch 1082/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8929\n",
      "Epoch 1083/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.8929\n",
      "Epoch 1084/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8929\n",
      "Epoch 1085/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8929\n",
      "Epoch 1086/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8929\n",
      "Epoch 1087/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8929\n",
      "Epoch 1088/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8929\n",
      "Epoch 1089/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8929\n",
      "Epoch 1090/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8929\n",
      "Epoch 1091/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8929\n",
      "Epoch 1092/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.8929\n",
      "Epoch 1093/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.8929\n",
      "Epoch 1094/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8929\n",
      "Epoch 1095/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8929\n",
      "Epoch 1096/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.8929\n",
      "Epoch 1097/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8929\n",
      "Epoch 1098/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8929\n",
      "Epoch 1099/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8929\n",
      "Epoch 1100/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8929\n",
      "Epoch 1101/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8929\n",
      "Epoch 1102/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.8929\n",
      "Epoch 1103/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8929\n",
      "Epoch 1104/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8929\n",
      "Epoch 1105/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8929\n",
      "Epoch 1106/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8929\n",
      "Epoch 1107/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8929\n",
      "Epoch 1108/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8929\n",
      "Epoch 1109/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8929\n",
      "Epoch 1110/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8929\n",
      "Epoch 1111/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5119 - accuracy: 0.8929\n",
      "Epoch 1112/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8929\n",
      "Epoch 1113/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8929\n",
      "Epoch 1114/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8929\n",
      "Epoch 1115/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8929\n",
      "Epoch 1116/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8929\n",
      "Epoch 1117/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8929\n",
      "Epoch 1118/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.8929\n",
      "Epoch 1119/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8929\n",
      "Epoch 1120/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8929\n",
      "Epoch 1121/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8929\n",
      "Epoch 1122/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8929\n",
      "Epoch 1123/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8929\n",
      "Epoch 1124/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.8929\n",
      "Epoch 1125/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8929\n",
      "Epoch 1126/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.8929\n",
      "Epoch 1127/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8929\n",
      "Epoch 1128/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8929\n",
      "Epoch 1129/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8929\n",
      "Epoch 1130/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8929\n",
      "Epoch 1131/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8929\n",
      "Epoch 1132/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8929\n",
      "Epoch 1133/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8929\n",
      "Epoch 1134/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8929\n",
      "Epoch 1135/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.8929\n",
      "Epoch 1136/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8929\n",
      "Epoch 1137/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8929\n",
      "Epoch 1138/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8929\n",
      "Epoch 1139/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.8929\n",
      "Epoch 1140/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8929\n",
      "Epoch 1141/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8929\n",
      "Epoch 1142/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8929\n",
      "Epoch 1143/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8929\n",
      "Epoch 1144/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.8929\n",
      "Epoch 1145/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8929\n",
      "Epoch 1146/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8929\n",
      "Epoch 1147/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8929\n",
      "Epoch 1148/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5103 - accuracy: 0.8929\n",
      "Epoch 1149/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8929\n",
      "Epoch 1150/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.8929\n",
      "Epoch 1151/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8929\n",
      "Epoch 1152/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8929\n",
      "Epoch 1153/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8929\n",
      "Epoch 1154/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8929\n",
      "Epoch 1155/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8929\n",
      "Epoch 1156/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8929\n",
      "Epoch 1157/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8929\n",
      "Epoch 1158/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8929\n",
      "Epoch 1159/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.8929\n",
      "Epoch 1160/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8929\n",
      "Epoch 1161/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8929\n",
      "Epoch 1162/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8929\n",
      "Epoch 1163/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.8929\n",
      "Epoch 1164/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8929\n",
      "Epoch 1165/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8929\n",
      "Epoch 1166/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8929\n",
      "Epoch 1167/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8929\n",
      "Epoch 1168/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8929\n",
      "Epoch 1169/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8929\n",
      "Epoch 1170/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8929\n",
      "Epoch 1171/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8929\n",
      "Epoch 1172/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8929\n",
      "Epoch 1173/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8929\n",
      "Epoch 1174/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8929\n",
      "Epoch 1175/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8929\n",
      "Epoch 1176/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8929\n",
      "Epoch 1177/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8929\n",
      "Epoch 1178/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8929\n",
      "Epoch 1179/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8929\n",
      "Epoch 1180/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8929\n",
      "Epoch 1181/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8929\n",
      "Epoch 1182/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8929\n",
      "Epoch 1183/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8929\n",
      "Epoch 1184/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8929\n",
      "Epoch 1185/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8929\n",
      "Epoch 1186/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8929\n",
      "Epoch 1187/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8929\n",
      "Epoch 1188/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8929\n",
      "Epoch 1189/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8929\n",
      "Epoch 1190/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8929\n",
      "Epoch 1191/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8929\n",
      "Epoch 1192/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8929\n",
      "Epoch 1193/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5084 - accuracy: 0.8929\n",
      "Epoch 1194/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8929\n",
      "Epoch 1195/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8929\n",
      "Epoch 1196/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8929\n",
      "Epoch 1197/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8929\n",
      "Epoch 1198/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8929\n",
      "Epoch 1199/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8929\n",
      "Epoch 1200/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8929\n",
      "Epoch 1201/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8929\n",
      "Epoch 1202/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8929\n",
      "Epoch 1203/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8929\n",
      "Epoch 1204/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8929\n",
      "Epoch 1205/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8929\n",
      "Epoch 1206/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8929\n",
      "Epoch 1207/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8929\n",
      "Epoch 1208/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8929\n",
      "Epoch 1209/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8929\n",
      "Epoch 1210/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8929\n",
      "Epoch 1211/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8929\n",
      "Epoch 1212/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8929\n",
      "Epoch 1213/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8929\n",
      "Epoch 1214/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8929\n",
      "Epoch 1215/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8929\n",
      "Epoch 1216/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8929\n",
      "Epoch 1217/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8929\n",
      "Epoch 1218/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8929\n",
      "Epoch 1219/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.8929\n",
      "Epoch 1220/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8929\n",
      "Epoch 1221/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8929\n",
      "Epoch 1222/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8929\n",
      "Epoch 1223/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8929\n",
      "Epoch 1224/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8929\n",
      "Epoch 1225/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8929\n",
      "Epoch 1226/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8929\n",
      "Epoch 1227/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8929\n",
      "Epoch 1228/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8929\n",
      "Epoch 1229/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8929\n",
      "Epoch 1230/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8929\n",
      "Epoch 1231/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8929\n",
      "Epoch 1232/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8929\n",
      "Epoch 1233/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8929\n",
      "Epoch 1234/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8929\n",
      "Epoch 1235/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8929\n",
      "Epoch 1236/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8929\n",
      "Epoch 1237/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8929\n",
      "Epoch 1238/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.8929\n",
      "Epoch 1239/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8929\n",
      "Epoch 1240/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.8929\n",
      "Epoch 1241/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8929\n",
      "Epoch 1242/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.8929\n",
      "Epoch 1243/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.8929\n",
      "Epoch 1244/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.8929\n",
      "Epoch 1245/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8929\n",
      "Epoch 1246/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8929\n",
      "Epoch 1247/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.8929\n",
      "Epoch 1248/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8929\n",
      "Epoch 1249/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8929\n",
      "Epoch 1250/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8929\n",
      "Epoch 1251/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8929\n",
      "Epoch 1252/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.8929\n",
      "Epoch 1253/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8929\n",
      "Epoch 1254/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8929\n",
      "Epoch 1255/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8929\n",
      "Epoch 1256/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8929\n",
      "Epoch 1257/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8929\n",
      "Epoch 1258/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8929\n",
      "Epoch 1259/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8929\n",
      "Epoch 1260/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.8929\n",
      "Epoch 1261/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.8929\n",
      "Epoch 1262/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.8929\n",
      "Epoch 1263/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8929\n",
      "Epoch 1264/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8929\n",
      "Epoch 1265/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8929\n",
      "Epoch 1266/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8929\n",
      "Epoch 1267/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8929\n",
      "Epoch 1268/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8929\n",
      "Epoch 1269/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8929\n",
      "Epoch 1270/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.8929\n",
      "Epoch 1271/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8929\n",
      "Epoch 1272/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8929\n",
      "Epoch 1273/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8929\n",
      "Epoch 1274/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8929\n",
      "Epoch 1275/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8929\n",
      "Epoch 1276/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8929\n",
      "Epoch 1277/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8929\n",
      "Epoch 1278/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8929\n",
      "Epoch 1279/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8929\n",
      "Epoch 1280/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8929\n",
      "Epoch 1281/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8929\n",
      "Epoch 1282/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8929\n",
      "Epoch 1283/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8929\n",
      "Epoch 1284/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8929\n",
      "Epoch 1285/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8929\n",
      "Epoch 1286/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8929\n",
      "Epoch 1287/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8929\n",
      "Epoch 1288/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8929\n",
      "Epoch 1289/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8929\n",
      "Epoch 1290/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8929\n",
      "Epoch 1291/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8929\n",
      "Epoch 1292/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8929\n",
      "Epoch 1293/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8929\n",
      "Epoch 1294/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8929\n",
      "Epoch 1295/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8929\n",
      "Epoch 1296/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8929\n",
      "Epoch 1297/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8929\n",
      "Epoch 1298/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8929\n",
      "Epoch 1299/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8929\n",
      "Epoch 1300/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8929\n",
      "Epoch 1301/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8929\n",
      "Epoch 1302/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8929\n",
      "Epoch 1303/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8929\n",
      "Epoch 1304/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8929\n",
      "Epoch 1305/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8929\n",
      "Epoch 1306/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8929\n",
      "Epoch 1307/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8929\n",
      "Epoch 1308/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8929\n",
      "Epoch 1309/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8929\n",
      "Epoch 1310/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8929\n",
      "Epoch 1311/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8929\n",
      "Epoch 1312/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8929\n",
      "Epoch 1313/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8929\n",
      "Epoch 1314/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8929\n",
      "Epoch 1315/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8929\n",
      "Epoch 1316/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8929\n",
      "Epoch 1317/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8929\n",
      "Epoch 1318/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8929\n",
      "Epoch 1319/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8929\n",
      "Epoch 1320/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8929\n",
      "Epoch 1321/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8929\n",
      "Epoch 1322/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8929\n",
      "Epoch 1323/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8929\n",
      "Epoch 1324/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8929\n",
      "Epoch 1325/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8929\n",
      "Epoch 1326/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8929\n",
      "Epoch 1327/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8929\n",
      "Epoch 1328/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8929\n",
      "Epoch 1329/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8929\n",
      "Epoch 1330/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8929\n",
      "Epoch 1331/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8929\n",
      "Epoch 1332/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8929\n",
      "Epoch 1333/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8929\n",
      "Epoch 1334/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8929\n",
      "Epoch 1335/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8929\n",
      "Epoch 1336/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8929\n",
      "Epoch 1337/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8929\n",
      "Epoch 1338/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.8929\n",
      "Epoch 1339/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8929\n",
      "Epoch 1340/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 1341/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 1342/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 1343/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8929\n",
      "Epoch 1344/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8929\n",
      "Epoch 1345/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8929\n",
      "Epoch 1346/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8929\n",
      "Epoch 1347/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8929\n",
      "Epoch 1348/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.8929\n",
      "Epoch 1349/2500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5019 - accuracy: 0.8929\n",
      "Epoch 1350/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5018 - accuracy: 0.8929\n",
      "Epoch 1351/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.8929\n",
      "Epoch 1352/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8929\n",
      "Epoch 1353/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8929\n",
      "Epoch 1354/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8929\n",
      "Epoch 1355/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.8929\n",
      "Epoch 1356/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8929\n",
      "Epoch 1357/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.8929\n",
      "Epoch 1358/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.8929\n",
      "Epoch 1359/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.8929\n",
      "Epoch 1360/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8929\n",
      "Epoch 1361/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8929\n",
      "Epoch 1362/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8929\n",
      "Epoch 1363/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8929\n",
      "Epoch 1364/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8929\n",
      "Epoch 1365/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8929\n",
      "Epoch 1366/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8929\n",
      "Epoch 1367/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8929\n",
      "Epoch 1368/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8929\n",
      "Epoch 1369/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8929\n",
      "Epoch 1370/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8929\n",
      "Epoch 1371/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8929\n",
      "Epoch 1372/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8929\n",
      "Epoch 1373/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8929\n",
      "Epoch 1374/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8929\n",
      "Epoch 1375/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8929\n",
      "Epoch 1376/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8929\n",
      "Epoch 1377/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8929\n",
      "Epoch 1378/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8929\n",
      "Epoch 1379/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8929\n",
      "Epoch 1380/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8929\n",
      "Epoch 1381/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8929\n",
      "Epoch 1382/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8929\n",
      "Epoch 1383/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8929\n",
      "Epoch 1384/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.8929\n",
      "Epoch 1385/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8929\n",
      "Epoch 1386/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8929\n",
      "Epoch 1387/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8929\n",
      "Epoch 1388/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8929\n",
      "Epoch 1389/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8929\n",
      "Epoch 1390/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8929\n",
      "Epoch 1391/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8929\n",
      "Epoch 1392/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8929\n",
      "Epoch 1393/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.8929\n",
      "Epoch 1394/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.8929\n",
      "Epoch 1395/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8929\n",
      "Epoch 1396/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8929\n",
      "Epoch 1397/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8929\n",
      "Epoch 1398/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8929\n",
      "Epoch 1399/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8929\n",
      "Epoch 1400/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4998 - accuracy: 0.8929\n",
      "Epoch 1401/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8929\n",
      "Epoch 1402/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8929\n",
      "Epoch 1403/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8929\n",
      "Epoch 1404/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8929\n",
      "Epoch 1405/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8929\n",
      "Epoch 1406/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.8929\n",
      "Epoch 1407/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8929\n",
      "Epoch 1408/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8929\n",
      "Epoch 1409/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8929\n",
      "Epoch 1410/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8929\n",
      "Epoch 1411/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8929\n",
      "Epoch 1412/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8929\n",
      "Epoch 1413/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8929\n",
      "Epoch 1414/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8929\n",
      "Epoch 1415/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8929\n",
      "Epoch 1416/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8929\n",
      "Epoch 1417/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8929\n",
      "Epoch 1418/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8929\n",
      "Epoch 1419/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8929\n",
      "Epoch 1420/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.8929\n",
      "Epoch 1421/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8929\n",
      "Epoch 1422/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8929\n",
      "Epoch 1423/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8929\n",
      "Epoch 1424/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8929\n",
      "Epoch 1425/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8929\n",
      "Epoch 1426/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8929\n",
      "Epoch 1427/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8929\n",
      "Epoch 1428/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.8929\n",
      "Epoch 1429/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8929\n",
      "Epoch 1430/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8929\n",
      "Epoch 1431/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8929\n",
      "Epoch 1432/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8929\n",
      "Epoch 1433/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8929\n",
      "Epoch 1434/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8929\n",
      "Epoch 1435/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8929\n",
      "Epoch 1436/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8929\n",
      "Epoch 1437/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8929\n",
      "Epoch 1438/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8929\n",
      "Epoch 1439/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8929\n",
      "Epoch 1440/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8929\n",
      "Epoch 1441/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8929\n",
      "Epoch 1442/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8929\n",
      "Epoch 1443/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8929\n",
      "Epoch 1444/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8929\n",
      "Epoch 1445/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8929\n",
      "Epoch 1446/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8929\n",
      "Epoch 1447/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8929\n",
      "Epoch 1448/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8929\n",
      "Epoch 1449/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8929\n",
      "Epoch 1450/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8929\n",
      "Epoch 1451/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8929\n",
      "Epoch 1452/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8929\n",
      "Epoch 1453/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8929\n",
      "Epoch 1454/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8929\n",
      "Epoch 1455/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8929\n",
      "Epoch 1456/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8929\n",
      "Epoch 1457/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8929\n",
      "Epoch 1458/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8929\n",
      "Epoch 1459/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8929\n",
      "Epoch 1460/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8929\n",
      "Epoch 1461/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8929\n",
      "Epoch 1462/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8929\n",
      "Epoch 1463/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8929\n",
      "Epoch 1464/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8929\n",
      "Epoch 1465/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8929\n",
      "Epoch 1466/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8929\n",
      "Epoch 1467/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4971 - accuracy: 0.8929\n",
      "Epoch 1468/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8929\n",
      "Epoch 1469/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8929\n",
      "Epoch 1470/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8929\n",
      "Epoch 1471/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8929\n",
      "Epoch 1472/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8929\n",
      "Epoch 1473/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8929\n",
      "Epoch 1474/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8929\n",
      "Epoch 1475/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8929\n",
      "Epoch 1476/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8929\n",
      "Epoch 1477/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8929\n",
      "Epoch 1478/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8929\n",
      "Epoch 1479/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.8929\n",
      "Epoch 1480/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8929\n",
      "Epoch 1481/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8929\n",
      "Epoch 1482/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8929\n",
      "Epoch 1483/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8929\n",
      "Epoch 1484/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8929\n",
      "Epoch 1485/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8929\n",
      "Epoch 1486/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8929\n",
      "Epoch 1487/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8929\n",
      "Epoch 1488/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4963 - accuracy: 0.8929\n",
      "Epoch 1489/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8929\n",
      "Epoch 1490/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8929\n",
      "Epoch 1491/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8929\n",
      "Epoch 1492/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8929\n",
      "Epoch 1493/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8929\n",
      "Epoch 1494/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4961 - accuracy: 0.8929\n",
      "Epoch 1495/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8929\n",
      "Epoch 1496/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8929\n",
      "Epoch 1497/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8929\n",
      "Epoch 1498/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8929\n",
      "Epoch 1499/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8929\n",
      "Epoch 1500/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8929\n",
      "Epoch 1501/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8929\n",
      "Epoch 1502/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8929\n",
      "Epoch 1503/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8929\n",
      "Epoch 1504/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8929\n",
      "Epoch 1505/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8929\n",
      "Epoch 1506/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8929\n",
      "Epoch 1507/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8929\n",
      "Epoch 1508/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8929\n",
      "Epoch 1509/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8929\n",
      "Epoch 1510/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8929\n",
      "Epoch 1511/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8929\n",
      "Epoch 1512/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8929\n",
      "Epoch 1513/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8929\n",
      "Epoch 1514/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8929\n",
      "Epoch 1515/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8929\n",
      "Epoch 1516/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8929\n",
      "Epoch 1517/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8929\n",
      "Epoch 1518/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8929\n",
      "Epoch 1519/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8929\n",
      "Epoch 1520/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8929\n",
      "Epoch 1521/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8929\n",
      "Epoch 1522/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8929\n",
      "Epoch 1523/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8929\n",
      "Epoch 1524/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8929\n",
      "Epoch 1525/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8929\n",
      "Epoch 1526/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8929\n",
      "Epoch 1527/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8929\n",
      "Epoch 1528/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8929\n",
      "Epoch 1529/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8929\n",
      "Epoch 1530/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8929\n",
      "Epoch 1531/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4946 - accuracy: 0.8929\n",
      "Epoch 1532/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8929\n",
      "Epoch 1533/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8929\n",
      "Epoch 1534/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8929\n",
      "Epoch 1535/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8929\n",
      "Epoch 1536/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8929\n",
      "Epoch 1537/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8929\n",
      "Epoch 1538/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8929\n",
      "Epoch 1539/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8929\n",
      "Epoch 1540/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.8929\n",
      "Epoch 1541/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8929\n",
      "Epoch 1542/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8929\n",
      "Epoch 1543/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8929\n",
      "Epoch 1544/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8929\n",
      "Epoch 1545/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8929\n",
      "Epoch 1546/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8929\n",
      "Epoch 1547/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8929\n",
      "Epoch 1548/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8929\n",
      "Epoch 1549/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8929\n",
      "Epoch 1550/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8929\n",
      "Epoch 1551/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8929\n",
      "Epoch 1552/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8929\n",
      "Epoch 1553/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8929\n",
      "Epoch 1554/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8929\n",
      "Epoch 1555/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8929\n",
      "Epoch 1556/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8929\n",
      "Epoch 1557/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8929\n",
      "Epoch 1558/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8929\n",
      "Epoch 1559/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8929\n",
      "Epoch 1560/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8929\n",
      "Epoch 1561/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8929\n",
      "Epoch 1562/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8929\n",
      "Epoch 1563/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8929\n",
      "Epoch 1564/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8929\n",
      "Epoch 1565/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8929\n",
      "Epoch 1566/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8929\n",
      "Epoch 1567/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8929\n",
      "Epoch 1568/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4932 - accuracy: 0.8929\n",
      "Epoch 1569/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8929\n",
      "Epoch 1570/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8929\n",
      "Epoch 1571/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8929\n",
      "Epoch 1572/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8929\n",
      "Epoch 1573/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8929\n",
      "Epoch 1574/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8929\n",
      "Epoch 1575/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8929\n",
      "Epoch 1576/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8929\n",
      "Epoch 1577/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8929\n",
      "Epoch 1578/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8929\n",
      "Epoch 1579/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8929\n",
      "Epoch 1580/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8929\n",
      "Epoch 1581/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8929\n",
      "Epoch 1582/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8929\n",
      "Epoch 1583/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8929\n",
      "Epoch 1584/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8929\n",
      "Epoch 1585/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8929\n",
      "Epoch 1586/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4925 - accuracy: 0.8929\n",
      "Epoch 1587/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8929\n",
      "Epoch 1588/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8929\n",
      "Epoch 1589/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8929\n",
      "Epoch 1590/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8929\n",
      "Epoch 1591/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8929\n",
      "Epoch 1592/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8929\n",
      "Epoch 1593/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8929\n",
      "Epoch 1594/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8929\n",
      "Epoch 1595/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8929\n",
      "Epoch 1596/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8929\n",
      "Epoch 1597/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8929\n",
      "Epoch 1598/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8929\n",
      "Epoch 1599/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8929\n",
      "Epoch 1600/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8929\n",
      "Epoch 1601/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8929\n",
      "Epoch 1602/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8929\n",
      "Epoch 1603/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8929\n",
      "Epoch 1604/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8929\n",
      "Epoch 1605/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8929\n",
      "Epoch 1606/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8929\n",
      "Epoch 1607/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8929\n",
      "Epoch 1608/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8929\n",
      "Epoch 1609/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8929\n",
      "Epoch 1610/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8929\n",
      "Epoch 1611/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8929\n",
      "Epoch 1612/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8929\n",
      "Epoch 1613/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8929\n",
      "Epoch 1614/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8929\n",
      "Epoch 1615/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8929\n",
      "Epoch 1616/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8929\n",
      "Epoch 1617/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8929\n",
      "Epoch 1618/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8929\n",
      "Epoch 1619/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8929\n",
      "Epoch 1620/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8929\n",
      "Epoch 1621/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8929\n",
      "Epoch 1622/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8929\n",
      "Epoch 1623/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8929\n",
      "Epoch 1624/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8929\n",
      "Epoch 1625/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8929\n",
      "Epoch 1626/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8929\n",
      "Epoch 1627/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8929\n",
      "Epoch 1628/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8929\n",
      "Epoch 1629/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8929\n",
      "Epoch 1630/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8929\n",
      "Epoch 1631/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8929\n",
      "Epoch 1632/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8929\n",
      "Epoch 1633/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8929\n",
      "Epoch 1634/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8929\n",
      "Epoch 1635/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8929\n",
      "Epoch 1636/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8929\n",
      "Epoch 1637/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8929\n",
      "Epoch 1638/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8929\n",
      "Epoch 1639/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8929\n",
      "Epoch 1640/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8929\n",
      "Epoch 1641/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8929\n",
      "Epoch 1642/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8929\n",
      "Epoch 1643/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8929\n",
      "Epoch 1644/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8929\n",
      "Epoch 1645/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8929\n",
      "Epoch 1646/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8929\n",
      "Epoch 1647/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8929\n",
      "Epoch 1648/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8929\n",
      "Epoch 1649/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8929\n",
      "Epoch 1650/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8929\n",
      "Epoch 1651/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8929\n",
      "Epoch 1652/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8929\n",
      "Epoch 1653/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8929\n",
      "Epoch 1654/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8929\n",
      "Epoch 1655/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8929\n",
      "Epoch 1656/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8929\n",
      "Epoch 1657/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8929\n",
      "Epoch 1658/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8929\n",
      "Epoch 1659/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8929\n",
      "Epoch 1660/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8929\n",
      "Epoch 1661/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8929\n",
      "Epoch 1662/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8929\n",
      "Epoch 1663/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8929\n",
      "Epoch 1664/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8929\n",
      "Epoch 1665/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8929\n",
      "Epoch 1666/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8929\n",
      "Epoch 1667/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8929\n",
      "Epoch 1668/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8929\n",
      "Epoch 1669/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8929\n",
      "Epoch 1670/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8929\n",
      "Epoch 1671/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8929\n",
      "Epoch 1672/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8929\n",
      "Epoch 1673/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8929\n",
      "Epoch 1674/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8929\n",
      "Epoch 1675/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8929\n",
      "Epoch 1676/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8929\n",
      "Epoch 1677/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8929\n",
      "Epoch 1678/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8929\n",
      "Epoch 1679/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8929\n",
      "Epoch 1680/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8929\n",
      "Epoch 1681/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8929\n",
      "Epoch 1682/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8929\n",
      "Epoch 1683/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 1684/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 1685/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 1686/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8929\n",
      "Epoch 1687/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8929\n",
      "Epoch 1688/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8929\n",
      "Epoch 1689/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8929\n",
      "Epoch 1690/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8929\n",
      "Epoch 1691/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8929\n",
      "Epoch 1692/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8929\n",
      "Epoch 1693/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8929\n",
      "Epoch 1694/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8929\n",
      "Epoch 1695/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8929\n",
      "Epoch 1696/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8929\n",
      "Epoch 1697/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8929\n",
      "Epoch 1698/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8929\n",
      "Epoch 1699/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8929\n",
      "Epoch 1700/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8929\n",
      "Epoch 1701/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8929\n",
      "Epoch 1702/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8929\n",
      "Epoch 1703/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8929\n",
      "Epoch 1704/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8929\n",
      "Epoch 1705/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8929\n",
      "Epoch 1706/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8929\n",
      "Epoch 1707/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8929\n",
      "Epoch 1708/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8929\n",
      "Epoch 1709/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8929\n",
      "Epoch 1710/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8929\n",
      "Epoch 1711/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8929\n",
      "Epoch 1712/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8929\n",
      "Epoch 1713/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8929\n",
      "Epoch 1714/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8929\n",
      "Epoch 1715/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8929\n",
      "Epoch 1716/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8929\n",
      "Epoch 1717/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8929\n",
      "Epoch 1718/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8929\n",
      "Epoch 1719/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8929\n",
      "Epoch 1720/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4875 - accuracy: 0.8929\n",
      "Epoch 1721/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8929\n",
      "Epoch 1722/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8929\n",
      "Epoch 1723/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8929\n",
      "Epoch 1724/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8929\n",
      "Epoch 1725/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8929\n",
      "Epoch 1726/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8929\n",
      "Epoch 1727/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8929\n",
      "Epoch 1728/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8929\n",
      "Epoch 1729/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8929\n",
      "Epoch 1730/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8929\n",
      "Epoch 1731/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8929\n",
      "Epoch 1732/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8929\n",
      "Epoch 1733/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8929\n",
      "Epoch 1734/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8929\n",
      "Epoch 1735/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8929\n",
      "Epoch 1736/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8929\n",
      "Epoch 1737/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8929\n",
      "Epoch 1738/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8929\n",
      "Epoch 1739/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4868 - accuracy: 0.8929\n",
      "Epoch 1740/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8929\n",
      "Epoch 1741/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8929\n",
      "Epoch 1742/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8929\n",
      "Epoch 1743/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8929\n",
      "Epoch 1744/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8929\n",
      "Epoch 1745/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8929\n",
      "Epoch 1746/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4865 - accuracy: 0.8929\n",
      "Epoch 1747/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8929\n",
      "Epoch 1748/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8929\n",
      "Epoch 1749/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8929\n",
      "Epoch 1750/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8929\n",
      "Epoch 1751/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8929\n",
      "Epoch 1752/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8929\n",
      "Epoch 1753/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8929\n",
      "Epoch 1754/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8929\n",
      "Epoch 1755/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8929\n",
      "Epoch 1756/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8929\n",
      "Epoch 1757/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8929\n",
      "Epoch 1758/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8929\n",
      "Epoch 1759/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8929\n",
      "Epoch 1760/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8929\n",
      "Epoch 1761/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8929\n",
      "Epoch 1762/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8929\n",
      "Epoch 1763/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8929\n",
      "Epoch 1764/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8929\n",
      "Epoch 1765/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8929\n",
      "Epoch 1766/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8929\n",
      "Epoch 1767/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.8929\n",
      "Epoch 1768/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4857 - accuracy: 0.8929\n",
      "Epoch 1769/2500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4857 - accuracy: 0.8929\n",
      "Epoch 1770/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.8929\n",
      "Epoch 1771/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.8929\n",
      "Epoch 1772/2500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 1773/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 1774/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 1775/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.8929\n",
      "Epoch 1776/2500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4854 - accuracy: 0.8929\n",
      "Epoch 1777/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.8929\n",
      "Epoch 1778/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.8929\n",
      "Epoch 1779/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8929\n",
      "Epoch 1780/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8929\n",
      "Epoch 1781/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.8929\n",
      "Epoch 1782/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8929\n",
      "Epoch 1783/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8929\n",
      "Epoch 1784/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8929\n",
      "Epoch 1785/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8929\n",
      "Epoch 1786/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8929\n",
      "Epoch 1787/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8929\n",
      "Epoch 1788/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8929\n",
      "Epoch 1789/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8929\n",
      "Epoch 1790/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8929\n",
      "Epoch 1791/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8929\n",
      "Epoch 1792/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8929\n",
      "Epoch 1793/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8929\n",
      "Epoch 1794/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8929\n",
      "Epoch 1795/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8929\n",
      "Epoch 1796/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8929\n",
      "Epoch 1797/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8929\n",
      "Epoch 1798/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8929\n",
      "Epoch 1799/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4846 - accuracy: 0.8929\n",
      "Epoch 1800/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8929\n",
      "Epoch 1801/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8929\n",
      "Epoch 1802/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8929\n",
      "Epoch 1803/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8929\n",
      "Epoch 1804/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8929\n",
      "Epoch 1805/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8929\n",
      "Epoch 1806/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8929\n",
      "Epoch 1807/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8929\n",
      "Epoch 1808/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8929\n",
      "Epoch 1809/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8929\n",
      "Epoch 1810/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8929\n",
      "Epoch 1811/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8929\n",
      "Epoch 1812/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8929\n",
      "Epoch 1813/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8929\n",
      "Epoch 1814/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4840 - accuracy: 0.8929\n",
      "Epoch 1815/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.8929\n",
      "Epoch 1816/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8929\n",
      "Epoch 1817/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8929\n",
      "Epoch 1818/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8929\n",
      "Epoch 1819/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8929\n",
      "Epoch 1820/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8929\n",
      "Epoch 1821/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8929\n",
      "Epoch 1822/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8929\n",
      "Epoch 1823/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8929\n",
      "Epoch 1824/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8929\n",
      "Epoch 1825/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8929\n",
      "Epoch 1826/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8929\n",
      "Epoch 1827/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8929\n",
      "Epoch 1828/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8929\n",
      "Epoch 1829/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8929\n",
      "Epoch 1830/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8929\n",
      "Epoch 1831/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8929\n",
      "Epoch 1832/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8929\n",
      "Epoch 1833/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8929\n",
      "Epoch 1834/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8929\n",
      "Epoch 1835/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8929\n",
      "Epoch 1836/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8929\n",
      "Epoch 1837/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8929\n",
      "Epoch 1838/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8929\n",
      "Epoch 1839/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8929\n",
      "Epoch 1840/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8929\n",
      "Epoch 1841/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8929\n",
      "Epoch 1842/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8929\n",
      "Epoch 1843/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4830 - accuracy: 0.8929\n",
      "Epoch 1844/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8929\n",
      "Epoch 1845/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8929\n",
      "Epoch 1846/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8929\n",
      "Epoch 1847/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8929\n",
      "Epoch 1848/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8929\n",
      "Epoch 1849/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8929\n",
      "Epoch 1850/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8929\n",
      "Epoch 1851/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8929\n",
      "Epoch 1852/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8929\n",
      "Epoch 1853/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8929\n",
      "Epoch 1854/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4826 - accuracy: 0.8929\n",
      "Epoch 1855/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8929\n",
      "Epoch 1856/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8929\n",
      "Epoch 1857/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8929\n",
      "Epoch 1858/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8929\n",
      "Epoch 1859/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8929\n",
      "Epoch 1860/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8929\n",
      "Epoch 1861/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8929\n",
      "Epoch 1862/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8929\n",
      "Epoch 1863/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8929\n",
      "Epoch 1864/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 1865/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 1866/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 1867/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8929\n",
      "Epoch 1868/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8929\n",
      "Epoch 1869/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8929\n",
      "Epoch 1870/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4820 - accuracy: 0.8929\n",
      "Epoch 1871/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8929\n",
      "Epoch 1872/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8929\n",
      "Epoch 1873/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8929\n",
      "Epoch 1874/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8929\n",
      "Epoch 1875/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8929\n",
      "Epoch 1876/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8929\n",
      "Epoch 1877/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8929\n",
      "Epoch 1878/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8929\n",
      "Epoch 1879/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8929\n",
      "Epoch 1880/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8929\n",
      "Epoch 1881/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8929\n",
      "Epoch 1882/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8929\n",
      "Epoch 1883/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8929\n",
      "Epoch 1884/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8929\n",
      "Epoch 1885/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8929\n",
      "Epoch 1886/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4814 - accuracy: 0.8929\n",
      "Epoch 1887/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4814 - accuracy: 0.8929\n",
      "Epoch 1888/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8929\n",
      "Epoch 1889/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8929\n",
      "Epoch 1890/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4813 - accuracy: 0.8929\n",
      "Epoch 1891/2500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4813 - accuracy: 0.8929\n",
      "Epoch 1892/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4812 - accuracy: 0.8929\n",
      "Epoch 1893/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4812 - accuracy: 0.8929\n",
      "Epoch 1894/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8929\n",
      "Epoch 1895/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8929\n",
      "Epoch 1896/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8929\n",
      "Epoch 1897/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8929\n",
      "Epoch 1898/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8929\n",
      "Epoch 1899/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8929\n",
      "Epoch 1900/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8929\n",
      "Epoch 1901/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8929\n",
      "Epoch 1902/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8929\n",
      "Epoch 1903/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8929\n",
      "Epoch 1904/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8929\n",
      "Epoch 1905/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8929\n",
      "Epoch 1906/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.8929\n",
      "Epoch 1907/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4807 - accuracy: 0.8929\n",
      "Epoch 1908/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8929\n",
      "Epoch 1909/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8929\n",
      "Epoch 1910/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4806 - accuracy: 0.8929\n",
      "Epoch 1911/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8929\n",
      "Epoch 1912/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8929\n",
      "Epoch 1913/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8929\n",
      "Epoch 1914/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4805 - accuracy: 0.8929\n",
      "Epoch 1915/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4804 - accuracy: 0.8929\n",
      "Epoch 1916/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4804 - accuracy: 0.8929\n",
      "Epoch 1917/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.8929\n",
      "Epoch 1918/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4803 - accuracy: 0.8929\n",
      "Epoch 1919/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8929\n",
      "Epoch 1920/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8929\n",
      "Epoch 1921/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8929\n",
      "Epoch 1922/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8929\n",
      "Epoch 1923/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8929\n",
      "Epoch 1924/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8929\n",
      "Epoch 1925/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4801 - accuracy: 0.8929\n",
      "Epoch 1926/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8929\n",
      "Epoch 1927/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8929\n",
      "Epoch 1928/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8929\n",
      "Epoch 1929/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8929\n",
      "Epoch 1930/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8929\n",
      "Epoch 1931/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8929\n",
      "Epoch 1932/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8929\n",
      "Epoch 1933/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8929\n",
      "Epoch 1934/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8929\n",
      "Epoch 1935/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8929\n",
      "Epoch 1936/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8929\n",
      "Epoch 1937/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8929\n",
      "Epoch 1938/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8929\n",
      "Epoch 1939/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8929\n",
      "Epoch 1940/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8929\n",
      "Epoch 1941/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8929\n",
      "Epoch 1942/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.8929\n",
      "Epoch 1943/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8929\n",
      "Epoch 1944/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4794 - accuracy: 0.8929\n",
      "Epoch 1945/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8929\n",
      "Epoch 1946/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8929\n",
      "Epoch 1947/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8929\n",
      "Epoch 1948/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8929\n",
      "Epoch 1949/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8929\n",
      "Epoch 1950/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8929\n",
      "Epoch 1951/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8929\n",
      "Epoch 1952/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8929\n",
      "Epoch 1953/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8929\n",
      "Epoch 1954/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8929\n",
      "Epoch 1955/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 1956/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 1957/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 1958/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8929\n",
      "Epoch 1959/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8929\n",
      "Epoch 1960/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8929\n",
      "Epoch 1961/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4788 - accuracy: 0.8929\n",
      "Epoch 1962/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8929\n",
      "Epoch 1963/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8929\n",
      "Epoch 1964/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8929\n",
      "Epoch 1965/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8929\n",
      "Epoch 1966/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8929\n",
      "Epoch 1967/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8929\n",
      "Epoch 1968/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8929\n",
      "Epoch 1969/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8929\n",
      "Epoch 1970/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8929\n",
      "Epoch 1971/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8929\n",
      "Epoch 1972/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8929\n",
      "Epoch 1973/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8929\n",
      "Epoch 1974/2500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4784 - accuracy: 0.8929\n",
      "Epoch 1975/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8929\n",
      "Epoch 1976/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8929\n",
      "Epoch 1977/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8929\n",
      "Epoch 1978/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4782 - accuracy: 0.8929\n",
      "Epoch 1979/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8929\n",
      "Epoch 1980/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4782 - accuracy: 0.8929\n",
      "Epoch 1981/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4781 - accuracy: 0.8929\n",
      "Epoch 1982/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8929\n",
      "Epoch 1983/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8929\n",
      "Epoch 1984/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4780 - accuracy: 0.8929\n",
      "Epoch 1985/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8929\n",
      "Epoch 1986/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8929\n",
      "Epoch 1987/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8929\n",
      "Epoch 1988/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8929\n",
      "Epoch 1989/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8929\n",
      "Epoch 1990/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8929\n",
      "Epoch 1991/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8929\n",
      "Epoch 1992/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8929\n",
      "Epoch 1993/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8929\n",
      "Epoch 1994/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8929\n",
      "Epoch 1995/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8929\n",
      "Epoch 1996/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8929\n",
      "Epoch 1997/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8929\n",
      "Epoch 1998/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "Epoch 1999/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "Epoch 2000/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "Epoch 2001/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8929\n",
      "Epoch 2002/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8929\n",
      "Epoch 2003/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8929\n",
      "Epoch 2004/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8929\n",
      "Epoch 2005/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8929\n",
      "Epoch 2006/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8929\n",
      "Epoch 2007/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8929\n",
      "Epoch 2008/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8929\n",
      "Epoch 2009/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4772 - accuracy: 0.8929\n",
      "Epoch 2010/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8929\n",
      "Epoch 2011/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8929\n",
      "Epoch 2012/2500\n",
      "1/1 [==============================] - 0s 977us/step - loss: 0.4771 - accuracy: 0.8929\n",
      "Epoch 2013/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8929\n",
      "Epoch 2014/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8929\n",
      "Epoch 2015/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8929\n",
      "Epoch 2016/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8929\n",
      "Epoch 2017/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8929\n",
      "Epoch 2018/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8929\n",
      "Epoch 2019/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8929\n",
      "Epoch 2020/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8929\n",
      "Epoch 2021/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8929\n",
      "Epoch 2022/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4767 - accuracy: 0.8929\n",
      "Epoch 2023/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8929\n",
      "Epoch 2024/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8929\n",
      "Epoch 2025/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8929\n",
      "Epoch 2026/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8929\n",
      "Epoch 2027/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8929\n",
      "Epoch 2028/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8929\n",
      "Epoch 2029/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8929\n",
      "Epoch 2030/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8929\n",
      "Epoch 2031/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8929\n",
      "Epoch 2032/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8929\n",
      "Epoch 2033/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8929\n",
      "Epoch 2034/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8929\n",
      "Epoch 2035/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4763 - accuracy: 0.8929\n",
      "Epoch 2036/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8929\n",
      "Epoch 2037/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8929\n",
      "Epoch 2038/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8929\n",
      "Epoch 2039/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8929\n",
      "Epoch 2040/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8929\n",
      "Epoch 2041/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8929\n",
      "Epoch 2042/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8929\n",
      "Epoch 2043/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8929\n",
      "Epoch 2044/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8929\n",
      "Epoch 2045/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 2046/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 2047/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 2048/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8929\n",
      "Epoch 2049/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8929\n",
      "Epoch 2050/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8929\n",
      "Epoch 2051/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8929\n",
      "Epoch 2052/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8929\n",
      "Epoch 2053/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8929\n",
      "Epoch 2054/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8929\n",
      "Epoch 2055/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8929\n",
      "Epoch 2056/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8929\n",
      "Epoch 2057/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8929\n",
      "Epoch 2058/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8929\n",
      "Epoch 2059/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8929\n",
      "Epoch 2060/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8929\n",
      "Epoch 2061/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4754 - accuracy: 0.8929\n",
      "Epoch 2062/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8929\n",
      "Epoch 2063/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8929\n",
      "Epoch 2064/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8929\n",
      "Epoch 2065/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8929\n",
      "Epoch 2066/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8929\n",
      "Epoch 2067/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8929\n",
      "Epoch 2068/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8929\n",
      "Epoch 2069/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8929\n",
      "Epoch 2070/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8929\n",
      "Epoch 2071/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8929\n",
      "Epoch 2072/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8929\n",
      "Epoch 2073/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8929\n",
      "Epoch 2074/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8929\n",
      "Epoch 2075/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8929\n",
      "Epoch 2076/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8929\n",
      "Epoch 2077/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8929\n",
      "Epoch 2078/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8929\n",
      "Epoch 2079/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8929\n",
      "Epoch 2080/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8929\n",
      "Epoch 2081/2500\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.4747 - accuracy: 0.8929\n",
      "Epoch 2082/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8929\n",
      "Epoch 2083/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8929\n",
      "Epoch 2084/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8929\n",
      "Epoch 2085/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.8929\n",
      "Epoch 2086/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8929\n",
      "Epoch 2087/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8929\n",
      "Epoch 2088/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8929\n",
      "Epoch 2089/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8929\n",
      "Epoch 2090/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8929\n",
      "Epoch 2091/2500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4744 - accuracy: 0.8929\n",
      "Epoch 2092/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4743 - accuracy: 0.8929\n",
      "Epoch 2093/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8929\n",
      "Epoch 2094/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8929\n",
      "Epoch 2095/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8929\n",
      "Epoch 2096/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8929\n",
      "Epoch 2097/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8929\n",
      "Epoch 2098/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8929\n",
      "Epoch 2099/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8929\n",
      "Epoch 2100/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8929\n",
      "Epoch 2101/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8929\n",
      "Epoch 2102/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8929\n",
      "Epoch 2103/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8929\n",
      "Epoch 2104/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8929\n",
      "Epoch 2105/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8929\n",
      "Epoch 2106/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8929\n",
      "Epoch 2107/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8929\n",
      "Epoch 2108/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4738 - accuracy: 0.8929\n",
      "Epoch 2109/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8929\n",
      "Epoch 2110/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8929\n",
      "Epoch 2111/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8929\n",
      "Epoch 2112/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8929\n",
      "Epoch 2113/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8929\n",
      "Epoch 2114/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8929\n",
      "Epoch 2115/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8929\n",
      "Epoch 2116/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8929\n",
      "Epoch 2117/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8929\n",
      "Epoch 2118/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8929\n",
      "Epoch 2119/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4734 - accuracy: 0.8929\n",
      "Epoch 2120/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.8929\n",
      "Epoch 2121/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8929\n",
      "Epoch 2122/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4733 - accuracy: 0.8929\n",
      "Epoch 2123/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8929\n",
      "Epoch 2124/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8929\n",
      "Epoch 2125/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8929\n",
      "Epoch 2126/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8929\n",
      "Epoch 2127/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8929\n",
      "Epoch 2128/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8929\n",
      "Epoch 2129/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4731 - accuracy: 0.8929\n",
      "Epoch 2130/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8929\n",
      "Epoch 2131/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8929\n",
      "Epoch 2132/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8929\n",
      "Epoch 2133/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8929\n",
      "Epoch 2134/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2135/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2136/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2137/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2138/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8929\n",
      "Epoch 2139/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8929\n",
      "Epoch 2140/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8929\n",
      "Epoch 2141/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 2142/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 2143/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 2144/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8929\n",
      "Epoch 2145/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8929\n",
      "Epoch 2146/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.8929\n",
      "Epoch 2147/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4725 - accuracy: 0.8929\n",
      "Epoch 2148/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8929\n",
      "Epoch 2149/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8929\n",
      "Epoch 2150/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8929\n",
      "Epoch 2151/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8929\n",
      "Epoch 2152/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8929\n",
      "Epoch 2153/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8929\n",
      "Epoch 2154/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8929\n",
      "Epoch 2155/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8929\n",
      "Epoch 2156/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8929\n",
      "Epoch 2157/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8929\n",
      "Epoch 2158/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8929\n",
      "Epoch 2159/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8929\n",
      "Epoch 2160/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8929\n",
      "Epoch 2161/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8929\n",
      "Epoch 2162/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4720 - accuracy: 0.8929\n",
      "Epoch 2163/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8929\n",
      "Epoch 2164/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8929\n",
      "Epoch 2165/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8929\n",
      "Epoch 2166/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8929\n",
      "Epoch 2167/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8929\n",
      "Epoch 2168/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8929\n",
      "Epoch 2169/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8929\n",
      "Epoch 2170/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8929\n",
      "Epoch 2171/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8929\n",
      "Epoch 2172/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4717 - accuracy: 0.8929\n",
      "Epoch 2173/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4717 - accuracy: 0.8929\n",
      "Epoch 2174/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8929\n",
      "Epoch 2175/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8929\n",
      "Epoch 2176/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8929\n",
      "Epoch 2177/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4715 - accuracy: 0.8929\n",
      "Epoch 2178/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4715 - accuracy: 0.8929\n",
      "Epoch 2179/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4715 - accuracy: 0.8929\n",
      "Epoch 2180/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8929\n",
      "Epoch 2181/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8929\n",
      "Epoch 2182/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8929\n",
      "Epoch 2183/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8929\n",
      "Epoch 2184/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.8929\n",
      "Epoch 2185/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.8929\n",
      "Epoch 2186/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8929\n",
      "Epoch 2187/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8929\n",
      "Epoch 2188/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8929\n",
      "Epoch 2189/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8929\n",
      "Epoch 2190/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.8929\n",
      "Epoch 2191/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8929\n",
      "Epoch 2192/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8929\n",
      "Epoch 2193/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8929\n",
      "Epoch 2194/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.8929\n",
      "Epoch 2195/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8929\n",
      "Epoch 2196/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8929\n",
      "Epoch 2197/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.8929\n",
      "Epoch 2198/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8929\n",
      "Epoch 2199/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8929\n",
      "Epoch 2200/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8929\n",
      "Epoch 2201/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2202/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2203/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2204/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2205/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4706 - accuracy: 0.8929\n",
      "Epoch 2206/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.8929\n",
      "Epoch 2207/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8929\n",
      "Epoch 2208/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8929\n",
      "Epoch 2209/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8929\n",
      "Epoch 2210/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8929\n",
      "Epoch 2211/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8929\n",
      "Epoch 2212/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8929\n",
      "Epoch 2213/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8929\n",
      "Epoch 2214/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8929\n",
      "Epoch 2215/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8929\n",
      "Epoch 2216/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8929\n",
      "Epoch 2217/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8929\n",
      "Epoch 2218/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.8929\n",
      "Epoch 2219/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8929\n",
      "Epoch 2220/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8929\n",
      "Epoch 2221/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8929\n",
      "Epoch 2222/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8929\n",
      "Epoch 2223/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8929\n",
      "Epoch 2224/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8929\n",
      "Epoch 2225/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8929\n",
      "Epoch 2226/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8929\n",
      "Epoch 2227/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8929\n",
      "Epoch 2228/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8929\n",
      "Epoch 2229/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8929\n",
      "Epoch 2230/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8929\n",
      "Epoch 2231/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8929\n",
      "Epoch 2232/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8929\n",
      "Epoch 2233/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8929\n",
      "Epoch 2234/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8929\n",
      "Epoch 2235/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2236/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2237/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2238/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2239/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8929\n",
      "Epoch 2240/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8929\n",
      "Epoch 2241/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4695 - accuracy: 0.8929\n",
      "Epoch 2242/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4694 - accuracy: 0.8929\n",
      "Epoch 2243/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8929\n",
      "Epoch 2244/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8929\n",
      "Epoch 2245/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8929\n",
      "Epoch 2246/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8929\n",
      "Epoch 2247/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.8929\n",
      "Epoch 2248/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4692 - accuracy: 0.8929\n",
      "Epoch 2249/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8929\n",
      "Epoch 2250/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8929\n",
      "Epoch 2251/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8929\n",
      "Epoch 2252/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.8929\n",
      "Epoch 2253/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4691 - accuracy: 0.8929\n",
      "Epoch 2254/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4690 - accuracy: 0.8929\n",
      "Epoch 2255/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8929\n",
      "Epoch 2256/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8929\n",
      "Epoch 2257/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8929\n",
      "Epoch 2258/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8929\n",
      "Epoch 2259/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8929\n",
      "Epoch 2260/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8929\n",
      "Epoch 2261/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8929\n",
      "Epoch 2262/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8929\n",
      "Epoch 2263/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2264/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2265/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2266/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2267/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8929\n",
      "Epoch 2268/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8929\n",
      "Epoch 2269/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8929\n",
      "Epoch 2270/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8929\n",
      "Epoch 2271/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8929\n",
      "Epoch 2272/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.9286\n",
      "Epoch 2273/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.9286\n",
      "Epoch 2274/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.9286\n",
      "Epoch 2275/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.9286\n",
      "Epoch 2276/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.9286\n",
      "Epoch 2277/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4683 - accuracy: 0.9286\n",
      "Epoch 2278/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.9286\n",
      "Epoch 2279/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9286\n",
      "Epoch 2280/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9286\n",
      "Epoch 2281/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9286\n",
      "Epoch 2282/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4681 - accuracy: 0.9286\n",
      "Epoch 2283/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.9286\n",
      "Epoch 2284/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4681 - accuracy: 0.9286\n",
      "Epoch 2285/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2286/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2287/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2288/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2289/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9286\n",
      "Epoch 2290/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9286\n",
      "Epoch 2291/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9286\n",
      "Epoch 2292/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.9286\n",
      "Epoch 2293/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.9286\n",
      "Epoch 2294/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.9286\n",
      "Epoch 2295/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.9286\n",
      "Epoch 2296/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.9286\n",
      "Epoch 2297/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.9286\n",
      "Epoch 2298/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.9286\n",
      "Epoch 2299/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.9286\n",
      "Epoch 2300/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.9286\n",
      "Epoch 2301/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.9286\n",
      "Epoch 2302/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.9286\n",
      "Epoch 2303/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.9286\n",
      "Epoch 2304/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.9286\n",
      "Epoch 2305/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.9286\n",
      "Epoch 2306/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.9286\n",
      "Epoch 2307/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2308/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2309/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2310/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2311/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.9286\n",
      "Epoch 2312/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.9286\n",
      "Epoch 2313/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.9286\n",
      "Epoch 2314/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.9286\n",
      "Epoch 2315/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.9286\n",
      "Epoch 2316/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.9286\n",
      "Epoch 2317/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.9286\n",
      "Epoch 2318/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.9286\n",
      "Epoch 2319/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.9286\n",
      "Epoch 2320/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9286\n",
      "Epoch 2321/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9286\n",
      "Epoch 2322/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9286\n",
      "Epoch 2323/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.9286\n",
      "Epoch 2324/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9286\n",
      "Epoch 2325/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9286\n",
      "Epoch 2326/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2327/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2328/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2329/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2330/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9286\n",
      "Epoch 2331/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9286\n",
      "Epoch 2332/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9286\n",
      "Epoch 2333/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.9286\n",
      "Epoch 2334/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9286\n",
      "Epoch 2335/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.9286\n",
      "Epoch 2336/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9286\n",
      "Epoch 2337/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4664 - accuracy: 0.9286\n",
      "Epoch 2338/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9286\n",
      "Epoch 2339/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9286\n",
      "Epoch 2340/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9286\n",
      "Epoch 2341/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9286\n",
      "Epoch 2342/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2343/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2344/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2345/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2346/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.9286\n",
      "Epoch 2347/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9286\n",
      "Epoch 2348/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9286\n",
      "Epoch 2349/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9286\n",
      "Epoch 2350/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.9286\n",
      "Epoch 2351/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9286\n",
      "Epoch 2352/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9286\n",
      "Epoch 2353/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9286\n",
      "Epoch 2354/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9286\n",
      "Epoch 2355/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9286\n",
      "Epoch 2356/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9286\n",
      "Epoch 2357/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9286\n",
      "Epoch 2358/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2359/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2360/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2361/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2362/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9286\n",
      "Epoch 2363/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9286\n",
      "Epoch 2364/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9286\n",
      "Epoch 2365/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9286\n",
      "Epoch 2366/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9286\n",
      "Epoch 2367/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9286\n",
      "Epoch 2368/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9286\n",
      "Epoch 2369/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9286\n",
      "Epoch 2370/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9286\n",
      "Epoch 2371/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9286\n",
      "Epoch 2372/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9286\n",
      "Epoch 2373/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9286\n",
      "Epoch 2374/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2375/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2376/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2377/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2378/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.9286\n",
      "Epoch 2379/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9286\n",
      "Epoch 2380/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9286\n",
      "Epoch 2381/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9286\n",
      "Epoch 2382/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9286\n",
      "Epoch 2383/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9286\n",
      "Epoch 2384/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9286\n",
      "Epoch 2385/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9286\n",
      "Epoch 2386/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9286\n",
      "Epoch 2387/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2388/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2389/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2390/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2391/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9286\n",
      "Epoch 2392/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.9286\n",
      "Epoch 2393/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9286\n",
      "Epoch 2394/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4646 - accuracy: 0.9286\n",
      "Epoch 2395/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9286\n",
      "Epoch 2396/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9286\n",
      "Epoch 2397/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9286\n",
      "Epoch 2398/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9286\n",
      "Epoch 2399/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9286\n",
      "Epoch 2400/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.9286\n",
      "Epoch 2401/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.9286\n",
      "Epoch 2402/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9286\n",
      "Epoch 2403/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2404/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2405/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2406/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2407/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4642 - accuracy: 0.9286\n",
      "Epoch 2408/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.9286\n",
      "Epoch 2409/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.9286\n",
      "Epoch 2410/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4641 - accuracy: 0.9286\n",
      "Epoch 2411/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9286\n",
      "Epoch 2412/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9286\n",
      "Epoch 2413/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9286\n",
      "Epoch 2414/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9286\n",
      "Epoch 2415/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9286\n",
      "Epoch 2416/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2417/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2418/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2419/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2420/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9286\n",
      "Epoch 2421/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4638 - accuracy: 0.9286\n",
      "Epoch 2422/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9286\n",
      "Epoch 2423/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.9286\n",
      "Epoch 2424/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9286\n",
      "Epoch 2425/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9286\n",
      "Epoch 2426/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9286\n",
      "Epoch 2427/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9286\n",
      "Epoch 2428/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9286\n",
      "Epoch 2429/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2430/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2431/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2432/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2433/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9286\n",
      "Epoch 2434/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9286\n",
      "Epoch 2435/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9286\n",
      "Epoch 2436/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9286\n",
      "Epoch 2437/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.9286\n",
      "Epoch 2438/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.9286\n",
      "Epoch 2439/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2440/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2441/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2442/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2443/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9286\n",
      "Epoch 2444/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9286\n",
      "Epoch 2445/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9286\n",
      "Epoch 2446/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.9286\n",
      "Epoch 2447/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.9286\n",
      "Epoch 2448/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.9286\n",
      "Epoch 2449/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.9286\n",
      "Epoch 2450/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4629 - accuracy: 0.9286\n",
      "Epoch 2451/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.9286\n",
      "Epoch 2452/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2453/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2454/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2455/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2456/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.9286\n",
      "Epoch 2457/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.9286\n",
      "Epoch 2458/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.9286\n",
      "Epoch 2459/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.9286\n",
      "Epoch 2460/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.9286\n",
      "Epoch 2461/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.9286\n",
      "Epoch 2462/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2463/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2464/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2465/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2466/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.9286\n",
      "Epoch 2467/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4624 - accuracy: 0.9286\n",
      "Epoch 2468/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.9286\n",
      "Epoch 2469/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.9286\n",
      "Epoch 2470/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.9286\n",
      "Epoch 2471/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.9286\n",
      "Epoch 2472/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.9286\n",
      "Epoch 2473/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.9286\n",
      "Epoch 2474/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.9286\n",
      "Epoch 2475/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2476/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2477/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2478/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2479/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.9286\n",
      "Epoch 2480/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4620 - accuracy: 0.9286\n",
      "Epoch 2481/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.9286\n",
      "Epoch 2482/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.9286\n",
      "Epoch 2483/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.9286\n",
      "Epoch 2484/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.9286\n",
      "Epoch 2485/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2486/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2487/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2488/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2489/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4617 - accuracy: 0.9286\n",
      "Epoch 2490/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4617 - accuracy: 0.9286\n",
      "Epoch 2491/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.9286\n",
      "Epoch 2492/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.9286\n",
      "Epoch 2493/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.9286\n",
      "Epoch 2494/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.9286\n",
      "Epoch 2495/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2496/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2497/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2498/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2499/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.9286\n",
      "Epoch 2500/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a62b5df8b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X.to_numpy(), y.to_numpy(), epochs=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aaf32f-9ff8-4895-9ad2-4da5be51e174",
   "metadata": {},
   "source": [
    "Nach dem Training (anpassen der w's und b's) haben sich die Gewichte verändert. <br>\n",
    "Das Model kann alle Weights ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e270eb7-0c3c-4095-8d52-a9f4f2c857e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.2917147],\n",
       "        [1.2697676]], dtype=float32),\n",
       " array([-2.4975893], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('L1a2').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e67d7150-2c7c-4d11-9caa-53fbe612f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2917147],\n",
       "       [1.2697676]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, b = model.get_layer('L1a2').get_weights()\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db8a0fa8-a654-47ad-9cec-5a18d534ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54037255]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([ [0.22, 1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86c517c-5763-4973-8597-32dbd86bf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktivierungsfunktion. \n",
    "def sidmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca563b77-d164-42df-8463-8efb0157333d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5403725601709111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit den gebenen Weights:\n",
    "res = 1.749332 * 0.22 + 0.76867884 * 1 + (-0.9916893)\n",
    "sidmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443ad71e-6682-4053-9cf2-1ed7091a836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.predict([ [0.22, 1] ])) == sidmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a885bd-fbde-454d-90b6-4adbf85a79a2",
   "metadata": {},
   "source": [
    "Man sieht deutlich, dass die Ergebnisse gleich sind. <br>\n",
    "Bei internen Unterschieden kann es vorkommen, dass sich das Ergebnis minimal unterscheidet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d160e3-c918-4e1d-9596-6690e3a0ed7a",
   "metadata": {},
   "source": [
    "<h2>Python-NN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83342153-faa6-4a0c-a31c-898d550903d6",
   "metadata": {},
   "source": [
    "Mit diesem Wissen und zusätzlich mit dem Gradientenabstieg kann einfach ein neurales Netz in Python programmiert werden.\n",
    "\n",
    "Quellen zum Nachlesen:\n",
    "> Understanding the Mathematics behind Gradient Descent: https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e [Letzter Zugriff: 24.06.2024]\n",
    "\n",
    "> Gradient descent: https://en.wikipedia.org/wiki/Gradient_descent [Letzter Zugriff: 24.06.2024]\n",
    "\n",
    "> Logistic regression for binary classification with Core APIs: https://www.tensorflow.org/guide/core/logistic_regression_core [Letzter Zugriff: 24.06.2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677ad2c-d977-4876-aea0-ab8a4e1d91d2",
   "metadata": {},
   "source": [
    "Dank Numpy's Matrixmultiplikationen können wir uns hier viel Arbeit sparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6364ef79-000f-476b-9725-b387a38cc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradienabstieg.\n",
    "# - Für w1, w2 und b.\n",
    "def gradienten_abstieg(age, afford, y_true, epochs, loss_thr:float=2.0, lr:float=0.01):\n",
    "    # w1, 2w und Bais.\n",
    "    # - age, affordibility, y_true sind Vektoren.\n",
    "    w1   = w2 = 1  # Random, meist mit 1. \n",
    "    bias = 0  # Meist mit 0 \n",
    "    n = len(afford)  # Länge der Samples.\n",
    "\n",
    "    for i in range(epochs): # Für jede Epoche mach das:\n",
    "        # Weight-Sum. Siehe Abbildung 1 oben. \n",
    "        # - Jedes Neuron hat 2 Komponenten- Summe und Aktivierungsfunktion. \n",
    "        weight_sum = w1 * age + w2 * afford + bias  # Vektor Operation.\n",
    "        y_pred = sigmoid_funk(weight_sum)  # Aktivierungsfunktion.\n",
    "        \n",
    "        # Berechne Loss, hier Log-Loss\n",
    "        # - Oben definiert. \n",
    "        loss = logloss(y_pred, y_true)\n",
    "\n",
    "        # Dann nutzen wir die Ableitung. \n",
    "        # - Vereinfachte Ableitung. \n",
    "        # - Oder als Schleife.\n",
    "        w1d =  (1/n) * np.dot(np.transpose(age) ,    (y_pred-y_true))           \n",
    "        w2d =  (1/n) * np.dot(np.transpose(afford) , (y_pred-y_true)) \n",
    "        bias_d = np.mean(y_pred-y_true)\n",
    "\n",
    "        w1 = w1 - lr * w1d  # Formel von Oben.\n",
    "        w2 = w2 - lr * w2d  # - Hier werden die Gewichte angepasst - Die ganze Magie dahinter. \n",
    "        bias = bias - lr * bias_d\n",
    "\n",
    "        # Wie bei TF wollen wir auch Ausgaben sehen.\n",
    "        print(f\"epoche: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}\")\n",
    "\n",
    "        if loss <= loss_thr:\n",
    "            break\n",
    "    return w1, w2, bias\n",
    "\n",
    "def sigmoid_funk(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab98770-e48b-4bc3-ae65-b0c821101226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, w1: 0.9762849575718682, w2: 0.9413816587881323, bias: -0.11723219144694776, loss: 0.71595572538616\n",
      "epoche: 1, w1: 0.9585899606042918, w2: 0.8931885694836231, bias: -0.2191259515368365, loss: 0.6829875086265863\n",
      "epoche: 2, w1: 0.9464149777228181, w2: 0.8547036125789471, bias: -0.30702265178471283, loss: 0.6589217086986395\n",
      "epoche: 3, w1: 0.9391383692699615, w2: 0.8249187940412019, bias: -0.38253896783203234, loss: 0.6416822511323294\n",
      "epoche: 4, w1: 0.9360948301666506, w2: 0.8026921496785079, bias: -0.4473753028623717, loss: 0.6294529652627155\n",
      "epoche: 5, w1: 0.9366346644985458, w2: 0.7868725699850446, bias: -0.5031736709956828, loss: 0.6207751606893134\n",
      "epoche: 6, w1: 0.9401607708239514, w2: 0.7763814668731136, bias: -0.5514315265930735, loss: 0.6145491275476828\n",
      "epoche: 7, w1: 0.9461466946820075, w2: 0.7702560384753816, bias: -0.5934618343566833, loss: 0.6099834810303708\n",
      "epoche: 8, w1: 0.954141456340729, w2: 0.7676648564070271, bias: -0.6303847592529248, loss: 0.6065276757013168\n",
      "epoche: 9, w1: 0.9637664517522821, w2: 0.7679063148049593, bias: -0.6631378798968053, loss: 0.6038079530817342\n",
      "epoche: 10, w1: 0.9747083310088303, w2: 0.7703979331115388, bias: -0.6924954774838189, loss: 0.6015749693364817\n",
      "epoche: 11, w1: 0.9867103584261395, w2: 0.7746617534011894, bias: -0.7190909476098314, loss: 0.5996644256615059\n",
      "epoche: 12, w1: 0.9995636937987874, w2: 0.7803089200364081, bias: -0.7434389789778153, loss: 0.5979689848393459\n",
      "epoche: 13, w1: 1.013099330277909, w2: 0.7870250787974431, bias: -0.7659558320778166, loss: 0.5964189169716717\n",
      "epoche: 14, w1: 1.0271809992881886, w2: 0.7945573421598614, bias: -0.7869770551959033, loss: 0.5949690691974582\n",
      "epoche: 15, w1: 1.041699115120877, w2: 0.8027030592497458, bias: -0.8067725273857667, loss: 0.5935902340209914\n",
      "epoche: 16, w1: 1.056565709679365, w2: 0.811300360093811, bias: -0.8255589949994384, loss: 0.5922634963089803\n",
      "epoche: 17, w1: 1.0717102529851525, w2: 0.820220315993876, bias: -0.8435103872263123, loss: 0.5909765610643756\n",
      "epoche: 18, w1: 1.0870762373292722, w2: 0.8293605092853291, bias: -0.8607662290025561, loss: 0.5897213818339175\n",
      "epoche: 19, w1: 1.1026184044934702, w2: 0.8386397992758673, bias: -0.8774384589438693, loss: 0.5884926355293281\n",
      "epoche: 20, w1: 1.118300506056648, w2: 0.8479940853731878, bias: -0.8936169294930595, loss: 0.5872867445382833\n",
      "epoche: 21, w1: 1.1340935008285877, w2: 0.8573728913365836, bias: -0.9093738292060501, loss: 0.5861012510685376\n",
      "epoche: 22, w1: 1.149974107965514, w2: 0.8667366198121979, bias: -0.9247672296944903, loss: 0.5849344174217753\n",
      "epoche: 23, w1: 1.1659236478819142, w2: 0.8760543505926367, bias: -0.9398439253530088, loss: 0.5837849708279206\n",
      "epoche: 24, w1: 1.181927115075068, w2: 0.8853020779095938, bias: -0.9546417038628001, loss: 0.5826519406126269\n",
      "epoche: 25, w1: 1.1979724372618215, w2: 0.8944613010162257, bias: -0.9691911598165757, loss: 0.5815345542661167\n",
      "epoche: 26, w1: 1.2140498838539258, w2: 0.9035178983365907, bias: -0.9835171423971467, loss: 0.5804321710549764\n",
      "epoche: 27, w1: 1.230151593932721, w2: 0.9124612287839202, bias: -0.9976399103957359, loss: 0.5793442395511553\n",
      "epoche: 28, w1: 1.2462711997251532, w2: 0.9212834148051873, bias: -1.011576053447038, loss: 0.5782702703942325\n",
      "epoche: 29, w1: 1.2624035263309465, w2: 0.9299787706437079, bias: -1.025339226670031, loss: 0.5772098187563245\n",
      "epoche: 30, w1: 1.2785443522893492, w2: 0.9385433465536165, bias: -1.0389407364687462, loss: 0.5761624729888272\n",
      "epoche: 31, w1: 1.294690218665101, w2: 0.946974565544332, bias: -1.05239000765875, loss: 0.575127847210206\n",
      "epoche: 32, w1: 1.3108382768152496, w2: 0.9552709339336141, bias: -1.0656949559981583, loss: 0.5741055764087999\n",
      "epoche: 33, w1: 1.3269861669867828, w2: 0.9634318107588048, bias: -1.0788622853294036, loss: 0.573095313153089\n",
      "epoche: 34, w1: 1.3431319214852517, w2: 0.9714572241154047, bias: -1.0918977246434252, loss: 0.572096725331731\n",
      "epoche: 35, w1: 1.3592738874247026, w2: 0.9793477249064761, bias: -1.1048062172686968, loss: 0.5711094945555183\n",
      "epoche: 36, w1: 1.3754106650828124, w2: 0.9871042704147335, bias: -1.1175920719073082, loss: 0.5701333149869384\n",
      "epoche: 37, w1: 1.3915410586933423, w2: 0.9947281316481379, bias: -1.1302590832631496, loss: 0.5691678924479512\n",
      "epoche: 38, w1: 1.4076640371522064, w2: 1.002220819637284, bias: -1.1428106284317694, loss: 0.5682129437106813\n",
      "epoche: 39, w1: 1.4237787026266868, w2: 1.0095840268414777, bias: -1.1552497439664873, loss: 0.567268195910123\n",
      "epoche: 40, w1: 1.439884265466134, w2: 1.016819580600401, bias: -1.1675791875358126, loss: 0.5663333860398768\n",
      "epoche: 41, w1: 1.4559800241380902, w2: 1.0239294061898248, bias: -1.1798014872912554, loss: 0.5654082605058878\n",
      "epoche: 42, w1: 1.4720653491730684, w2: 1.0309154975351178, bias: -1.1919189814307745, loss: 0.5644925747220518\n",
      "epoche: 43, w1: 1.4881396703077114, w2: 1.0377798940309326, bias: -1.2039338499383556, loss: 0.5635860927372274\n",
      "epoche: 44, w1: 1.5042024661805242, w2: 1.0445246622299096, bias: -1.2158481400782477, loss: 0.5626885868868012\n",
      "epoche: 45, w1: 1.5202532560653508, w2: 1.051151881413821, bias: -1.2276637869022196, loss: 0.5617998374642751\n",
      "epoche: 46, w1: 1.536291593232114, w2: 1.0576636322602815, bias: -1.2393826297731931, loss: 0.5609196324098137\n",
      "epoche: 47, w1: 1.5523170596074611, w2: 1.0640619879773263, bias: -1.2510064257054307, loss: 0.5600477670136363\n",
      "epoche: 48, w1: 1.5683292614741942, w2: 1.0703490074050517, bias: -1.262536860159576, loss: 0.559184043632756\n",
      "epoche: 49, w1: 1.5843278260011515, w2: 1.0765267296846839, bias: -1.2739755558018289, loss: 0.5583282714199483\n",
      "epoche: 50, w1: 1.6003123984372822, w2: 1.0825971701761263, bias: -1.2853240796337064, loss: 0.557480266064102\n",
      "epoche: 51, w1: 1.616282639837202, w2: 1.0885623173693868, bias: -1.2965839488168436, loss: 0.5566398495412577\n",
      "epoche: 52, w1: 1.632238225212267, w2: 1.0944241305866267, bias: -1.3077566354519186, loss: 0.5558068498757675\n",
      "epoche: 53, w1: 1.6481788420225363, w2: 1.1001845383125366, bias: -1.3188435705186372, loss: 0.5549811009110736\n",
      "epoche: 54, w1: 1.6641041889420203, w2: 1.1058454370234425, bias: -1.3298461471421121, loss: 0.5541624420896621\n",
      "epoche: 55, w1: 1.680013974843183, w2: 1.1114086904116431, bias: -1.340765723317776, loss: 0.5533507182417892\n",
      "epoche: 56, w1: 1.6959079179575178, w2: 1.1168761289223184, bias: -1.3516036242004785, loss: 0.5525457793826015\n",
      "epoche: 57, w1: 1.7117857451776601, w2: 1.1222495495369946, bias: -1.3623611440422583, loss: 0.5517474805172987\n",
      "epoche: 58, w1: 1.7276471914734153, w2: 1.127530715750842, bias: -1.373039547846403, loss: 0.5509556814540068\n",
      "epoche: 59, w1: 1.7434919993995963, w2: 1.1327213577017066, bias: -1.3836400727919107, loss: 0.5501702466240413\n",
      "epoche: 60, w1: 1.7593199186779789, w2: 1.137823172417261, bias: -1.3941639294716976, loss: 0.5493910449092638\n",
      "epoche: 61, w1: 1.7751307058391974, w2: 1.1428378241534503, bias: -1.4046123029792807, loss: 0.5486179494762363\n",
      "epoche: 62, w1: 1.7909241239132294, w2: 1.1477669448028254, bias: -1.414986353871782, loss: 0.5478508376169026\n",
      "epoche: 63, w1: 1.8066999421593621, w2: 1.1526121343556983, bias: -1.4252872190315977, loss: 0.5470895905955274\n",
      "epoche: 64, w1: 1.8224579358283377, w2: 1.157374961400522, bias: -1.4355160124446757, loss: 0.5463340935016423\n",
      "epoche: 65, w1: 1.8381978859508143, w2: 1.1620569636526688, bias: -1.4456738259098199, loss: 0.545584235108752\n",
      "epoche: 66, w1: 1.8539195791474314, w2: 1.1666596485030025, bias: -1.455761729690625, loss: 0.5448399077385692\n",
      "epoche: 67, w1: 1.8696228074566918, w2: 1.171184493579418, bias: -1.4657807731193904, loss: 0.5441010071305534\n",
      "epoche: 68, w1: 1.8853073681776116, w2: 1.1756329473159355, bias: -1.4757319851605522, loss: 0.5433674323165382\n",
      "epoche: 69, w1: 1.90097306372468, w2: 1.1800064295250816, bias: -1.485616374939728, loss: 0.5426390855002413\n",
      "epoche: 70, w1: 1.916619701493147, w2: 1.1843063319701936, bias: -1.4954349322433091, loss: 0.5419158719414601\n",
      "epoche: 71, w1: 1.9322470937330354, w2: 1.188534018935014, bias: -1.5051886279926034, loss: 0.5411976998447616\n",
      "epoche: 72, w1: 1.9478550574305795, w2: 1.1926908277885213, bias: -1.5148784146957868, loss: 0.5404844802524873\n",
      "epoche: 73, w1: 1.963443414196037, w2: 1.1967780695434145, bias: -1.5245052268803239, loss: 0.5397761269418961\n",
      "epoche: 74, w1: 1.979011990157019, w2: 1.2007970294070347, bias: -1.5340699815080343, loss: 0.5390725563262807\n",
      "epoche: 75, w1: 1.9945606158566365, w2: 1.204748967323808, bias: -1.5435735783745976, loss: 0.5383736873598947\n",
      "epoche: 76, w1: 2.0100891261558957, w2: 1.2086351185085324, bias: -1.5530169004949752, loss: 0.5376794414465402\n",
      "epoche: 77, w1: 2.025597360139867, w2: 1.2124566939700172, bias: -1.5624008144759807, loss: 0.5369897423516634\n",
      "epoche: 78, w1: 2.041085161027247, w2: 1.2162148810247393, bias: -1.571726170877026, loss: 0.5363045161178243\n",
      "epoche: 79, w1: 2.056552376082984, w2: 1.2199108438002961, bias: -1.580993804559907, loss: 0.5356236909833977\n",
      "epoche: 80, w1: 2.071998856533708, w2: 1.223545723728533, bias: -1.590204535028361, loss: 0.5349471973043814\n",
      "epoche: 81, w1: 2.0874244574857364, w2: 1.2271206400282983, bias: -1.5993591667580227, loss: 0.5342749674791847\n",
      "epoche: 82, w1: 2.1028290378454635, w2: 1.2306366901778385, bias: -1.6084584895173175, loss: 0.5336069358762775\n",
      "epoche: 83, w1: 2.1182124602419803, w2: 1.2340949503768903, bias: -1.6175032786797578, loss: 0.5329430387645884\n",
      "epoche: 84, w1: 2.1335745909517803, w2: 1.2374964759985692, bias: -1.6264942955280564, loss: 0.5322832142465398\n",
      "epoche: 85, w1: 2.1489152998254353, w2: 1.2408423020311738, bias: -1.6354322875504157, loss: 0.5316274021936149\n",
      "epoche: 86, w1: 2.164234460216138, w2: 1.2441334435100557, bias: -1.6443179887293216, loss: 0.5309755441843597\n",
      "epoche: 87, w1: 2.17953194891002, w2: 1.2473708959397127, bias: -1.6531521198231298, loss: 0.5303275834447163\n",
      "epoche: 88, w1: 2.194807646058162, w2: 1.250555635706283, bias: -1.661935388640714, loss: 0.5296834647906044\n",
      "epoche: 89, w1: 2.2100614351102315, w2: 1.2536886204806221, bias: -1.6706684903094138, loss: 0.5290431345726528\n",
      "epoche: 90, w1: 2.2252932027496732, w2: 1.2567707896121498, bias: -1.6793521075365123, loss: 0.5284065406230041\n",
      "epoche: 91, w1: 2.2405028388304045, w2: 1.2598030645136624, bias: -1.687986910864449, loss: 0.5277736322041034\n",
      "epoche: 92, w1: 2.2556902363149516, w2: 1.2627863490373046, bias: -1.6965735589199615, loss: 0.5271443599594009\n",
      "epoche: 93, w1: 2.2708552912139846, w2: 1.265721529841896, bias: -1.7051126986573433, loss: 0.5265186758658851\n",
      "epoche: 94, w1: 2.285997902527202, w2: 1.268609476751809, bias: -1.713604965595987, loss: 0.5258965331883829\n",
      "epoche: 95, w1: 2.301117972185521, w2: 1.2714510431075912, bias: -1.72205098405238, loss: 0.5252778864355494\n",
      "epoche: 96, w1: 2.316215404994538, w2: 1.2742470661085263, bias: -1.7304513673667086, loss: 0.5246626913174889\n",
      "epoche: 97, w1: 2.3312901085792146, w2: 1.276998367147324, bias: -1.7388067181242182, loss: 0.5240509047049378\n",
      "epoche: 98, w1: 2.3463419933297587, w2: 1.2797057521371236, bias: -1.7471176283714775, loss: 0.5234424845899525\n",
      "epoche: 99, w1: 2.3613709723486647, w2: 1.2823700118309993, bias: -1.75538467982768, loss: 0.5228373900480411\n",
      "epoche: 100, w1: 2.3763769613988805, w2: 1.284991922134146, bias: -1.7636084440911166, loss: 0.5222355812016855\n",
      "epoche: 101, w1: 2.39135987885307, w2: 1.2875722444089237, bias: -1.7717894828409502, loss: 0.521637019185197\n",
      "epoche: 102, w1: 2.406319645643941, w2: 1.2901117257729362, bias: -1.7799283480344106, loss: 0.5210416661108577\n",
      "epoche: 103, w1: 2.4212561852156123, w2: 1.2926110993903108, bias: -1.7880255820995339, loss: 0.520449485036295\n",
      "epoche: 104, w1: 2.436169423475991, w2: 1.2950710847563496, bias: -1.7960817181235582, loss: 0.5198604399330428\n",
      "epoche: 105, w1: 2.4510592887501326, w2: 1.297492387975712, bias: -1.80409728003709, loss: 0.5192744956562453\n",
      "epoche: 106, w1: 2.4659257117345597, w2: 1.2998757020342908, bias: -1.8120727827941474, loss: 0.5186916179154573\n",
      "epoche: 107, w1: 2.480768625452516, w2: 1.3022217070649333, bias: -1.8200087325481875, loss: 0.5181117732465002\n",
      "epoche: 108, w1: 2.495587965210131, w2: 1.3045310706071627, bias: -1.8279056268242182, loss: 0.517534928984334\n",
      "epoche: 109, w1: 2.510383668553471, w2: 1.306804447861045, bias: -1.8357639546870945, loss: 0.5169610532369054\n",
      "epoche: 110, w1: 2.5251556752264555, w2: 1.3090424819353481, bias: -1.8435841969060938, loss: 0.5163901148599374\n",
      "epoche: 111, w1: 2.53990392712962, w2: 1.3112458040901316, bias: -1.8513668261158651, loss: 0.5158220834326187\n",
      "epoche: 112, w1: 2.5546283682796993, w2: 1.3134150339739061, bias: -1.8591123069738433, loss: 0.5152569292341681\n",
      "epoche: 113, w1: 2.569328944770016, w2: 1.3155507798554957, bias: -1.8668210963142136, loss: 0.5146946232212323\n",
      "epoche: 114, w1: 2.584005604731653, w2: 1.317653638850733, bias: -1.8744936432985144, loss: 0.5141351370060901\n",
      "epoche: 115, w1: 2.5986582982953896, w2: 1.3197241971441145, bias: -1.8821303895629624, loss: 0.5135784428356321\n",
      "epoche: 116, w1: 2.6132869775543854, w2: 1.3217630302055412, bias: -1.8897317693625777, loss: 0.5130245135710865\n",
      "epoche: 117, w1: 2.6278915965275926, w2: 1.3237707030022632, bias: -1.8972982097121907, loss: 0.5124733226684618\n",
      "epoche: 118, w1: 2.6424721111238805, w2: 1.3257477702061466, bias: -1.9048301305244053, loss: 0.5119248441596823\n",
      "epoche: 119, w1: 2.657028479106855, w2: 1.3276947763963785, bias: -1.9123279447445942, loss: 0.5113790526343877\n",
      "epoche: 120, w1: 2.6715606600603565, w2: 1.3296122562577193, bias: -1.9197920584829977, loss: 0.5108359232223747\n",
      "epoche: 121, w1: 2.6860686153546203, w2: 1.3315007347744132, bias: -1.9272228711439967, loss: 0.5102954315766537\n",
      "epoche: 122, w1: 2.7005523081130858, w2: 1.3333607274198622, bias: -1.9346207755526292, loss: 0.5097575538571013\n",
      "epoche: 123, w1: 2.715011703179838, w2: 1.3351927403421655, bias: -1.9419861580784152, loss: 0.5092222667146837\n",
      "epoche: 124, w1: 2.729446767087667, w2: 1.3369972705456261, bias: -1.9493193987565562, loss: 0.5086895472762308\n",
      "epoche: 125, w1: 2.743857468026732, w2: 1.3387748060683227, bias: -1.9566208714065731, loss: 0.5081593731297416\n",
      "epoche: 126, w1: 2.7582437758138156, w2: 1.3405258261558406, bias: -1.9638909437484413, loss: 0.5076317223102\n",
      "epoche: 127, w1: 2.7726056618621566, w2: 1.3422508014312555, bias: -1.971129977516285, loss: 0.5071065732858836\n",
      "epoche: 128, w1: 2.786943099151845, w2: 1.3439501940614618, bias: -1.9783383285696885, loss: 0.5065839049451448\n",
      "epoche: 129, w1: 2.8012560622007707, w2: 1.3456244579199292, bias: -1.985516347002681, loss: 0.5060636965836517\n",
      "epoche: 130, w1: 2.8155445270361117, w2: 1.3472740387459798, bias: -1.9926643772504486, loss: 0.5055459278920662\n",
      "epoche: 131, w1: 2.829808471166348, w2: 1.3488993743006625, bias: -1.9997827581938294, loss: 0.5050305789441486\n",
      "epoche: 132, w1: 2.8440478735537953, w2: 1.3505008945193109, bias: -2.0068718232616427, loss: 0.5045176301852686\n",
      "epoche: 133, w1: 2.858262714587639, w2: 1.3520790216608614, bias: -2.0139319005309027, loss: 0.5040070624213123\n",
      "epoche: 134, w1: 2.872452976057467, w2: 1.3536341704540098, bias: -2.020963312824968, loss: 0.5034988568079679\n",
      "epoche: 135, w1: 2.8866186411272805, w2: 1.355166748240281, bias: -2.0279663778096735, loss: 0.5029929948403764\n",
      "epoche: 136, w1: 2.900759694309985, w2: 1.3566771551140848, bias: -2.0349414080874895, loss: 0.5024894583431359\n",
      "epoche: 137, w1: 2.914876121442335, w2: 1.3581657840598298, bias: -2.041888711289761, loss: 0.5019882294606461\n",
      "epoche: 138, w1: 2.92896790966034, w2: 1.3596330210861642, bias: -2.048808590167064, loss: 0.5014892906477794\n",
      "epoche: 139, w1: 2.9430350473751083, w2: 1.361079245357411, bias: -2.0557013426777244, loss: 0.5009926246608691\n",
      "epoche: 140, w1: 2.957077524249128, w2: 1.3625048293222641, bias: -2.0625672620745448, loss: 0.5004982145490007\n",
      "epoche: 141, w1: 2.9710953311729713, w2: 1.3639101388398103, bias: -2.0694066369897763, loss: 0.5000060436455989\n",
      "epoche: 142, w1: 2.985088460242416, w2: 1.3652955333029357, bias: -2.0762197515183782, loss: 0.4995160955602955\n",
      "epoche: 143, w1: 2.9990569047359736, w2: 1.366661365759184, bias: -2.0830068852996018, loss: 0.49902835417107283\n",
      "epoche: 144, w1: 3.013000659092818, w2: 1.3680079830291183, bias: -2.0897683135969403, loss: 0.49854280361666853\n",
      "epoche: 145, w1: 3.0269197188911035, w2: 1.3693357258222523, bias: -2.096504307376478, loss: 0.49805942828923533\n",
      "epoche: 146, w1: 3.040814080826666, w2: 1.3706449288505997, bias: -2.103215133383677, loss: 0.49757821282724635\n",
      "epoche: 147, w1: 3.0546837426920996, w2: 1.3719359209399022, bias: -2.109901054218636, loss: 0.4970991421086351\n",
      "epoche: 148, w1: 3.0685287033562023, w2: 1.373209025138586, bias: -2.1165623284098567, loss: 0.4966222012441651\n",
      "epoche: 149, w1: 3.0823489627437795, w2: 1.3744645588245021, bias: -2.1231992104865474, loss: 0.4961473755710193\n",
      "epoche: 150, w1: 3.0961445218158, w2: 1.3757028338094976, bias: -2.129811951049503, loss: 0.49567465064660027\n",
      "epoche: 151, w1: 3.1099153825499024, w2: 1.3769241564418702, bias: -2.1364007968405856, loss: 0.4952040122425369\n",
      "epoche: 152, w1: 3.123661547921234, w2: 1.3781288277067532, bias: -2.1429659908108434, loss: 0.4947354463388879\n",
      "epoche: 153, w1: 3.137383021883628, w2: 1.3793171433244773, bias: -2.149507772187292, loss: 0.4942689391185352\n",
      "epoche: 154, w1: 3.1510798093511028, w2: 1.3804893938469571, bias: -2.1560263765383945, loss: 0.4938044769617633\n",
      "epoche: 155, w1: 3.1647519161796818, w2: 1.3816458647521437, bias: -2.1625220358382604, loss: 0.4933420464410137\n",
      "epoche: 156, w1: 3.1783993491495273, w2: 1.3827868365365894, bias: -2.1689949785296, loss: 0.492881634315813\n",
      "epoche: 157, w1: 3.19202211594738, w2: 1.383912584806167, bias: -2.175445429585457, loss: 0.4924232275278645\n",
      "epoche: 158, w1: 3.2056202251493, w2: 1.3850233803649836, bias: -2.1818736105697427, loss: 0.4919668131963007\n",
      "epoche: 159, w1: 3.2191936862037043, w2: 1.3861194893025288, bias: -2.1882797396966094, loss: 0.49151237861308933\n",
      "epoche: 160, w1: 3.232742509414693, w2: 1.3872011730791, bias: -2.194664031888671, loss: 0.4910599112385886\n",
      "epoche: 161, w1: 3.246266705925661, w2: 1.388268688609539, bias: -2.2010266988341143, loss: 0.49060939869724535\n",
      "epoche: 162, w1: 3.259766287703185, w2: 1.3893222883453191, bias: -2.207367949042707, loss: 0.490160828773432\n",
      "epoche: 163, w1: 3.27324126752119, w2: 1.39036222035502, bias: -2.213687987900743, loss: 0.4897141894074188\n",
      "epoche: 164, w1: 3.286691658945378, w2: 1.3913887284032245, bias: -2.219987017724934, loss: 0.489269468691473\n",
      "epoche: 165, w1: 3.300117476317924, w2: 1.392402052027872, bias: -2.226265237815277, loss: 0.48882665486608473\n",
      "epoche: 166, w1: 3.3135187347424297, w2: 1.3934024266161034, bias: -2.232522844506919, loss: 0.4883857363163126\n",
      "epoche: 167, w1: 3.32689545006913, w2: 1.3943900834786296, bias: -2.2387600312210383, loss: 0.4879467015682456\n",
      "epoche: 168, w1: 3.340247638880349, w2: 1.3953652499226556, bias: -2.244976988514764, loss: 0.48750953928557816\n",
      "epoche: 169, w1: 3.3535753184762007, w2: 1.3963281493233928, bias: -2.251173904130155, loss: 0.48707423826629287\n",
      "epoche: 170, w1: 3.3668785068605294, w2: 1.3972790011941871, bias: -2.2573509630422555, loss: 0.4866407874394491\n",
      "epoche: 171, w1: 3.3801572227270844, w2: 1.3982180212552981, bias: -2.263508347506251, loss: 0.48620917586207163\n",
      "epoche: 172, w1: 3.3934114854459287, w2: 1.3991454215013517, bias: -2.2696462371037387, loss: 0.4857793927161385\n",
      "epoche: 173, w1: 3.4066413150500714, w2: 1.4000614102675002, bias: -2.2757648087881335, loss: 0.48535142730566294\n",
      "epoche: 174, w1: 3.4198467322223256, w2: 1.400966192294315, bias: -2.2818642369292284, loss: 0.4849252690538656\n",
      "epoche: 175, w1: 3.4330277582823836, w2: 1.4018599687914384, bias: -2.287944693356923, loss: 0.4845009075004372\n",
      "epoche: 176, w1: 3.446184415174109, w2: 1.4027429375000227, bias: -2.2940063474041428, loss: 0.48407833229888386\n",
      "epoche: 177, w1: 3.4593167254530375, w2: 1.403615292753982, bias: -2.300049365948961, loss: 0.4836575332139574\n",
      "epoche: 178, w1: 3.472424712274086, w2: 1.40447722554008, bias: -2.3060739134559407, loss: 0.4832385001191627\n",
      "epoche: 179, w1: 3.4855083993794675, w2: 1.4053289235568804, bias: -2.312080152016718, loss: 0.4828212229943444\n",
      "epoche: 180, w1: 3.4985678110868017, w2: 1.4061705712725845, bias: -2.318068241389832, loss: 0.4824056919233461\n",
      "epoche: 181, w1: 3.5116029722774273, w2: 1.4070023499817752, bias: -2.3240383390398276, loss: 0.48199189709174217\n",
      "epoche: 182, w1: 3.5246139083849037, w2: 1.4078244378610962, bias: -2.329990600175638, loss: 0.4815798287846394\n",
      "epoche: 183, w1: 3.5376006453837032, w2: 1.4086370100238834, bias: -2.335925177788266, loss: 0.4811694773845443\n",
      "epoche: 184, w1: 3.5505632097780913, w2: 1.4094402385737739, bias: -2.341842222687776, loss: 0.4807608333692976\n",
      "epoche: 185, w1: 3.5635016285911876, w2: 1.4102342926573117, bias: -2.347741883539612, loss: 0.480353887310069\n",
      "epoche: 186, w1: 3.57641592935421, w2: 1.4110193385155725, bias: -2.3536243069002554, loss: 0.47994862986941395\n",
      "epoche: 187, w1: 3.5893061400958923, w2: 1.4117955395348254, bias: -2.359489637252232, loss: 0.47954505179938917\n",
      "epoche: 188, w1: 3.6021722893320787, w2: 1.4125630562962554, bias: -2.3653380170384883, loss: 0.47914314393972346\n",
      "epoche: 189, w1: 3.6150144060554865, w2: 1.4133220466247614, bias: -2.371169586696144, loss: 0.478742897216045\n",
      "epoche: 190, w1: 3.62783251972564, w2: 1.4140726656368514, bias: -2.376984484689635, loss: 0.47834430263816036\n",
      "epoche: 191, w1: 3.640626660258966, w2: 1.4148150657876537, bias: -2.382782847543256, loss: 0.47794735129838506\n",
      "epoche: 192, w1: 3.653396858019054, w2: 1.4155493969170603, bias: -2.388564809873126, loss: 0.4775520343699241\n",
      "epoche: 193, w1: 3.666143143807076, w2: 1.4162758062950207, bias: -2.3943305044185683, loss: 0.47715834310529953\n",
      "epoche: 194, w1: 3.678865548852361, w2: 1.4169944386660052, bias: -2.400080062072937, loss: 0.4767662688348248\n",
      "epoche: 195, w1: 3.691564104803127, w2: 1.4177054362926504, bias: -2.4058136119138878, loss: 0.476375802965124\n",
      "epoche: 196, w1: 3.7042388437173615, w2: 1.4184089389986092, bias: -2.4115312812331084, loss: 0.4759869369776936\n",
      "epoche: 197, w1: 3.716889798053853, w2: 1.4191050842106148, bias: -2.4172331955655193, loss: 0.4755996624275083\n",
      "epoche: 198, w1: 3.729517000663368, w2: 1.41979400699978, bias: -2.422919478717954, loss: 0.4752139709416631\n",
      "epoche: 199, w1: 3.742120484779974, w2: 1.4204758401221445, bias: -2.428590252797331, loss: 0.4748298542180597\n",
      "epoche: 200, w1: 3.7547002840125017, w2: 1.4211507140584836, bias: -2.4342456382383237, loss: 0.47444730402412694\n",
      "epoche: 201, w1: 3.7672564323361493, w2: 1.4218187570533978, bias: -2.439885753830543, loss: 0.4740663121955794\n",
      "epoche: 202, w1: 3.7797889640842213, w2: 1.422480095153693, bias: -2.445510716745238, loss: 0.4736868706352115\n",
      "epoche: 203, w1: 3.7922979139400046, w2: 1.4231348522460665, bias: -2.4511206425615226, loss: 0.47330897131172567\n",
      "epoche: 204, w1: 3.8047833169287752, w2: 1.4237831500941158, bias: -2.4567156452921464, loss: 0.4729326062585938\n",
      "epoche: 205, w1: 3.8172452084099366, w2: 1.4244251083746773, bias: -2.4622958374088064, loss: 0.4725577675729502\n",
      "epoche: 206, w1: 3.8296836240692866, w2: 1.4250608447135142, bias: -2.467861329867016, loss: 0.47218444741451726\n",
      "epoche: 207, w1: 3.8420985999114095, w2: 1.4256904747203634, bias: -2.473412232130539, loss: 0.4718126380045586\n",
      "epoche: 208, w1: 3.854490172252193, w2: 1.4263141120233525, bias: -2.478948652195394, loss: 0.4714423316248643\n",
      "epoche: 209, w1: 3.8668583777114685, w2: 1.4269318683028038, bias: -2.484470696613441, loss: 0.4710735206167618\n",
      "epoche: 210, w1: 3.8792032532057683, w2: 1.427543853324433, bias: -2.4899784705155548, loss: 0.4707061973801553\n",
      "epoche: 211, w1: 3.8915248359412042, w2: 1.4281501749719545, bias: -2.495472077634395, loss: 0.4703403543725911\n",
      "epoche: 212, w1: 3.9038231634064617, w2: 1.4287509392791093, bias: -2.500951620326779, loss: 0.4699759841083489\n",
      "epoche: 213, w1: 3.916098273365907, w2: 1.4293462504611207, bias: -2.50641719959567, loss: 0.46961307915755757\n",
      "epoche: 214, w1: 3.9283502038528098, w2: 1.4299362109455929, bias: -2.511868915111778, loss: 0.46925163214533416\n",
      "epoche: 215, w1: 3.9405789931626725, w2: 1.4305209214028614, bias: -2.5173068652347914, loss: 0.46889163575094717\n",
      "epoche: 216, w1: 3.9527846798466735, w2: 1.4311004807758072, bias: -2.522731147034237, loss: 0.46853308270700167\n",
      "epoche: 217, w1: 3.964967302705214, w2: 1.4316749863091431, bias: -2.528141856309985, loss: 0.468175965798646\n",
      "epoche: 218, w1: 3.9771269007815713, w2: 1.432244533578184, bias: -2.533539087612395, loss: 0.4678202778627996\n",
      "epoche: 219, w1: 3.989263513355657, w2: 1.4328092165171087, bias: -2.5389229342621196, loss: 0.4674660117874012\n",
      "epoche: 220, w1: 4.001377179937877, w2: 1.4333691274467275, bias: -2.544293488369564, loss: 0.467113160510677\n",
      "epoche: 221, w1: 4.013467940263091, w2: 1.4339243571017588, bias: -2.5496508408540133, loss: 0.46676171702042674\n",
      "epoche: 222, w1: 4.025535834284673, w2: 1.4344749946576292, bias: -2.5549950814624314, loss: 0.46641167435333036\n",
      "epoche: 223, w1: 4.037580902168668, w2: 1.4350211277568024, bias: -2.560326298787938, loss: 0.46606302559426965\n",
      "epoche: 224, w1: 4.049603184288043, w2: 1.4355628425346492, bias: -2.5656445802879686, loss: 0.4657157638756706\n",
      "epoche: 225, w1: 4.061602721217038, w2: 1.4361002236448641, bias: -2.5709500123021267, loss: 0.46536988237685867\n",
      "epoche: 226, w1: 4.073579553725603, w2: 1.4366333542844392, bias: -2.5762426800697287, loss: 0.4650253743234343\n",
      "epoche: 227, w1: 4.08553372277393, w2: 1.4371623162182021, bias: -2.581522667747053, loss: 0.46468223298666084\n",
      "epoche: 228, w1: 4.097465269507078, w2: 1.4376871898029275, bias: -2.586790058424292, loss: 0.4643404516828694\n",
      "epoche: 229, w1: 4.1093742352496765, w2: 1.4382080540110294, bias: -2.5920449341422205, loss: 0.46400002377287847\n",
      "epoche: 230, w1: 4.121260661500731, w2: 1.4387249864538414, bias: -2.597287375908576, loss: 0.463660942661427\n",
      "epoche: 231, w1: 4.133124589928501, w2: 1.439238063404495, bias: -2.6025174637141677, loss: 0.46332320179662206\n",
      "epoche: 232, w1: 4.14496606236547, w2: 1.4397473598203996, bias: -2.6077352765487074, loss: 0.46298679466939924\n",
      "epoche: 233, w1: 4.156785120803396, w2: 1.4402529493653355, bias: -2.6129408924163764, loss: 0.4626517148129972\n",
      "epoche: 234, w1: 4.168581807388445, w2: 1.4407549044311638, bias: -2.6181343883511263, loss: 0.46231795580244317\n",
      "epoche: 235, w1: 4.180356164416403, w2: 1.441253296159163, bias: -2.6233158404317267, loss: 0.4619855112540526\n",
      "epoche: 236, w1: 4.192108234327972, w2: 1.441748194460997, bias: -2.6284853237965544, loss: 0.4616543748249384\n",
      "epoche: 237, w1: 4.2038380597041405, w2: 1.442239668039322, bias: -2.633642912658137, loss: 0.46132454021253383\n",
      "epoche: 238, w1: 4.215545683261628, w2: 1.4427277844080402, bias: -2.638788680317452, loss: 0.46099600115412503\n",
      "epoche: 239, w1: 4.227231147848414, w2: 1.4432126099122045, bias: -2.6439226991779834, loss: 0.46066875142639496\n",
      "epoche: 240, w1: 4.2388944964393325, w2: 1.443694209747582, bias: -2.649045040759547, loss: 0.46034278484497754\n",
      "epoche: 241, w1: 4.250535772131747, w2: 1.4441726479798827, bias: -2.65415577571188, loss: 0.46001809526402176\n",
      "epoche: 242, w1: 4.262155018141293, w2: 1.4446479875636582, bias: -2.6592549738280074, loss: 0.4596946765757669\n",
      "epoche: 243, w1: 4.2737522777976915, w2: 1.4451202903608782, bias: -2.6643427040573817, loss: 0.4593725227101245\n",
      "epoche: 244, w1: 4.285327594540639, w2: 1.4455896171591884, bias: -2.6694190345188056, loss: 0.4590516276342726\n",
      "epoche: 245, w1: 4.296881011915756, w2: 1.4460560276898582, bias: -2.6744840325131385, loss: 0.45873198535225723\n",
      "epoche: 246, w1: 4.308412573570617, w2: 1.4465195806454214, bias: -2.6795377645357923, loss: 0.4584135899046026\n",
      "epoche: 247, w1: 4.319922323250832, w2: 1.446980333697017, bias: -2.684580296289018, loss: 0.4580964353679303\n",
      "epoche: 248, w1: 4.331410304796206, w2: 1.4474383435114349, bias: -2.689611692693991, loss: 0.45778051585458657\n",
      "epoche: 249, w1: 4.342876562136956, w2: 1.4478936657678712, bias: -2.6946320179026912, loss: 0.4574658255122766\n",
      "epoche: 250, w1: 4.354321139289998, w2: 1.4483463551744002, bias: -2.6996413353095936, loss: 0.457152358523708\n",
      "epoche: 251, w1: 4.365744080355291, w2: 1.4487964654841663, bias: -2.704639707563157, loss: 0.45684010910624057\n",
      "epoche: 252, w1: 4.377145429512247, w2: 1.4492440495113008, bias: -2.709627196577131, loss: 0.45652907151154365\n",
      "epoche: 253, w1: 4.388525231016199, w2: 1.4496891591465704, bias: -2.714603863541667, loss: 0.4562192400252605\n",
      "epoche: 254, w1: 4.399883529194932, w2: 1.4501318453727605, bias: -2.719569768934256, loss: 0.4559106089666793\n",
      "epoche: 255, w1: 4.411220368445272, w2: 1.4505721582797981, bias: -2.72452497253048, loss: 0.4556031726884111\n",
      "epoche: 256, w1: 4.422535793229729, w2: 1.4510101470796195, bias: -2.7294695334145844, loss: 0.45529692557607415\n",
      "epoche: 257, w1: 4.433829848073205, w2: 1.4514458601207878, bias: -2.7344035099898854, loss: 0.454991862047984\n",
      "epoche: 258, w1: 4.445102577559753, w2: 1.4518793449028629, bias: -2.7393269599889956, loss: 0.4546879765548499\n",
      "epoche: 259, w1: 4.456354026329394, w2: 1.4523106480905301, bias: -2.7442399404838906, loss: 0.45438526357947745\n",
      "epoche: 260, w1: 4.467584239074984, w2: 1.452739815527491, bias: -2.749142507895806, loss: 0.45408371763647576\n",
      "epoche: 261, w1: 4.478793260539145, w2: 1.4531668922501206, bias: -2.754034718004972, loss: 0.4537833332719723\n",
      "epoche: 262, w1: 4.489981135511237, w2: 1.4535919225008944, bias: -2.758916625960192, loss: 0.45348410506333064\n",
      "epoche: 263, w1: 4.5011479088243895, w2: 1.454014949741591, bias: -2.7637882862882623, loss: 0.45318602761887483\n",
      "epoche: 264, w1: 4.5122936253525845, w2: 1.4544360166662729, bias: -2.768649752903238, loss: 0.4528890955776186\n",
      "epoche: 265, w1: 4.523418330007788, w2: 1.4548551652140493, bias: -2.7735010791155474, loss: 0.45259330360899924\n",
      "epoche: 266, w1: 4.53452206773713, w2: 1.4552724365816259, bias: -2.7783423176409605, loss: 0.45229864641261713\n",
      "epoche: 267, w1: 4.545604883520137, w2: 1.4556878712356434, bias: -2.7831735206094086, loss: 0.4520051187179782\n",
      "epoche: 268, w1: 4.5566668223660125, w2: 1.456101508924811, bias: -2.7879947395736613, loss: 0.45171271528424245\n",
      "epoche: 269, w1: 4.567707929310961, w2: 1.4565133886918367, bias: -2.7928060255178635, loss: 0.4514214308999763\n",
      "epoche: 270, w1: 4.578728249415565, w2: 1.4569235488851568, bias: -2.797607428865933, loss: 0.45113126038290907\n",
      "epoche: 271, w1: 4.5897278277622044, w2: 1.457332027170473, bias: -2.8023989994898217, loss: 0.4508421985796938\n",
      "epoche: 272, w1: 4.60070670945252, w2: 1.4577388605420936, bias: -2.8071807867176424, loss: 0.45055424036567215\n",
      "epoche: 273, w1: 4.611664939604926, w2: 1.4581440853340872, bias: -2.8119528393416666, loss: 0.45026738064464294\n",
      "epoche: 274, w1: 4.622602563352165, w2: 1.4585477372312514, bias: -2.81671520562619, loss: 0.44998161434863426\n",
      "epoche: 275, w1: 4.633519625838904, w2: 1.4589498512798973, bias: -2.8214679333152737, loss: 0.44969693643768066\n",
      "epoche: 276, w1: 4.644416172219379, w2: 1.4593504618984556, bias: -2.826211069640357, loss: 0.44941334189960197\n",
      "epoche: 277, w1: 4.655292247655072, w2: 1.459749602887907, bias: -2.83094466132775, loss: 0.44913082574978697\n",
      "epoche: 278, w1: 4.66614789731244, w2: 1.4601473074420368, bias: -2.835668754606007, loss: 0.44884938303098026\n",
      "epoche: 279, w1: 4.67698316636068, w2: 1.4605436081575227, bias: -2.840383395213176, loss: 0.4485690088130715\n",
      "epoche: 280, w1: 4.687798099969531, w2: 1.4609385370438526, bias: -2.845088628403937, loss: 0.44828969819289\n",
      "epoche: 281, w1: 4.698592743307125, w2: 1.4613321255330785, bias: -2.8497844989566214, loss: 0.4480114462939993\n",
      "epoche: 282, w1: 4.7093671415378635, w2: 1.4617244044894098, bias: -2.854471051180124, loss: 0.44773424826649855\n",
      "epoche: 283, w1: 4.720121339820346, w2: 1.4621154042186466, bias: -2.8591483289206963, loss: 0.44745809928682295\n",
      "epoche: 284, w1: 4.730855383305329, w2: 1.4625051544774572, bias: -2.8638163755686397, loss: 0.4471829945575504\n",
      "epoche: 285, w1: 4.741569317133722, w2: 1.4628936844825022, bias: -2.8684752340648845, loss: 0.44690892930720905\n",
      "epoche: 286, w1: 4.752263186434624, w2: 1.463281022919407, bias: -2.8731249469074682, loss: 0.44663589879008797\n",
      "epoche: 287, w1: 4.762937036323391, w2: 1.4636671979515874, bias: -2.8777655561579083, loss: 0.44636389828605144\n",
      "epoche: 288, w1: 4.7735909118997455, w2: 1.4640522372289282, bias: -2.8823971034474725, loss: 0.44609292310035376\n",
      "epoche: 289, w1: 4.7842248582459135, w2: 1.4644361678963194, bias: -2.887019629983352, loss: 0.4458229685634591\n",
      "epoche: 290, w1: 4.794838920424804, w2: 1.46481901660205, bias: -2.891633176554733, loss: 0.44555403003086225\n",
      "epoche: 291, w1: 4.805433143478216, w2: 1.4652008095060658, bias: -2.896237783538774, loss: 0.44528610288291137\n",
      "epoche: 292, w1: 4.816007572425081, w2: 1.4655815722880887, bias: -2.9008334909064857, loss: 0.4450191825246353\n",
      "epoche: 293, w1: 4.826562252259739, w2: 1.4659613301556036, bias: -2.90542033822852, loss: 0.44475326438557017\n",
      "epoche: 294, w1: 4.8370972279502515, w2: 1.466340107851713, bias: -2.909998364680866, loss: 0.44448834391959136\n",
      "epoche: 295, w1: 4.847612544436733, w2: 1.4667179296628636, bias: -2.9145676090504535, loss: 0.44422441660474465\n",
      "epoche: 296, w1: 4.85810824662973, w2: 1.4670948194264435, bias: -2.9191281097406727, loss: 0.4439614779430815\n",
      "epoche: 297, w1: 4.8685843794086185, w2: 1.4674708005382566, bias: -2.9236799047768005, loss: 0.4436995234604964\n",
      "epoche: 298, w1: 4.879040987620042, w2: 1.4678458959598732, bias: -2.9282230318113456, loss: 0.44343854870656424\n",
      "epoche: 299, w1: 4.8894781160763685, w2: 1.4682201282258596, bias: -2.932757528129306, loss: 0.44317854925438255\n",
      "epoche: 300, w1: 4.89989580955419, w2: 1.468593519450889, bias: -2.9372834306533466, loss: 0.4429195207004132\n",
      "epoche: 301, w1: 4.910294112792838, w2: 1.4689660913367368, bias: -2.941800775948891, loss: 0.44266145866432743\n",
      "epoche: 302, w1: 4.920673070492938, w2: 1.469337865179159, bias: -2.9463096002291373, loss: 0.44240435878885176\n",
      "epoche: 303, w1: 4.931032727314984, w2: 1.4697088618746597, bias: -2.950809939359991, loss: 0.44214821673961696\n",
      "epoche: 304, w1: 4.941373127877951, w2: 1.4700791019271462, bias: -2.9553018288649233, loss: 0.4418930282050072\n",
      "epoche: 305, w1: 4.951694316757923, w2: 1.4704486054544759, bias: -2.9597853039297513, loss: 0.441638788896012\n",
      "epoche: 306, w1: 4.961996338486755, w2: 1.4708173921948953, bias: -2.964260399407343, loss: 0.4413854945460799\n",
      "epoche: 307, w1: 4.972279237550762, w2: 1.4711854815133742, bias: -2.9687271498222505, loss: 0.4411331409109723\n",
      "epoche: 308, w1: 4.982543058389429, w2: 1.4715528924078356, bias: -2.973185589375267, loss: 0.44088172376862156\n",
      "epoche: 309, w1: 4.992787845394155, w2: 1.4719196435152835, bias: -2.977635751947914, loss: 0.4406312389189881\n",
      "epoche: 310, w1: 5.003013642907012, w2: 1.4722857531178306, bias: -2.982077671106862, loss: 0.44038168218391965\n",
      "epoche: 311, w1: 5.013220495219536, w2: 1.472651239148628, bias: -2.9865113801082743, loss: 0.44013304940701403\n",
      "epoche: 312, w1: 5.023408446571541, w2: 1.4730161191976967, bias: -2.9909369119020894, loss: 0.4398853364534796\n",
      "epoche: 313, w1: 5.033577541149959, w2: 1.4733804105176649, bias: -2.995354299136234, loss: 0.43963853921000073\n",
      "epoche: 314, w1: 5.043727823087695, w2: 1.4737441300294107, bias: -2.9997635741607693, loss: 0.439392653584603\n",
      "epoche: 315, w1: 5.05385933646252, w2: 1.4741072943276134, bias: -3.0041647690319757, loss: 0.4391476755065195\n",
      "epoche: 316, w1: 5.063972125295972, w2: 1.4744699196862128, bias: -3.008557915516371, loss: 0.4389036009260591\n",
      "epoche: 317, w1: 5.074066233552292, w2: 1.4748320220637807, bias: -3.0129430450946657, loss: 0.43866042581447645\n",
      "epoche: 318, w1: 5.084141705137375, w2: 1.4751936171088047, bias: -3.0173201889656602, loss: 0.43841814616384156\n",
      "epoche: 319, w1: 5.094198583897743, w2: 1.475554720164884, bias: -3.0216893780500786, loss: 0.438176757986913\n",
      "epoche: 320, w1: 5.104236913619545, w2: 1.4759153462758423, bias: -3.0260506429943432, loss: 0.4379362573170104\n",
      "epoche: 321, w1: 5.114256738027572, w2: 1.4762755101907572, bias: -3.030404014174291, loss: 0.43769664020788873\n",
      "epoche: 322, w1: 5.124258100784298, w2: 1.4766352263689055, bias: -3.0347495216988323, loss: 0.43745790273361457\n",
      "epoche: 323, w1: 5.134241045488941, w2: 1.476994508984631, bias: -3.039087195413554, loss: 0.43722004098844186\n",
      "epoche: 324, w1: 5.144205615676537, w2: 1.47735337193213, bias: -3.043417064904266, loss: 0.436983051086691\n",
      "epoche: 325, w1: 5.154151854817045, w2: 1.4777118288301603, bias: -3.0477391595004892, loss: 0.43674692916262675\n",
      "epoche: 326, w1: 5.164079806314466, w2: 1.4780698930266742, bias: -3.0520535082788993, loss: 0.4365116713703391\n",
      "epoche: 327, w1: 5.17398951350598, w2: 1.478427577603374, bias: -3.056360140066706, loss: 0.436277273883624\n",
      "epoche: 328, w1: 5.183881019661104, w2: 1.4787848953801943, bias: -3.0606590834449876, loss: 0.43604373289586584\n",
      "epoche: 329, w1: 5.193754367980872, w2: 1.4791418589197125, bias: -3.064950366751973, loss: 0.4358110446199205\n",
      "epoche: 330, w1: 5.203609601597026, w2: 1.4794984805314848, bias: -3.0692340180862696, loss: 0.4355792052879999\n",
      "epoche: 331, w1: 5.213446763571231, w2: 1.4798547722763145, bias: -3.073510065310047, loss: 0.43534821115155725\n",
      "epoche: 332, w1: 5.2232658968943095, w2: 1.4802107459704483, bias: -3.077778536052167, loss: 0.4351180584811726\n",
      "epoche: 333, w1: 5.233067044485485, w2: 1.4805664131897063, bias: -3.082039457711269, loss: 0.43488874356644136\n",
      "epoche: 334, w1: 5.242850249191651, w2: 1.4809217852735432, bias: -3.0862928574588047, loss: 0.43466026271586145\n",
      "epoche: 335, w1: 5.252615553786656, w2: 1.4812768733290453, bias: -3.09053876224203, loss: 0.43443261225672253\n",
      "epoche: 336, w1: 5.262363000970601, w2: 1.4816316882348601, bias: -3.094777198786949, loss: 0.4342057885349965\n",
      "epoche: 337, w1: 5.272092633369156, w2: 1.481986240645064, bias: -3.0990081936012115, loss: 0.4339797879152281\n",
      "epoche: 338, w1: 5.281804493532896, w2: 1.4823405409929655, bias: -3.103231772976971, loss: 0.43375460678042616\n",
      "epoche: 339, w1: 5.291498623936645, w2: 1.482694599494849, bias: -3.1074479629936933, loss: 0.4335302415319576\n",
      "epoche: 340, w1: 5.301175066978848, w2: 1.4830484261536545, bias: -3.111656789520927, loss: 0.43330668858943966\n",
      "epoche: 341, w1: 5.3108338649809435, w2: 1.4834020307625997, bias: -3.1158582782210273, loss: 0.43308394439063463\n",
      "epoche: 342, w1: 5.320475060186763, w2: 1.4837554229087426, bias: -3.120052454551844, loss: 0.4328620053913454\n",
      "epoche: 343, w1: 5.330098694761943, w2: 1.4841086119764864, bias: -3.124239343769362, loss: 0.43264086806531116\n",
      "epoche: 344, w1: 5.339704810793344, w2: 1.4844616071510264, bias: -3.128418970930308, loss: 0.432420528904104\n",
      "epoche: 345, w1: 5.349293450288498, w2: 1.4848144174217426, bias: -3.132591360894713, loss: 0.432200984417027\n",
      "epoche: 346, w1: 5.358864655175059, w2: 1.4851670515855362, bias: -3.1367565383284375, loss: 0.43198223113101214\n",
      "epoche: 347, w1: 5.368418467300267, w2: 1.4855195182501113, bias: -3.14091452770566, loss: 0.4317642655905197\n",
      "epoche: 348, w1: 5.377954928430439, w2: 1.4858718258372048, bias: -3.145065353311324, loss: 0.43154708435743805\n",
      "epoche: 349, w1: 5.387474080250458, w2: 1.4862239825857622, bias: -3.1492090392435523, loss: 0.4313306840109841\n",
      "epoche: 350, w1: 5.396975964363283, w2: 1.4865759965550627, bias: -3.1533456094160224, loss: 0.4311150611476053\n",
      "epoche: 351, w1: 5.406460622289472, w2: 1.486927875627794, bias: -3.1574750875603055, loss: 0.43090021238088067\n",
      "epoche: 352, w1: 5.415928095466721, w2: 1.4872796275130755, bias: -3.1615974972281724, loss: 0.4306861343414245\n",
      "epoche: 353, w1: 5.425378425249403, w2: 1.4876312597494346, bias: -3.165712861793862, loss: 0.4304728236767898\n",
      "epoche: 354, w1: 5.434811652908137, w2: 1.487982779707732, bias: -3.1698212044563188, loss: 0.4302602770513713\n",
      "epoche: 355, w1: 5.444227819629357, w2: 1.488334194594043, bias: -3.173922548241393, loss: 0.43004849114631266\n",
      "epoche: 356, w1: 5.453626966514898, w2: 1.4886855114524875, bias: -3.178016916004011, loss: 0.4298374626594092\n",
      "epoche: 357, w1: 5.4630091345815925, w2: 1.4890367371680187, bias: -3.182104330430312, loss: 0.42962718830501645\n",
      "epoche: 358, w1: 5.47237436476088, w2: 1.4893878784691625, bias: -3.18618481403975, loss: 0.4294176648139557\n",
      "epoche: 359, w1: 5.481722697898426, w2: 1.4897389419307154, bias: -3.190258389187171, loss: 0.42920888893342196\n",
      "epoche: 360, w1: 5.491054174753755, w2: 1.4900899339763969, bias: -3.1943250780648498, loss: 0.4290008574268918\n",
      "epoche: 361, w1: 5.500368835999893, w2: 1.4904408608814588, bias: -3.1983849027045053, loss: 0.428793567074033\n",
      "epoche: 362, w1: 5.509666722223023, w2: 1.4907917287752535, bias: -3.202437884979279, loss: 0.42858701467061283\n",
      "epoche: 363, w1: 5.518947873922146, w2: 1.4911425436437586, bias: -3.2064840466056888, loss: 0.4283811970284087\n",
      "epoche: 364, w1: 5.52821233150876, w2: 1.4914933113320625, bias: -3.21052340914555, loss: 0.42817611097511893\n",
      "epoche: 365, w1: 5.537460135306544, w2: 1.491844037546808, bias: -3.2145559940078705, loss: 0.42797175335427334\n",
      "epoche: 366, w1: 5.546691325551055, w2: 1.492194727858597, bias: -3.218581822450715, loss: 0.4277681210251461\n",
      "epoche: 367, w1: 5.555905942389432, w2: 1.4925453877043557, bias: -3.2226009155830444, loss: 0.4275652108626666\n",
      "epoche: 368, w1: 5.565104025880119, w2: 1.4928960223896621, bias: -3.226613294366526, loss: 0.4273630197573345\n",
      "epoche: 369, w1: 5.574285615992582, w2: 1.4932466370910347, bias: -3.2306189796173186, loss: 0.4271615446151313\n",
      "epoche: 370, w1: 5.5834507526070505, w2: 1.4935972368581847, bias: -3.234617992007826, loss: 0.42696078235743595\n",
      "epoche: 371, w1: 5.592599475514262, w2: 1.4939478266162316, bias: -3.2386103520684344, loss: 0.4267607299209387\n",
      "epoche: 372, w1: 5.601731824415214, w2: 1.494298411167882, bias: -3.2425960801892124, loss: 0.4265613842575568\n",
      "epoche: 373, w1: 5.610847838920933, w2: 1.4946489951955741, bias: -3.246575196621596, loss: 0.42636274233434984\n",
      "epoche: 374, w1: 5.619947558552241, w2: 1.4949995832635863, bias: -3.250547721480041, loss: 0.42616480113343697\n",
      "epoche: 375, w1: 5.629031022739539, w2: 1.495350179820112, bias: -3.254513674743658, loss: 0.4259675576519125\n",
      "epoche: 376, w1: 5.638098270822599, w2: 1.495700789199301, bias: -3.2584730762578165, loss: 0.4257710089017649\n",
      "epoche: 377, w1: 5.647149342050364, w2: 1.496051415623267, bias: -3.2624259457357305, loss: 0.425575151909793\n",
      "epoche: 378, w1: 5.656184275580749, w2: 1.4964020632040627, bias: -3.266372302760018, loss: 0.4253799837175261\n",
      "epoche: 379, w1: 5.665203110480464, w2: 1.4967527359456227, bias: -3.27031216678424, loss: 0.42518550138114175\n",
      "epoche: 380, w1: 5.674205885724832, w2: 1.4971034377456758, bias: -3.274245557134414, loss: 0.42499170197138586\n",
      "epoche: 381, w1: 5.683192640197624, w2: 1.497454172397624, bias: -3.2781724930105067, loss: 0.42479858257349257\n",
      "epoche: 382, w1: 5.692163412690896, w2: 1.4978049435923928, bias: -3.282092993487908, loss: 0.42460614028710486\n",
      "epoche: 383, w1: 5.70111824190484, w2: 1.4981557549202509, bias: -3.2860070775188763, loss: 0.4244143722261949\n",
      "epoche: 384, w1: 5.710057166447633, w2: 1.4985066098725999, bias: -3.28991476393397, loss: 0.4242232755189867\n",
      "epoche: 385, w1: 5.718980224835306, w2: 1.4988575118437348, bias: -3.293816071443453, loss: 0.42403284730787705\n",
      "epoche: 386, w1: 5.727887455491607, w2: 1.4992084641325767, bias: -3.2977110186386835, loss: 0.4238430847493584\n",
      "epoche: 387, w1: 5.736778896747882, w2: 1.4995594699443762, bias: -3.3015996239934804, loss: 0.42365398501394197\n",
      "epoche: 388, w1: 5.74565458684296, w2: 1.4999105323923894, bias: -3.305481905865469, loss: 0.4234655452860806\n",
      "epoche: 389, w1: 5.754514563923038, w2: 1.500261654499527, bias: -3.3093578824974106, loss: 0.42327776276409346\n",
      "epoche: 390, w1: 5.763358866041586, w2: 1.5006128391999767, bias: -3.313227572018509, loss: 0.4230906346600896\n",
      "epoche: 391, w1: 5.772187531159246, w2: 1.5009640893407967, bias: -3.3170909924457, loss: 0.4229041581998928\n",
      "epoche: 392, w1: 5.781000597143745, w2: 1.5013154076834876, bias: -3.320948161684924, loss: 0.42271833062296765\n",
      "epoche: 393, w1: 5.789798101769813, w2: 1.5016667969055342, bias: -3.324799097532376, loss: 0.4225331491823444\n",
      "epoche: 394, w1: 5.7985800827191065, w2: 1.5020182596019251, bias: -3.3286438176757405, loss: 0.42234861114454564\n",
      "epoche: 395, w1: 5.807346577580137, w2: 1.5023697982866464, bias: -3.3324823396954084, loss: 0.42216471378951254\n",
      "epoche: 396, w1: 5.8160976238482105, w2: 1.502721415394151, bias: -3.3363146810656765, loss: 0.4219814544105319\n",
      "epoche: 397, w1: 5.824833258925366, w2: 1.503073113280804, bias: -3.3401408591559276, loss: 0.42179883031416404\n",
      "epoche: 398, w1: 5.833553520120329, w2: 1.5034248942263042, bias: -3.3439608912317964, loss: 0.4216168388201706\n",
      "epoche: 399, w1: 5.8422584446484604, w2: 1.5037767604350833, bias: -3.3477747944563174, loss: 0.4214354772614425\n",
      "epoche: 400, w1: 5.850948069631719, w2: 1.5041287140376813, bias: -3.351582585891057, loss: 0.42125474298392895\n",
      "epoche: 401, w1: 5.859622432098625, w2: 1.5044807570920993, bias: -3.355384282497228, loss: 0.4210746333465671\n",
      "epoche: 402, w1: 5.868281568984236, w2: 1.504832891585131, bias: -3.35917990113679, loss: 0.4208951457212106\n",
      "epoche: 403, w1: 5.8769255171301165, w2: 1.505185119433672, bias: -3.3629694585735335, loss: 0.4207162774925612\n",
      "epoche: 404, w1: 5.885554313284325, w2: 1.5055374424860077, bias: -3.366752971474146, loss: 0.42053802605809754\n",
      "epoche: 405, w1: 5.894167994101397, w2: 1.5058898625230794, bias: -3.370530456409268, loss: 0.420360388828007\n",
      "epoche: 406, w1: 5.902766596142342, w2: 1.5062423812597312, bias: -3.374301929854531, loss: 0.42018336322511685\n",
      "epoche: 407, w1: 5.911350155874636, w2: 1.5065950003459347, bias: -3.37806740819158, loss: 0.4200069466848258\n",
      "epoche: 408, w1: 5.919918709672226, w2: 1.5069477213679954, bias: -3.381826907709081, loss: 0.41983113665503596\n",
      "epoche: 409, w1: 5.928472293815536, w2: 1.5073005458497377, bias: -3.38558044460372, loss: 0.4196559305960858\n",
      "epoche: 410, w1: 5.937010944491479, w2: 1.5076534752536714, bias: -3.3893280349811805, loss: 0.4194813259806825\n",
      "epoche: 411, w1: 5.945534697793475, w2: 1.5080065109821392, bias: -3.3930696948571106, loss: 0.4193073202938352\n",
      "epoche: 412, w1: 5.95404358972147, w2: 1.5083596543784443, bias: -3.396805440158077, loss: 0.4191339110327892\n",
      "epoche: 413, w1: 5.962537656181962, w2: 1.5087129067279608, bias: -3.4005352867225054, loss: 0.4189610957069593\n",
      "epoche: 414, w1: 5.971016932988032, w2: 1.5090662692592245, bias: -3.4042592503016054, loss: 0.41878887183786506\n",
      "epoche: 415, w1: 5.979481455859378, w2: 1.5094197431450076, bias: -3.407977346560285, loss: 0.41861723695906494\n",
      "epoche: 416, w1: 5.987931260422351, w2: 1.5097733295033733, bias: -3.4116895910780527, loss: 0.41844618861609134\n",
      "epoche: 417, w1: 5.9963663822100015, w2: 1.5101270293987155, bias: -3.4153959993499035, loss: 0.41827572436638694\n",
      "epoche: 418, w1: 6.004786856662125, w2: 1.5104808438427793, bias: -3.419096586787196, loss: 0.4181058417792403\n",
      "epoche: 419, w1: 6.013192719125314, w2: 1.5108347737956667, bias: -3.4227913687185154, loss: 0.4179365384357215\n",
      "epoche: 420, w1: 6.021584004853009, w2: 1.5111888201668235, bias: -3.4264803603905256, loss: 0.4177678119286198\n",
      "epoche: 421, w1: 6.0299607490055624, w2: 1.5115429838160122, bias: -3.430163576968809, loss: 0.41759965986238023\n",
      "epoche: 422, w1: 6.038322986650297, w2: 1.5118972655542666, bias: -3.4338410335386937, loss: 0.4174320798530409\n",
      "epoche: 423, w1: 6.0466707527615755, w2: 1.512251666144833, bias: -3.437512745106071, loss: 0.41726506952817116\n",
      "epoche: 424, w1: 6.055004082220868, w2: 1.512606186304094, bias: -3.4411787265981997, loss: 0.417098626526809\n",
      "epoche: 425, w1: 6.063323009816826, w2: 1.5129608267024777, bias: -3.444838992864501, loss: 0.41693274849940043\n",
      "epoche: 426, w1: 6.071627570245361, w2: 1.513315587965352, bias: -3.4484935586773418, loss: 0.4167674331077376\n",
      "epoche: 427, w1: 6.079917798109722, w2: 1.513670470673904, bias: -3.452142438732806, loss: 0.4166026780248983\n",
      "epoche: 428, w1: 6.088193727920585, w2: 1.5140254753660047, bias: -3.455785647651457, loss: 0.41643848093518565\n",
      "epoche: 429, w1: 6.096455394096132, w2: 1.51438060253706, bias: -3.459423199979089, loss: 0.4162748395340675\n",
      "epoche: 430, w1: 6.10470283096215, w2: 1.5147358526408468, bias: -3.4630551101874674, loss: 0.4161117515281168\n",
      "epoche: 431, w1: 6.1129360727521185, w2: 1.515091226090335, bias: -3.4666813926750604, loss: 0.4159492146349528\n",
      "epoche: 432, w1: 6.121155153607309, w2: 1.5154467232584976, bias: -3.4703020617677587, loss: 0.4157872265831809\n",
      "epoche: 433, w1: 6.1293601075768835, w2: 1.5158023444791053, bias: -3.473917131719588, loss: 0.4156257851123348\n",
      "epoche: 434, w1: 6.137550968617999, w2: 1.5161580900475091, bias: -3.4775266167134085, loss: 0.41546488797281755\n",
      "epoche: 435, w1: 6.145727770595912, w2: 1.51651396022141, bias: -3.4811305308616083, loss: 0.41530453292584374\n",
      "epoche: 436, w1: 6.153890547284088, w2: 1.5168699552216145, bias: -3.4847288882067846, loss: 0.4151447177433813\n",
      "epoche: 437, w1: 6.162039332364311, w2: 1.51722607523278, bias: -3.4883217027224163, loss: 0.41498544020809497\n",
      "epoche: 438, w1: 6.170174159426802, w2: 1.517582320404145, bias: -3.4919089883135292, loss: 0.41482669811328793\n",
      "epoche: 439, w1: 6.17829506197033, w2: 1.517938690850249, bias: -3.495490758817351, loss: 0.41466848926284616\n",
      "epoche: 440, w1: 6.186402073402336, w2: 1.51829518665164, bias: -3.4990670280039557, loss: 0.414510811471182\n",
      "epoche: 441, w1: 6.194495227039054, w2: 1.5186518078555702, bias: -3.5026378095769033, loss: 0.4143536625631762\n",
      "epoche: 442, w1: 6.2025745561056365, w2: 1.5190085544766792, bias: -3.506203117173867, loss: 0.41419704037412475\n",
      "epoche: 443, w1: 6.210640093736279, w2: 1.5193654264976673, bias: -3.5097629643672534, loss: 0.41404094274968173\n",
      "epoche: 444, w1: 6.218691872974352, w2: 1.5197224238699565, bias: -3.513317364664817, loss: 0.4138853675458042\n",
      "epoche: 445, w1: 6.226729926772533, w2: 1.5200795465143406, bias: -3.5168663315102604, loss: 0.4137303126286979\n",
      "epoche: 446, w1: 6.23475428799294, w2: 1.5204367943216255, bias: -3.520409878283833, loss: 0.4135757758747625\n",
      "epoche: 447, w1: 6.24276498940727, w2: 1.520794167153256, bias: -3.523948018302918, loss: 0.413421755170537\n",
      "epoche: 448, w1: 6.250762063696933, w2: 1.5211516648419356, bias: -3.527480764822612, loss: 0.4132682484126463\n",
      "epoche: 449, w1: 6.258745543453199, w2: 1.5215092871922336, bias: -3.5310081310362977, loss: 0.4131152535077473\n",
      "epoche: 450, w1: 6.266715461177338, w2: 1.5218670339811822, bias: -3.5345301300762086, loss: 0.41296276837247564\n",
      "epoche: 451, w1: 6.274671849280764, w2: 1.5222249049588648, bias: -3.5380467750139863, loss: 0.4128107909333923\n",
      "epoche: 452, w1: 6.282614740085187, w2: 1.5225828998489928, bias: -3.54155807886123, loss: 0.41265931912693177\n",
      "epoche: 453, w1: 6.290544165822757, w2: 1.5229410183494743, bias: -3.545064054570041, loss: 0.4125083508993485\n",
      "epoche: 454, w1: 6.298460158636219, w2: 1.5232992601329716, bias: -3.5485647150335544, loss: 0.41235788420666564\n",
      "epoche: 455, w1: 6.306362750579065, w2: 1.5236576248474507, bias: -3.552060073086471, loss: 0.4122079170146228\n",
      "epoche: 456, w1: 6.314251973615687, w2: 1.5240161121167204, bias: -3.555550141505578, loss: 0.41205844729862445\n",
      "epoche: 457, w1: 6.3221278596215384, w2: 1.524374721540963, bias: -3.5590349330102633, loss: 0.4119094730436892\n",
      "epoche: 458, w1: 6.329990440383288, w2: 1.5247334526972565, bias: -3.5625144602630225, loss: 0.41176099224439777\n",
      "epoche: 459, w1: 6.337839747598982, w2: 1.525092305140086, bias: -3.5659887358699622, loss: 0.4116130029048436\n",
      "epoche: 460, w1: 6.345675812878207, w2: 1.5254512784018486, bias: -3.5694577723812935, loss: 0.41146550303858137\n",
      "epoche: 461, w1: 6.3534986677422545, w2: 1.525810371993349, bias: -3.5729215822918206, loss: 0.4113184906685779\n",
      "epoche: 462, w1: 6.361308343624283, w2: 1.5261695854042858, bias: -3.5763801780414233, loss: 0.4111719638271611\n",
      "epoche: 463, w1: 6.369104871869486, w2: 1.5265289181037314, bias: -3.5798335720155325, loss: 0.41102592055597137\n",
      "epoche: 464, w1: 6.376888283735263, w2: 1.5268883695406013, bias: -3.5832817765456, loss: 0.41088035890591207\n",
      "epoche: 465, w1: 6.384658610391386, w2: 1.5272479391441176, bias: -3.5867248039095623, loss: 0.41073527693710066\n",
      "epoche: 466, w1: 6.392415882920174, w2: 1.527607626324264, bias: -3.5901626663322967, loss: 0.4105906727188196\n",
      "epoche: 467, w1: 6.400160132316663, w2: 1.5279674304722317, bias: -3.5935953759860753, loss: 0.4104465443294683\n",
      "epoche: 468, w1: 6.407891389488782, w2: 1.52832735096086, bias: -3.5970229449910103, loss: 0.41030288985651486\n",
      "epoche: 469, w1: 6.415609685257528, w2: 1.528687387145067, bias: -3.6004453854154934, loss: 0.41015970739644814\n",
      "epoche: 470, w1: 6.423315050357144, w2: 1.5290475383622752, bias: -3.603862709276631, loss: 0.4100169950547296\n",
      "epoche: 471, w1: 6.431007515435295, w2: 1.5294078039328274, bias: -3.6072749285406744, loss: 0.4098747509457475\n",
      "epoche: 472, w1: 6.438687111053248, w2: 1.5297681831603978, bias: -3.6106820551234415, loss: 0.40973297319276764\n",
      "epoche: 473, w1: 6.446353867686057, w2: 1.5301286753323944, bias: -3.6140841008907363, loss: 0.40959165992788854\n",
      "epoche: 474, w1: 6.454007815722736, w2: 1.530489279720355, bias: -3.6174810776587623, loss: 0.4094508092919936\n",
      "epoche: 475, w1: 6.461648985466452, w2: 1.5308499955803374, bias: -3.6208729971945295, loss: 0.40931041943470536\n",
      "epoche: 476, w1: 6.469277407134701, w2: 1.5312108221533003, bias: -3.6242598712162573, loss: 0.4091704885143392\n",
      "epoche: 477, w1: 6.476893110859499, w2: 1.5315717586654807, bias: -3.627641711393772, loss: 0.4090310146978577\n",
      "epoche: 478, w1: 6.4844961266875645, w2: 1.531932804328762, bias: -3.6310185293489003, loss: 0.40889199616082517\n",
      "epoche: 479, w1: 6.492086484580508, w2: 1.5322939583410387, bias: -3.634390336655856, loss: 0.4087534310873621\n",
      "epoche: 480, w1: 6.499664214415019, w2: 1.532655219886571, bias: -3.6377571448416224, loss: 0.4086153176701008\n",
      "epoche: 481, w1: 6.507229345983058, w2: 1.5330165881363376, bias: -3.6411189653863323, loss: 0.40847765411013964\n",
      "epoche: 482, w1: 6.514781908992042, w2: 1.5333780622483781, bias: -3.6444758097236396, loss: 0.4083404386169994\n",
      "epoche: 483, w1: 6.522321933065038, w2: 1.5337396413681335, bias: -3.6478276892410895, loss: 0.40820366940857855\n",
      "epoche: 484, w1: 6.52984944774096, w2: 1.534101324628777, bias: -3.651174615280482, loss: 0.4080673447111098\n",
      "epoche: 485, w1: 6.537364482474753, w2: 1.5344631111515414, bias: -3.6545165991382307, loss: 0.40793146275911535\n",
      "epoche: 486, w1: 6.544867066637592, w2: 1.534825000046041, bias: -3.6578536520657203, loss: 0.40779602179536417\n",
      "epoche: 487, w1: 6.552357229517078, w2: 1.5351869904105861, bias: -3.6611857852696557, loss: 0.4076610200708289\n",
      "epoche: 488, w1: 6.559835000317428, w2: 1.5355490813324928, bias: -3.6645130099124095, loss: 0.40752645584464187\n",
      "epoche: 489, w1: 6.567300408159678, w2: 1.5359112718883883, bias: -3.6678353371123635, loss: 0.40739232738405295\n",
      "epoche: 490, w1: 6.5747534820818725, w2: 1.5362735611445093, bias: -3.6711527779442483, loss: 0.4072586329643874\n",
      "epoche: 491, w1: 6.582194251039268, w2: 1.5366359481569964, bias: -3.674465343439476, loss: 0.4071253708690027\n",
      "epoche: 492, w1: 6.5896227439045285, w2: 1.5369984319721828, bias: -3.6777730445864716, loss: 0.40699253938924673\n",
      "epoche: 493, w1: 6.597038989467926, w2: 1.5373610116268774, bias: -3.6810758923309974, loss: 0.4068601368244164\n",
      "epoche: 494, w1: 6.6044430164375365, w2: 1.5377236861486439, bias: -3.6843738975764775, loss: 0.40672816148171564\n",
      "epoche: 495, w1: 6.611834853439445, w2: 1.5380864545560742, bias: -3.6876670711843134, loss: 0.40659661167621397\n",
      "epoche: 496, w1: 6.6192145290179445, w2: 1.5384493158590575, bias: -3.6909554239742, loss: 0.4064654857308056\n",
      "epoche: 497, w1: 6.626582071635735, w2: 1.538812269059044, bias: -3.6942389667244355, loss: 0.40633478197616846\n",
      "epoche: 498, w1: 6.633937509674128, w2: 1.5391753131493042, bias: -3.6975177101722294, loss: 0.40620449875072356\n",
      "epoche: 499, w1: 6.641280871433249, w2: 1.5395384471151843, bias: -3.700791665014005, loss: 0.4060746344005942\n",
      "epoche: 500, w1: 6.648612185132239, w2: 1.5399016699343555, bias: -3.704060841905698, loss: 0.40594518727956647\n",
      "epoche: 501, w1: 6.655931478909459, w2: 1.5402649805770603, bias: -3.7073252514630552, loss: 0.40581615574904806\n",
      "epoche: 502, w1: 6.663238780822692, w2: 1.5406283780063534, bias: -3.7105849042619248, loss: 0.4056875381780301\n",
      "epoche: 503, w1: 6.670534118849351, w2: 1.5409918611783389, bias: -3.713839810838546, loss: 0.4055593329430463\n",
      "epoche: 504, w1: 6.6778175208866815, w2: 1.541355429042403, bias: -3.717089981689836, loss: 0.40543153842813406\n",
      "epoche: 505, w1: 6.6850890147519655, w2: 1.5417190805414422, bias: -3.720335427273671, loss: 0.40530415302479555\n",
      "epoche: 506, w1: 6.692348628182729, w2: 1.5420828146120886, bias: -3.7235761580091657, loss: 0.40517717513195844\n",
      "epoche: 507, w1: 6.699596388836947, w2: 1.542446630184929, bias: -3.726812184276949, loss: 0.40505060315593766\n",
      "epoche: 508, w1: 6.706832324293252, w2: 1.5428105261847216, bias: -3.730043516419437, loss: 0.40492443551039653\n",
      "epoche: 509, w1: 6.714056462051136, w2: 1.5431745015306093, bias: -3.7332701647411026, loss: 0.40479867061630886\n",
      "epoche: 510, w1: 6.721268829531163, w2: 1.5435385551363272, bias: -3.7364921395087403, loss: 0.4046733069019206\n",
      "epoche: 511, w1: 6.728469454075171, w2: 1.5439026859104077, bias: -3.7397094509517315, loss: 0.4045483428027125\n",
      "epoche: 512, w1: 6.735658362946483, w2: 1.5442668927563814, bias: -3.7429221092623033, loss: 0.4044237767613619\n",
      "epoche: 513, w1: 6.742835583330113, w2: 1.5446311745729748, bias: -3.7461301245957865, loss: 0.40429960722770586\n",
      "epoche: 514, w1: 6.750001142332976, w2: 1.5449955302543037, bias: -3.7493335070708693, loss: 0.4041758326587037\n",
      "epoche: 515, w1: 6.757155066984095, w2: 1.5453599586900633, bias: -3.7525322667698484, loss: 0.40405245151840036\n",
      "epoche: 516, w1: 6.764297384234808, w2: 1.5457244587657146, bias: -3.755726413738879, loss: 0.40392946227788895\n",
      "epoche: 517, w1: 6.771428120958982, w2: 1.5460890293626686, bias: -3.758915957988218, loss: 0.4038068634152747\n",
      "epoche: 518, w1: 6.7785473039532125, w2: 1.5464536693584647, bias: -3.76210090949247, loss: 0.40368465341563914\n",
      "epoche: 519, w1: 6.785654959937043, w2: 1.5468183776269484, bias: -3.765281278190825, loss: 0.40356283077100263\n",
      "epoche: 520, w1: 6.792751115553166, w2: 1.5471831530384437, bias: -3.768457073987296, loss: 0.40344139398028933\n",
      "epoche: 521, w1: 6.799835797367638, w2: 1.5475479944599233, bias: -3.771628306750955, loss: 0.40332034154929136\n",
      "epoche: 522, w1: 6.806909031870086, w2: 1.5479129007551753, bias: -3.7747949863161647, loss: 0.40319967199063317\n",
      "epoche: 523, w1: 6.813970845473917, w2: 1.5482778707849671, bias: -3.7779571224828072, loss: 0.4030793838237356\n",
      "epoche: 524, w1: 6.821021264516529, w2: 1.548642903407206, bias: -3.7811147250165122, loss: 0.4029594755747824\n",
      "epoche: 525, w1: 6.828060315259519, w2: 1.5490079974770963, bias: -3.7842678036488806, loss: 0.402839945776683\n",
      "epoche: 526, w1: 6.835088023888895, w2: 1.5493731518472942, bias: -3.787416368077707, loss: 0.4027207929690396\n",
      "epoche: 527, w1: 6.842104416515285, w2: 1.5497383653680594, bias: -3.7905604279671987, loss: 0.40260201569811166\n",
      "epoche: 528, w1: 6.849109519174148, w2: 1.5501036368874042, bias: -3.7936999929481936, loss: 0.4024836125167818\n",
      "epoche: 529, w1: 6.856103357825979, w2: 1.5504689652512385, bias: -3.796835072618374, loss: 0.4023655819845216\n",
      "epoche: 530, w1: 6.863085958356525, w2: 1.5508343493035144, bias: -3.79996567654248, loss: 0.4022479226673578\n",
      "epoche: 531, w1: 6.870057346576993, w2: 1.5511997878863653, bias: -3.803091814252518, loss: 0.40213063313783776\n",
      "epoche: 532, w1: 6.87701754822426, w2: 1.5515652798402444, bias: -3.806213495247971, loss: 0.40201371197499725\n",
      "epoche: 533, w1: 6.883966588961082, w2: 1.5519308240040597, bias: -3.8093307289960014, loss: 0.4018971577643253\n",
      "epoche: 534, w1: 6.890904494376304, w2: 1.552296419215306, bias: -3.8124435249316564, loss: 0.4017809690977324\n",
      "epoche: 535, w1: 6.897831289985072, w2: 1.552662064310195, bias: -3.815551892458068, loss: 0.40166514457351654\n",
      "epoche: 536, w1: 6.9047470012290395, w2: 1.5530277581237835, bias: -3.818655840946652, loss: 0.4015496827963311\n",
      "epoche: 537, w1: 6.911651653476581, w2: 1.553393499490097, bias: -3.8217553797373056, loss: 0.4014345823771512\n",
      "epoche: 538, w1: 6.918545272022999, w2: 1.5537592872422532, bias: -3.8248505181386014, loss: 0.4013198419332423\n",
      "epoche: 539, w1: 6.925427882090735, w2: 1.5541251202125814, bias: -3.82794126542798, loss: 0.40120546008812685\n",
      "epoche: 540, w1: 6.932299508829577, w2: 1.5544909972327405, bias: -3.8310276308519415, loss: 0.40109143547155307\n",
      "epoche: 541, w1: 6.939160177316873, w2: 1.5548569171338344, bias: -3.8341096236262335, loss: 0.400977766719462\n",
      "epoche: 542, w1: 6.946009912557738, w2: 1.555222878746525, bias: -3.837187252936037, loss: 0.40086445247395674\n",
      "epoche: 543, w1: 6.952848739485261, w2: 1.5555888809011431, bias: -3.840260527936153, loss: 0.4007514913832703\n",
      "epoche: 544, w1: 6.959676682960717, w2: 1.5559549224277973, bias: -3.843329457751183, loss: 0.4006388821017339\n",
      "epoche: 545, w1: 6.966493767773776, w2: 1.5563210021564797, bias: -3.8463940514757113, loss: 0.40052662328974625\n",
      "epoche: 546, w1: 6.9733000186427105, w2: 1.5566871189171714, bias: -3.849454318174484, loss: 0.40041471361374253\n",
      "epoche: 547, w1: 6.980095460214605, w2: 1.5570532715399432, bias: -3.8525102668825846, loss: 0.4003031517461628\n",
      "epoche: 548, w1: 6.986880117065563, w2: 1.5574194588550574, bias: -3.855561906605611, loss: 0.40019193636542205\n",
      "epoche: 549, w1: 6.993654013700917, w2: 1.5577856796930647, bias: -3.858609246319848, loss: 0.40008106615587885\n",
      "epoche: 550, w1: 7.000417174555437, w2: 1.558151932884901, bias: -3.8616522949724397, loss: 0.3999705398078057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.000417174555437, 1.558151932884901, -3.8616522949724397)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradienten_abstieg(X['age'], X['affordibility'], y.to_numpy(), epochs=2500, loss_thr=0.4, lr=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710ddfa-9539-4870-b9a0-5f01c11e3d3c",
   "metadata": {},
   "source": [
    "Damit kann jetzt eine Klasse erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "619e18c6-e81b-4e38-b559-4b47a911005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einfaches Netz\n",
    "# - Angepasst für den Versuch.\n",
    "class my_nn():\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.bias  = 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Wie oben: Summe und dann Funktion anwenden.\n",
    "        weight_sum = (self.w1 * X_test['age'] + self.w2 * X_test['affordibility'] + self.bias)  \n",
    "        return sigmoid_funk(weight_sum)\n",
    "\n",
    "    def fit(self, X, y, epochs):\n",
    "        self.w1, self.w2, self.bias = self.gradienten_abstieg( X['age'], X['affordibility'], y, epochs)\n",
    "\n",
    "        \n",
    "    def gradienten_abstieg(self, age, afford, y_true, epochs, loss_thr:float=2.0, lr:float=0.01):\n",
    "        w1   = w2 = 1  # Random, meist mit 1. \n",
    "        bias = 0  # Meist mit 0 \n",
    "        n = len(afford) \n",
    "        for i in range(int(epochs)):   \n",
    "            weight_sum = self.w1 * age + self.w2 * afford + self.bias  # Vektor Operation.\n",
    "            y_pred = sigmoid_funk(weight_sum)  # Aktivierungsfunktion.\n",
    "            loss = logloss(y_pred, y_true)\n",
    "            w1d =  (1/n) * np.dot(np.transpose(age) ,    (y_pred-y_true))           \n",
    "            w2d =  (1/n) * np.dot(np.transpose(afford) , (y_pred-y_true)) \n",
    "            bias_d = np.mean(y_pred-y_true)\n",
    "            self.w1 = self.w1 - lr * w1d  # Formel von Oben.\n",
    "            self.w2 = self.w2 - lr * w2d  # - Hier werden die Gewichte angepasst - Die ganze Magie dahinter. \n",
    "            self.bias = self.bias - lr *bias_d\n",
    "\n",
    "            if i%100==0:\n",
    "                print(f\"epoche: {i}, w1: {self.w1}, w2: {self.w2}, bias: {self.bias}, loss: {loss}\")\n",
    "            \n",
    "        return self.w1, self.w2, self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4041db16-143d-4324-81cb-86198143fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, w1: 0.9995256991514374, w2: 0.9988276331757626, bias: -0.0023446438289389552, loss: 0.71595572538616\n",
      "epoche: 100, w1: 0.9632313469977409, w2: 0.9008775541087021, bias: -0.20843013437288502, loss: 0.6619327284009086\n",
      "epoche: 200, w1: 0.9463485553759833, w2: 0.8370701880535407, bias: -0.3652806910274291, loss: 0.632575560887126\n",
      "epoche: 300, w1: 0.9444504004015485, w2: 0.7999211539363223, bias: -0.4842577485735926, loss: 0.6168202751035144\n",
      "epoche: 400, w1: 0.9534266271505314, w2: 0.7820864281235341, bias: -0.5757101431428063, loss: 0.6079502711195035\n"
     ]
    }
   ],
   "source": [
    "my_mdoel = my_nn()\n",
    "my_mdoel.fit(X, y, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c33db6-210c-41b6-ac85-637c14a9185b",
   "metadata": {},
   "source": [
    "<h1>Stochastik Gradient, Batch Gradient und Mini-Batch Gradient</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43cc84-f8aa-4a0d-9409-f084b4fd288f",
   "metadata": {},
   "source": [
    "Bei dem oberen Beispiel wurde alle Samples für das Training genutzt. Das war der Batch Gradientenabstieg.\n",
    "Nachteil ist, dass bei einem großen Dataset vorher durch alle Samples iteriert werden muss, bevor die Anpassung der Weights erfolg, das kann lange dauern.\n",
    "\n",
    "\n",
    "Bei dem stochastischen Gradientenabstieg (<b>SGD</b>) wird per Zufall ein Sample ausgewählt und dann Backpropagiert. Bei großen Datasets spart man Zeit, indem man jedes Sample nimmt und eine Anpassung durchführt, und nicht erst durch alle durchgeht. \n",
    "\n",
    "Bei dem Ansatz Mini-Batch Gradientenabstieg werden n-Batches genommen, die aus m-zufälligen Samples bestehen. Bei einem Dataset der Größe 100 und der Batch-Größe 20 gibt es 5 Batches die je aus 20 zufällig ausgewählten Samples bestehen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c386c7-752f-4fa5-ad52-481504e2c7b0",
   "metadata": {},
   "source": [
    "<i>Abb5</i>: Batch, Mini-Batch und stochastischen Gradientenabstieg.\n",
    "\n",
    "<img src=\"./img/nn_8.PNG\" width=700 hight=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "462291cc-bc79-4939-bf80-89bd453c0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Loss:\n",
    "# - Mit Numpy, von Oben\n",
    "def logloss(y_pred, y_true):\n",
    "    # Weil log(0) nicht definiert ist => Wert nah bei 0 nehmen.\n",
    "    eps = 1e-15\n",
    "    y_pred2 = max(y_pred, eps)   \n",
    "    y_pred2 = min(y_pred2, 1-eps) \n",
    "    y_pred2 = np.array(y_pred2)\n",
    "\n",
    "    return -np.mean(\\\n",
    "        y_true * np.log(y_pred2) + (1-y_true) * np.log(1 - y_pred2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0fc004ef-e5db-4c18-ac77-a69211523dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "# - Wähle zufälliges Sample und führe Anpassung durch. \n",
    "def stochastik_gradienten_abstieg(X, y_true, epochs, loss_thr:float=2.0, lr:float=0.01):\n",
    "    w1   = w2 = 1   \n",
    "    bias = 0 \n",
    "    n = X.shape[0]  # Anzahl Einträge\n",
    "\n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        random_index = random.randint(0, n-1)  # Ziehe Sample. \n",
    "        \n",
    "        sample_x = X.iloc[random_index]  # Mit iloc auf Zeile zugreifen.\n",
    "        sample_y = y_true[random_index]\n",
    "\n",
    "        # Summe und Funktion\n",
    "        weight_sum = w1 * sample_x['age'] + w2 * sample_x['affordibility'] + bias\n",
    "        y_pred = sigmoid_funk(weight_sum)  # Aktivierungsfunktion. \n",
    "\n",
    "        loss = logloss(y_pred, sample_y)\n",
    "\n",
    "        w1d =  (1/n) * np.dot(np.transpose(sample_x['age']) ,           (y_pred-sample_y))           \n",
    "        w2d =  (1/n) * np.dot(np.transpose(sample_x['affordibility']) , (y_pred-sample_y)) \n",
    "        bias_d = np.mean(y_pred-y_true)\n",
    "\n",
    "        w1 = w1 - lr * w1d \n",
    "        w2 = w2 - lr * w2d  \n",
    "        bias = bias - lr * bias_d\n",
    "        \n",
    "        if i % 100 ==0:\n",
    "            cost_list.append(loss)\n",
    "            epoch_list.append(i)\n",
    "    return w1, w2, bias, loss, cost_list, epoch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "66b83803-1943-40e7-b2fc-08ae58c8185f",
   "metadata": {},
   "outputs": [],
   "source": [
    "w1, w2, bias, loss, cost_list, epoch_list = stochastik_gradienten_abstieg(X, y, 2500, loss_thr=0.4, lr=0.5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "ebaf7869-124d-4c1a-9adb-18d37971409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2be6ee8a1c0>]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "139b9b77-9c98-4c57-93cb-0fe9ef7968bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Loss:\n",
    "# - Mit Numpy\n",
    "def logloss(y_pred, y_true):\n",
    "    # Weil log(0) nicht definiert ist => Wert nah bei 0 nehmen.\n",
    "    eps = 1e-15\n",
    "    y_pred = [max(i, eps)    for i in y_pred ]\n",
    "    y_pred = [min(i, 1-eps)  for i in y_pred ]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return -np.mean(\\\n",
    "        y_true * np.log(y_pred) + (1-y_true) * np.log(1 - y_pred ) )\n",
    "    \n",
    "# Mini-Batch Gradientenasbtieg. \n",
    "def mini_batch_gradienten_abstieg(X, y_true, epochs, batch_size:int=5, loss_thr:float=2.0, lr:float=0.01):\n",
    "    w1   = w2 = 1   \n",
    "    bias = 0 \n",
    "    n = X.shape[0]  # Anzahl Einträge\n",
    "    \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    # Wenn Batchgröße ist als n, dann nehme ganzes Dataset.\n",
    "    if batch_size > n: \n",
    "        batch_size = n\n",
    "        \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    # Anzahl der Batches.\n",
    "    num_batches = int(n/batch_size)\n",
    "    \n",
    "    for i in range(epochs):  \n",
    "        \n",
    "        random_indices = np.random.permutation(n)  # Zufällige Ziehungenm. \n",
    "        X_samples = X.iloc[random_indices]      # X und y Ziehungen müssen mit dem Index passen. \n",
    "        y_samples = y_true[random_indices]\n",
    "        \n",
    "        for j in range(0, n ,batch_size):\n",
    "            \n",
    "            X_s = X_samples.iloc[j:j+batch_size]  # Batch mit Samples.\n",
    "            y_s = y_samples[j:j+batch_size]  # Batch mit Samples.\n",
    "            # Summe und Aktivierungsfunktion.\n",
    "            weight_sum = w1 * X_s['age'] + w2 * X_s['affordibility'] + bias\n",
    "            y_pred = sigmoid_funk(weight_sum)\n",
    "\n",
    "            loss = logloss(y_pred, y_s)\n",
    "                 \n",
    "            w1d =  (1/n) * np.dot(np.transpose(X_s['age']) ,           (y_pred-y_s))           \n",
    "            w2d =  (1/n) * np.dot(np.transpose(X_s['affordibility']) , (y_pred-y_s)) \n",
    "            bias_d = np.mean(y_pred-y_s)\n",
    "\n",
    "            w1 = w1 - lr * w1d \n",
    "            w2 = w2 - lr * w2d  \n",
    "            bias = bias - lr * bias_d\n",
    "                \n",
    "        if i%100==0:\n",
    "            cost_list.append(loss)\n",
    "            epoch_list.append(i)\n",
    "            #print(f'loss: {loss}')\n",
    "        \n",
    "    return w1, w2, bias, loss, cost_list, epoch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "78b855a7-5319-4c05-b327-358269d7e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.7582444415793739\n",
      "loss: 0.2555338246070278\n",
      "loss: 0.412687775523207\n",
      "loss: 0.39647603857669456\n",
      "loss: 0.5569474936378678\n",
      "loss: 0.3476145923525681\n",
      "loss: 0.3459761259610376\n",
      "loss: 0.4881524011038817\n",
      "loss: 0.15434763540215185\n",
      "loss: 0.25358228181536824\n",
      "loss: 0.23080083520547456\n",
      "loss: 0.2729239573422138\n",
      "loss: 0.47810929169756783\n",
      "loss: 0.3786095928600351\n",
      "loss: 0.24177863846486813\n",
      "loss: 0.18947029768702583\n",
      "loss: 0.34328135227153184\n",
      "loss: 0.20789809345233629\n",
      "loss: 0.2702316835408507\n",
      "loss: 0.4207338232720934\n",
      "loss: 0.6072564575781054\n",
      "loss: 0.34069826131933245\n",
      "loss: 0.1734224081900811\n",
      "loss: 0.13483264040889575\n",
      "loss: 0.1633108907815123\n"
     ]
    }
   ],
   "source": [
    "w1, w2, bias, loss, cost_list, epoch_list = mini_batch_gradienten_abstieg(X, y, 2500, batch_size=2, loss_thr=0.4, lr=0.5)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "72c12458-9979-4d46-b070-8759b5c63d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2be6eececa0>]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, cost_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb21cb9d-1416-4f03-90e3-8a126afb3ab4",
   "metadata": {},
   "source": [
    "<h1>Numpy-Matrix und Sonstiges</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9bbb451-c89c-466a-b782-e5997eec106a",
   "metadata": {},
   "source": [
    "Mithilfe der Matrixoperationen mit Numpy können wir den Code vereinfachen und etwas verallgemeinern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4cb2c-672b-4793-ac4a-9addb5ef4782",
   "metadata": {},
   "source": [
    "Beispiele für (Vektor-) Matrixoperationen (später in Numpy):\n",
    "\n",
    "<i>Abb5</i>: Matrix-Vektor-Multiplikation.\n",
    "\n",
    "<img src=\"./img/nn_9.PNG\" width=600 hight=300>\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{bmatrix} 2 & -1 & -1 \\\\ 1 & 1 & 4 \\end{bmatrix} \\ * \\begin{bmatrix} 2 \\\\ 3 \\\\ 0  \\end{bmatrix}\n",
    "=  \\begin{bmatrix} 1 \\\\ 5 \\\\   \\end{bmatrix}\n",
    "$  \n",
    "\n",
    "$\n",
    "\\begin{bmatrix} 2 & -1 & -1 \\end{bmatrix} \\ * \\begin{bmatrix} 2 \\\\ 3 \\\\ 0  \\end{bmatrix}\n",
    "=  \\begin{bmatrix} 1    \\end{bmatrix}\n",
    "$  \n",
    "\n",
    "----\n",
    "\n",
    "\n",
    "$\n",
    "\\begin{bmatrix} 2 & 3 & -1 \\\\ 1 & 0 & -1\\end{bmatrix} \\ + \\begin{bmatrix} -1 & 0 & 2 \\\\ 1 & 1 & 1  \\end{bmatrix}\n",
    "=  \\begin{bmatrix} 2 & 3 & 1 \\\\ 2 & 1 & 0    \\end{bmatrix}\n",
    "$  \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "<i>Abb</i>: Matrix-Vektor-Multiplikation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "379c5cf4-91a9-46e1-b7d6-72fc86eae59e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e84a954-fc11-4150-b6c2-4122d0cd4df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7070a3d3-dbd3-416d-8b17-ec6f7262c27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98003682-d7ca-4ba6-b8ef-5ebe0993a14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c33152dd-1ca3-4322-a7ba-d448094d0fa1",
   "metadata": {},
   "source": [
    "Kettenregel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161fca2-3d63-4c21-b51f-2f7a1747f52c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1298338a-2e3f-4181-a2e7-7dddfea3207c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6f6db6-caa0-404d-849d-4857869cd37c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70d6713-0fc0-427a-b85d-4180dc5d19bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5307607b-9eba-46c4-9fe9-db2195ac115e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d4bf370-c10d-4bd5-9d08-fa42c7bc6f68",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c32d2a3-7684-460f-acaa-17a3b94e1ac8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b225b6a0-c431-41b4-87d5-c63c1253f75d",
   "metadata": {},
   "source": [
    "Tensorflow bietet eine gute Auswahl an Methoden, um das Minimum zu finden und um die Weights anzupassen. Beim Kompilieren kann der Optimierer eingestellt werden, z. B. SGD.\n",
    "\n",
    "Einige dieser Methoden haben nehmen auch Parameter entgegen wie die Learning-rate.\n",
    "\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/optimizers [Letzter Zugriff: 25.06.2024]\n",
    "\n",
    "Es gibt auch einige gute Artikel und Videos die verschiedene Optimierer vergleichen.\n",
    "\n",
    "> Who's Adam and What's He Optimizing? https://www.youtube.com/watch?v=MD2fYip6QsQ&t=0s [Letzter Zugriff: 25.06.2024]\n",
    "\n",
    "> Courage to Learn ML: A Detailed Exploration of Gradient Descent and Popular Optimizers: https://medium.com/towards-data-science/courage-to-learn-ml-a-detailed-exploration-of-gradient-descent-and-popular-optimizers-022ecf97be7d [Letzter Zugriff: 25.06.2024]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae2fbd5-3dfa-4053-bb88-be7414af130f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ead9e822-aae8-4ef4-b661-674598f40976",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
