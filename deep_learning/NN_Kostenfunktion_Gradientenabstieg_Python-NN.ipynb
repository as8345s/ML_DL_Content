{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5465b81-b364-4369-b8d8-e7d921814906",
   "metadata": {},
   "source": [
    "<h1>Kostenfunktion - Gradientenabstieg</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0c5276-664b-48a0-8f3d-67c614b88b71",
   "metadata": {},
   "source": [
    "Loss oder auch Kostenfunkton ist ein sehr wichtiger Bestandteil, wenn es um Deep-Learning und Maschine-Learning geht. Durch das Berechnen der Abweichung des Ergebnisses von der Wahrheit (y_predicted und y_true), kann festgestellt werden wie falsch die prediction ist.\n",
    "\n",
    "Beim Trainieren soll diese Abweichung möglichst minimiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec39b0b-17a2-4a85-a200-f4150f3725d6",
   "metadata": {},
   "source": [
    "Um diese Abweichung zu berechnen gibt es verschiedene Funktionen. Die Funktion MSE ist z. B. sehr bekannt. \n",
    "\n",
    "Es ist ein interessantes Thema, für das es auch viele gute Artikel zum Nachlesen gibt."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9113a1e7-a61d-4180-8445-971b8f89f5a0",
   "metadata": {},
   "source": [
    "<i>Abb1</i>: Eingabe der Features in ein einziges Neuron. Jedes Neuron hat 2 Komponente.\n",
    "\n",
    "<img src=\"./img/nn_1.PNG\" width=600 hight=400>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aab02a8-e44a-4ea9-9bed-1e604b39e975",
   "metadata": {},
   "source": [
    "Das Netz startet mit einer bestimmten Initialisierung der Gewichte, wie in der Abbildung 1 zusehen ist. Diese können mit 1 starten, oder mit jeder anderen beliebigen Zahl. Bias wird oft mit 0 initialisiert. In der Erstes Epoche (oder Batch) performt das Netz sehr schlecht, erst nach der Erfassung des Fehlers und deren Reduzierung durch das Finden des Minimums, verbessert sich die Genauigkeit durch das Anpassen dieser Gewichte.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05f858-0be9-4af4-9bbc-88cc323e1b8d",
   "metadata": {},
   "source": [
    "<i>Abb2</i>: MSE und MAE.\n",
    "\n",
    "<img src=\"./img/nn_5.PNG\" width=600 hight=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3225e3-44b6-4f8f-8d6c-6e2732e166c6",
   "metadata": {},
   "source": [
    "MSE ist z. B. nützlich, wenn es negative Werte gibt.\n",
    "\n",
    "Es gibt viele Kostenfunktionen für verschiedene Einsätze. Frameworks wie Tensorflow bieten eine gute Übersicht der verfügbaren Kostenfunktionen, die während des Trainings genutzt werden können.\n",
    ">https://www.tensorflow.org/api_docs/python/tf/keras/losses [Letzter Zugriff: 24.06.2024]\n",
    "\n",
    "\n",
    "Wie auch bei den Aktivierungsfunktionen können diese einfach in Python umgesetzt werden, wenn man der Formel folgt.\n",
    "\n",
    "Einige dieser Kostenfunktionen haben Parameter die eingestellt werden könne. Die Funktion Log-Loss, auch genannt Binary-Crossentropy, hat solche Parameter\n",
    "\n",
    "> https://www.tensorflow.org/api_docs/python/tf/keras/losses/BinaryCrossentropy [Letzter Zugriff: 24.06.2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1544b165-68c4-466f-a205-6c15c1d38cc9",
   "metadata": {},
   "source": [
    "Der Einsatz von Log-Loss findet Platz bei Klassifizierungsproblemen, wo der Output des Netzes eine Wahrscheinlichkeit für eine Klasse ist. \n",
    "Dabei befinden sich die Werte zwichen 0 und 1 (Output ist Binär). Bei Multiclass-Klassifizierungen und der Aktivierungsfunktion Softmax wird Log-Loss ebenfalls eingesetzt.  \n",
    "\n",
    "Die Formel für Log-Loss ist (Binär): <br>\n",
    "\n",
    "$\n",
    "- \\frac{1}{n} \\ \\sum_{i=0}^{n} y_i \\log(\\hat{y}_i) + (1 - y_i) * log(1 - \\hat{y}_i)\n",
    "$\n",
    "\n",
    "Basierend auf der Funktion soll der Fehler minimiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2bae93-2092-48b7-966c-61aa674033a4",
   "metadata": {},
   "source": [
    "<h2>Kostenfunktion als Code</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "12e46b5d-132e-41fb-822c-767fdba910c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7dc4ca00-3e0d-4d84-bb74-229e9a633a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = [1, 0, 1, 0, 1]\n",
    "y_pred = [0.5, 0.3, 0.7, 0.2, 0.8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4db74182-106b-4647-b1c0-5771f692ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mit Numpy einfach umsetzbar. \n",
    "def MSE_1(y_pred:np.array, y_true:np.array):\n",
    "    return np.mean( np.square(y_pred - y_true) )\n",
    "\n",
    "# Ohne Numpy\n",
    "def MSE_2(y_pred, y_true):\n",
    "    tot_error = 0\n",
    "\n",
    "    for yp, yt in zip(y_pred, y_true):\n",
    "        tot_error = tot_error + (float(yt) - yp)**2\n",
    "\n",
    "    return (1 / len(y_pred)) * tot_error\n",
    "\n",
    "\n",
    "# Log-Loss:\n",
    "# - Mit Numpy\n",
    "def logloss(y_pred, y_true):\n",
    "    # Weil log(0) nicht definiert ist => Wert nah bei 0 nehmen.\n",
    "    eps = 1e-15\n",
    "    y_pred = [max(i, eps)    for i in y_pred ]\n",
    "    y_pred = [min(i, 1-eps)  for i in y_pred ]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return -np.mean(\\\n",
    "        y_true * np.log(y_pred) + (1-y_true) * np.log(1 - y_pred ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66fed53f-4f16-475a-919f-c6d3cf30053f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10200000000000001"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_1(np.array(y_true), np.array(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df4eb1a8-4d46-4b06-ab64-893e579c3a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10200000000000001"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MSE_2(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c702992-8374-4050-bc60-4e1bb74ff934",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.37055683421316593"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logloss(np.array(y_pred), np.array(y_true))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b8c4a7-7cd5-401c-8267-b26e296a3bfd",
   "metadata": {},
   "source": [
    "<h1>Gradientenabstieg</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e44286-40fc-45fa-8baf-842277ec35ba",
   "metadata": {},
   "source": [
    "Gradientenabstieg ist einer der wichtigsten und elementaren Konzepte in DL, um überhaupt das Model zu optimieren. Durch den Abstieg Richtung Minimum soll der Gesamtfehler minimiert und die Weights optimiert werden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c210e17-ae84-4f27-b713-6dcc6a0b706a",
   "metadata": {},
   "source": [
    "<i>Abb3</i>: Finde die Parameter.\n",
    "\n",
    "<img src=\"./img/nn_6.PNG\" width=400 hight=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82ae5f52-35ef-4ed6-878a-d112dd93afaf",
   "metadata": {},
   "source": [
    "In einem Netzwerk wollen wir die richtigen Parameter finden, als die w's und b's. \n",
    "\n",
    "In der Abbildung 3 sehen wir zwei einfache Tabelle, was sind aber die Parameter?\n",
    "\n",
    "In der Tabelle 1: <br>\n",
    "$\n",
    "y = X * w1 + b \\ = \\ X * 2 + 0\n",
    "$\n",
    "\n",
    "Es ist einfach zu erkennen.\n",
    "\n",
    "Was ist mit der Tabelle 2? Durch direktes Hinschauen geht das nicht, besonders nicht, wenn es sehr viele Parameter gibt.\n",
    "\n",
    "Durch das Gradientenverfahren können die Parameter gefunden werden => w1 = 0.34 und b = -0.7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f8c50-f97a-4e70-8861-5f575d8b3b36",
   "metadata": {},
   "source": [
    "<i>Abb4</i>: Epoche und total-error (Beispielhaft).\n",
    "\n",
    "<img src=\"./img/nn_7.PNG\" width=600 hight=300>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940300ab-f017-4896-a9b6-3d8de2f0e73e",
   "metadata": {},
   "source": [
    "Während des Forwardpasses werden die einzelnen Samples dem Netzwerk übergeben, Stück für Stück. Nach jedem Sample wird der Fehler mit einer bestimmten Kostenfunktion, z. B. Log-Loss, berechnet. <br>\n",
    "Am Ende wird der Total-Error berechnet, was uns als Loss angezeigt wird, z. B. als Log-Loss.\n",
    "\n",
    "Durch Backpropagation sollen die Parameter mit dem gegebenen Fehler angepasst werden. Es sind mehrere Epochen nötig, um Log-Loss zu reduzieren und um die passenden Weights zu finden.\n",
    "\n",
    "Das ändert/update der Weights sieht so aussehen:<br>\n",
    "$\n",
    "w1 = w1 - Schrittweite * PartielleAbleitung_w1\n",
    "$\n",
    "\n",
    "Jetzt werden die <b>Ableitungen</b> der Funktionen wichtig. Um die Steigung an einem Punkt zu bekommen, wird die Ableitung der Funktion benötigt. Der Punkt wird dann in die Ableitung eingesetzt und herauskommt die Steigung. <br>\n",
    "=> Wie ändert sich der Gesamt-Loss bei einer veränderung eines w's.\n",
    "\n",
    "Dabei wird die Schrittweite richtung Minimum auch als Learning-rate oder lr bezeichnet. \n",
    "- Bei großen Schritten könnte das Minimum überschritten werden => man kommt nie ans Ziel und spring immer umher.\n",
    "- Bei einem zu kleinen Wert dauert es lange, bis das Minimum erreicht ist.\n",
    "\n",
    "Für die anderen w's und das b ist das Vorgehen gleich."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6258481-e2cb-4049-bc15-999d752aaeec",
   "metadata": {},
   "source": [
    "Deswegen ist es wichtig, sich mit der Thematik auseinander zusetzen.\n",
    "\n",
    "Nach der Anpassung der Weights, wird der Vorgang fortgeführt bis das gewünschte Ergebnis da ist, z. B. wenn Loss sehr niedrig ist oder sich die w's nicht mehr stark verändern. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7634634-9ca0-45e3-91be-c5133c133ace",
   "metadata": {},
   "source": [
    "<h2>Code</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a9fb85-a27d-406b-98f8-3383b669d912",
   "metadata": {},
   "source": [
    "Als Versuchsbeispiel nehmen wir ein kleines Dataset wo es darum geht eine Versicherung abzuschließen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e30cf04b-1526-4bfc-b40a-fc824f7b6e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports.\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51106ca9-7b58-461c-a8f3-e4ec55bdc086",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>affordibility</th>\n",
       "      <th>bought_insurance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.47</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.52</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.55</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.60</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.29</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.49</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.55</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.58</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.19</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.21</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.40</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.45</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.50</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.23</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.46</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  affordibility  bought_insurance\n",
       "0   0.22              1                 0\n",
       "1   0.25              0                 0\n",
       "2   0.47              1                 1\n",
       "3   0.52              0                 0\n",
       "4   0.46              1                 1\n",
       "5   0.56              1                 1\n",
       "6   0.55              0                 0\n",
       "7   0.60              0                 1\n",
       "8   0.62              1                 1\n",
       "9   0.61              1                 1\n",
       "10  0.18              1                 0\n",
       "11  0.28              1                 0\n",
       "12  0.27              0                 0\n",
       "13  0.29              0                 0\n",
       "14  0.49              1                 1\n",
       "15  0.55              1                 1\n",
       "16  0.25              0                 1\n",
       "17  0.58              1                 1\n",
       "18  0.19              0                 0\n",
       "19  0.18              1                 0\n",
       "20  0.21              1                 0\n",
       "21  0.26              0                 0\n",
       "22  0.40              1                 1\n",
       "23  0.45              1                 1\n",
       "24  0.50              1                 1\n",
       "25  0.54              1                 1\n",
       "26  0.23              1                 0\n",
       "27  0.46              1                 0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lade Dataset\n",
    "data_df = pd.read_csv('./data/data.csv')\n",
    "data_df['age'] = data_df['age'] / 100\n",
    "data_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d675642-b563-438c-a8b3-52de0ad32245",
   "metadata": {},
   "source": [
    "Durch ein überschaubares Dataset und ein kleines Netz kann das Verfahren einfach implementiert werden.\n",
    "\n",
    "Wir haben 2 Neuronen als Input und 1 Neuron als Output. \n",
    "\n",
    "Als Erstes probieren wir es mit Keras aus und lassen uns die Weigts ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd42ea2f-9739-4296-8010-07c644d3e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model.\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(units=1, input_shape=(2,), \\\n",
    "                          kernel_initializer='ones', bias_initializer='zeros', activation='sigmoid', name=\"L1a2\")\n",
    "])\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss     ='binary_crossentropy', # Log-Loss\n",
    "    metrics  = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "789f2a44-4b8c-48d4-b7ee-25759a3b2328",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X = data_df.drop(['bought_insurance'], axis='columns')\n",
    "y = data_df['bought_insurance']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2e3e1f45-647e-439f-9cd7-95952e151cd6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5668 - accuracy: 0.7143\n",
      "Epoch 2/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5668 - accuracy: 0.7143\n",
      "Epoch 3/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5667 - accuracy: 0.7143\n",
      "Epoch 4/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5666 - accuracy: 0.7143\n",
      "Epoch 5/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5666 - accuracy: 0.7143\n",
      "Epoch 6/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7143\n",
      "Epoch 7/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5665 - accuracy: 0.7143\n",
      "Epoch 8/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7143\n",
      "Epoch 9/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5664 - accuracy: 0.7143\n",
      "Epoch 10/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5663 - accuracy: 0.7143\n",
      "Epoch 11/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5663 - accuracy: 0.7143\n",
      "Epoch 12/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5662 - accuracy: 0.7143\n",
      "Epoch 13/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5662 - accuracy: 0.7143\n",
      "Epoch 14/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5661 - accuracy: 0.7143\n",
      "Epoch 15/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7143\n",
      "Epoch 16/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5660 - accuracy: 0.7143\n",
      "Epoch 17/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7143\n",
      "Epoch 18/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5659 - accuracy: 0.7143\n",
      "Epoch 19/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7143\n",
      "Epoch 20/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5658 - accuracy: 0.7143\n",
      "Epoch 21/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7143\n",
      "Epoch 22/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5657 - accuracy: 0.7143\n",
      "Epoch 23/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5656 - accuracy: 0.7143\n",
      "Epoch 24/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5655 - accuracy: 0.7143\n",
      "Epoch 25/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5655 - accuracy: 0.7143\n",
      "Epoch 26/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7143\n",
      "Epoch 27/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5654 - accuracy: 0.7143\n",
      "Epoch 28/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7143\n",
      "Epoch 29/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5653 - accuracy: 0.7143\n",
      "Epoch 30/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5652 - accuracy: 0.7143\n",
      "Epoch 31/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5652 - accuracy: 0.7143\n",
      "Epoch 32/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7143\n",
      "Epoch 33/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5651 - accuracy: 0.7143\n",
      "Epoch 34/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5650 - accuracy: 0.7143\n",
      "Epoch 35/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7143\n",
      "Epoch 36/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5649 - accuracy: 0.7143\n",
      "Epoch 37/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7143\n",
      "Epoch 38/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5648 - accuracy: 0.7143\n",
      "Epoch 39/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7143\n",
      "Epoch 40/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5647 - accuracy: 0.7143\n",
      "Epoch 41/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7143\n",
      "Epoch 42/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5646 - accuracy: 0.7143\n",
      "Epoch 43/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7143\n",
      "Epoch 44/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5645 - accuracy: 0.7143\n",
      "Epoch 45/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5644 - accuracy: 0.7143\n",
      "Epoch 46/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7143\n",
      "Epoch 47/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5643 - accuracy: 0.7143\n",
      "Epoch 48/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5642 - accuracy: 0.7143\n",
      "Epoch 49/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5642 - accuracy: 0.7143\n",
      "Epoch 50/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5641 - accuracy: 0.7143\n",
      "Epoch 51/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5641 - accuracy: 0.7143\n",
      "Epoch 52/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5640 - accuracy: 0.7143\n",
      "Epoch 53/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5640 - accuracy: 0.7143\n",
      "Epoch 54/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7143\n",
      "Epoch 55/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5639 - accuracy: 0.7143\n",
      "Epoch 56/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5638 - accuracy: 0.7143\n",
      "Epoch 57/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5637 - accuracy: 0.7143\n",
      "Epoch 58/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5637 - accuracy: 0.7143\n",
      "Epoch 59/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7143\n",
      "Epoch 60/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5636 - accuracy: 0.7143\n",
      "Epoch 61/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7143\n",
      "Epoch 62/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5635 - accuracy: 0.7143\n",
      "Epoch 63/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7143\n",
      "Epoch 64/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5634 - accuracy: 0.7143\n",
      "Epoch 65/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7143\n",
      "Epoch 66/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5633 - accuracy: 0.7143\n",
      "Epoch 67/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5632 - accuracy: 0.7143\n",
      "Epoch 68/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7143\n",
      "Epoch 69/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5631 - accuracy: 0.7143\n",
      "Epoch 70/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5630 - accuracy: 0.7143\n",
      "Epoch 71/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5630 - accuracy: 0.7143\n",
      "Epoch 72/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5629 - accuracy: 0.7143\n",
      "Epoch 73/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5629 - accuracy: 0.7143\n",
      "Epoch 74/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7143\n",
      "Epoch 75/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5628 - accuracy: 0.7143\n",
      "Epoch 76/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5627 - accuracy: 0.7143\n",
      "Epoch 77/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5627 - accuracy: 0.7143\n",
      "Epoch 78/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5626 - accuracy: 0.7143\n",
      "Epoch 79/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7143\n",
      "Epoch 80/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7143\n",
      "Epoch 81/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5624 - accuracy: 0.7143\n",
      "Epoch 82/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5624 - accuracy: 0.7143\n",
      "Epoch 83/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7143\n",
      "Epoch 84/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5623 - accuracy: 0.7143\n",
      "Epoch 85/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7143\n",
      "Epoch 86/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5622 - accuracy: 0.7143\n",
      "Epoch 87/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7143\n",
      "Epoch 88/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5621 - accuracy: 0.7143\n",
      "Epoch 89/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7143\n",
      "Epoch 90/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5620 - accuracy: 0.7143\n",
      "Epoch 91/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5619 - accuracy: 0.7143\n",
      "Epoch 92/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7143\n",
      "Epoch 93/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5618 - accuracy: 0.7143\n",
      "Epoch 94/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5617 - accuracy: 0.7143\n",
      "Epoch 95/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5617 - accuracy: 0.7143\n",
      "Epoch 96/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7143\n",
      "Epoch 97/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5616 - accuracy: 0.7143\n",
      "Epoch 98/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7143\n",
      "Epoch 99/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5615 - accuracy: 0.7143\n",
      "Epoch 100/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5614 - accuracy: 0.7143\n",
      "Epoch 101/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5614 - accuracy: 0.7143\n",
      "Epoch 102/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5613 - accuracy: 0.7143\n",
      "Epoch 103/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7143\n",
      "Epoch 104/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5612 - accuracy: 0.7143\n",
      "Epoch 105/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7143\n",
      "Epoch 106/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5611 - accuracy: 0.7143\n",
      "Epoch 107/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7143\n",
      "Epoch 108/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5610 - accuracy: 0.7143\n",
      "Epoch 109/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7143\n",
      "Epoch 110/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5609 - accuracy: 0.7143\n",
      "Epoch 111/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7143\n",
      "Epoch 112/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5608 - accuracy: 0.7143\n",
      "Epoch 113/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5607 - accuracy: 0.7143\n",
      "Epoch 114/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5607 - accuracy: 0.7143\n",
      "Epoch 115/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5606 - accuracy: 0.7143\n",
      "Epoch 116/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7143\n",
      "Epoch 117/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5605 - accuracy: 0.7143\n",
      "Epoch 118/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7143\n",
      "Epoch 119/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5604 - accuracy: 0.7143\n",
      "Epoch 120/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5603 - accuracy: 0.7143\n",
      "Epoch 121/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5603 - accuracy: 0.7143\n",
      "Epoch 122/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5602 - accuracy: 0.7143\n",
      "Epoch 123/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5602 - accuracy: 0.7143\n",
      "Epoch 124/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5601 - accuracy: 0.7143\n",
      "Epoch 125/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5601 - accuracy: 0.7143\n",
      "Epoch 126/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7143\n",
      "Epoch 127/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5600 - accuracy: 0.7143\n",
      "Epoch 128/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5599 - accuracy: 0.7143\n",
      "Epoch 129/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5598 - accuracy: 0.7143\n",
      "Epoch 130/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5598 - accuracy: 0.7143\n",
      "Epoch 131/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7143\n",
      "Epoch 132/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.7143\n",
      "Epoch 133/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5596 - accuracy: 0.7143\n",
      "Epoch 134/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5596 - accuracy: 0.7143\n",
      "Epoch 135/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5595 - accuracy: 0.7143\n",
      "Epoch 136/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5595 - accuracy: 0.7143\n",
      "Epoch 137/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7143\n",
      "Epoch 138/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5594 - accuracy: 0.7143\n",
      "Epoch 139/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7143\n",
      "Epoch 140/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5593 - accuracy: 0.7143\n",
      "Epoch 141/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5592 - accuracy: 0.7143\n",
      "Epoch 142/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7143\n",
      "Epoch 143/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5591 - accuracy: 0.7143\n",
      "Epoch 144/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5590 - accuracy: 0.7143\n",
      "Epoch 145/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5590 - accuracy: 0.7143\n",
      "Epoch 146/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7143\n",
      "Epoch 147/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5589 - accuracy: 0.7143\n",
      "Epoch 148/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7143\n",
      "Epoch 149/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5588 - accuracy: 0.7143\n",
      "Epoch 150/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7143\n",
      "Epoch 151/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5587 - accuracy: 0.7143\n",
      "Epoch 152/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7143\n",
      "Epoch 153/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5586 - accuracy: 0.7143\n",
      "Epoch 154/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5585 - accuracy: 0.7143\n",
      "Epoch 155/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7143\n",
      "Epoch 156/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5584 - accuracy: 0.7143\n",
      "Epoch 157/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7143\n",
      "Epoch 158/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5583 - accuracy: 0.7143\n",
      "Epoch 159/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7143\n",
      "Epoch 160/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5582 - accuracy: 0.7143\n",
      "Epoch 161/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7143\n",
      "Epoch 162/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5581 - accuracy: 0.7143\n",
      "Epoch 163/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7143\n",
      "Epoch 164/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5580 - accuracy: 0.7143\n",
      "Epoch 165/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5579 - accuracy: 0.7143\n",
      "Epoch 166/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5579 - accuracy: 0.7143\n",
      "Epoch 167/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7143\n",
      "Epoch 168/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5578 - accuracy: 0.7143\n",
      "Epoch 169/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5577 - accuracy: 0.7143\n",
      "Epoch 170/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7143\n",
      "Epoch 171/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5576 - accuracy: 0.7143\n",
      "Epoch 172/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7143\n",
      "Epoch 173/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5575 - accuracy: 0.7143\n",
      "Epoch 174/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7143\n",
      "Epoch 175/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5574 - accuracy: 0.7143\n",
      "Epoch 176/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7143\n",
      "Epoch 177/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5573 - accuracy: 0.7143\n",
      "Epoch 178/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7143\n",
      "Epoch 179/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5572 - accuracy: 0.7143\n",
      "Epoch 180/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5571 - accuracy: 0.7143\n",
      "Epoch 181/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5571 - accuracy: 0.7143\n",
      "Epoch 182/2500\n",
      "1/1 [==============================] - 0s 986us/step - loss: 0.5570 - accuracy: 0.7143\n",
      "Epoch 183/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5569 - accuracy: 0.7143\n",
      "Epoch 184/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5569 - accuracy: 0.7143\n",
      "Epoch 185/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7143\n",
      "Epoch 186/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5568 - accuracy: 0.7143\n",
      "Epoch 187/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7143\n",
      "Epoch 188/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5567 - accuracy: 0.7143\n",
      "Epoch 189/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7143\n",
      "Epoch 190/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5566 - accuracy: 0.7143\n",
      "Epoch 191/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7143\n",
      "Epoch 192/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5565 - accuracy: 0.7143\n",
      "Epoch 193/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5564 - accuracy: 0.7143\n",
      "Epoch 194/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5564 - accuracy: 0.7143\n",
      "Epoch 195/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7143\n",
      "Epoch 196/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5563 - accuracy: 0.7143\n",
      "Epoch 197/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5562 - accuracy: 0.7143\n",
      "Epoch 198/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7143\n",
      "Epoch 199/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5561 - accuracy: 0.7143\n",
      "Epoch 200/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7143\n",
      "Epoch 201/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5560 - accuracy: 0.7143\n",
      "Epoch 202/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7143\n",
      "Epoch 203/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5559 - accuracy: 0.7143\n",
      "Epoch 204/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7143\n",
      "Epoch 205/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5558 - accuracy: 0.7143\n",
      "Epoch 206/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7143\n",
      "Epoch 207/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5557 - accuracy: 0.7143\n",
      "Epoch 208/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5556 - accuracy: 0.7143\n",
      "Epoch 209/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5556 - accuracy: 0.7143\n",
      "Epoch 210/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7143\n",
      "Epoch 211/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5555 - accuracy: 0.7143\n",
      "Epoch 212/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7143\n",
      "Epoch 213/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5554 - accuracy: 0.7143\n",
      "Epoch 214/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5553 - accuracy: 0.7143\n",
      "Epoch 215/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5552 - accuracy: 0.7143\n",
      "Epoch 216/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5552 - accuracy: 0.7143\n",
      "Epoch 217/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7143\n",
      "Epoch 218/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5551 - accuracy: 0.7143\n",
      "Epoch 219/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7143\n",
      "Epoch 220/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5550 - accuracy: 0.7143\n",
      "Epoch 221/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7143\n",
      "Epoch 222/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5549 - accuracy: 0.7143\n",
      "Epoch 223/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7143\n",
      "Epoch 224/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5548 - accuracy: 0.7143\n",
      "Epoch 225/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5547 - accuracy: 0.7143\n",
      "Epoch 226/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5547 - accuracy: 0.7143\n",
      "Epoch 227/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7143\n",
      "Epoch 228/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5546 - accuracy: 0.7143\n",
      "Epoch 229/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5545 - accuracy: 0.7143\n",
      "Epoch 230/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7143\n",
      "Epoch 231/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5544 - accuracy: 0.7143\n",
      "Epoch 232/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7143\n",
      "Epoch 233/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5543 - accuracy: 0.7143\n",
      "Epoch 234/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7143\n",
      "Epoch 235/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5542 - accuracy: 0.7143\n",
      "Epoch 236/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7143\n",
      "Epoch 237/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5541 - accuracy: 0.7143\n",
      "Epoch 238/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7143\n",
      "Epoch 239/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5540 - accuracy: 0.7143\n",
      "Epoch 240/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7143\n",
      "Epoch 241/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5539 - accuracy: 0.7143\n",
      "Epoch 242/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5538 - accuracy: 0.7143\n",
      "Epoch 243/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5538 - accuracy: 0.7143\n",
      "Epoch 244/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7143\n",
      "Epoch 245/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5537 - accuracy: 0.7143\n",
      "Epoch 246/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5536 - accuracy: 0.7143\n",
      "Epoch 247/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7143\n",
      "Epoch 248/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5535 - accuracy: 0.7143\n",
      "Epoch 249/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5534 - accuracy: 0.7143\n",
      "Epoch 250/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5534 - accuracy: 0.7143\n",
      "Epoch 251/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5533 - accuracy: 0.7143\n",
      "Epoch 252/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5533 - accuracy: 0.7143\n",
      "Epoch 253/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5532 - accuracy: 0.7143\n",
      "Epoch 254/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5532 - accuracy: 0.7143\n",
      "Epoch 255/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7143\n",
      "Epoch 256/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5531 - accuracy: 0.7143\n",
      "Epoch 257/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5530 - accuracy: 0.7143\n",
      "Epoch 258/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5530 - accuracy: 0.7143\n",
      "Epoch 259/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7143\n",
      "Epoch 260/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5529 - accuracy: 0.7143\n",
      "Epoch 261/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5528 - accuracy: 0.7143\n",
      "Epoch 262/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5528 - accuracy: 0.7143\n",
      "Epoch 263/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7143\n",
      "Epoch 264/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5527 - accuracy: 0.7143\n",
      "Epoch 265/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5526 - accuracy: 0.7143\n",
      "Epoch 266/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5525 - accuracy: 0.7143\n",
      "Epoch 267/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5525 - accuracy: 0.7143\n",
      "Epoch 268/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5524 - accuracy: 0.7143\n",
      "Epoch 269/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5524 - accuracy: 0.7143\n",
      "Epoch 270/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7143\n",
      "Epoch 271/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5523 - accuracy: 0.7143\n",
      "Epoch 272/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5522 - accuracy: 0.7143\n",
      "Epoch 273/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5522 - accuracy: 0.7143\n",
      "Epoch 274/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7143\n",
      "Epoch 275/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5521 - accuracy: 0.7143\n",
      "Epoch 276/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5520 - accuracy: 0.7143\n",
      "Epoch 277/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5520 - accuracy: 0.7143\n",
      "Epoch 278/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7143\n",
      "Epoch 279/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5519 - accuracy: 0.7143\n",
      "Epoch 280/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7143\n",
      "Epoch 281/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5518 - accuracy: 0.7143\n",
      "Epoch 282/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7143\n",
      "Epoch 283/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5517 - accuracy: 0.7143\n",
      "Epoch 284/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7143\n",
      "Epoch 285/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5516 - accuracy: 0.7143\n",
      "Epoch 286/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5515 - accuracy: 0.7143\n",
      "Epoch 287/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7143\n",
      "Epoch 288/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5514 - accuracy: 0.7143\n",
      "Epoch 289/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7143\n",
      "Epoch 290/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5513 - accuracy: 0.7143\n",
      "Epoch 291/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5512 - accuracy: 0.7143\n",
      "Epoch 292/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5512 - accuracy: 0.7143\n",
      "Epoch 293/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7143\n",
      "Epoch 294/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5511 - accuracy: 0.7143\n",
      "Epoch 295/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7143\n",
      "Epoch 296/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7143\n",
      "Epoch 297/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7143\n",
      "Epoch 298/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5509 - accuracy: 0.7143\n",
      "Epoch 299/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7143\n",
      "Epoch 300/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5508 - accuracy: 0.7143\n",
      "Epoch 301/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5507 - accuracy: 0.7143\n",
      "Epoch 302/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7143\n",
      "Epoch 303/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7143\n",
      "Epoch 304/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5506 - accuracy: 0.7143\n",
      "Epoch 305/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7143\n",
      "Epoch 306/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5505 - accuracy: 0.7143\n",
      "Epoch 307/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5504 - accuracy: 0.7143\n",
      "Epoch 308/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7143\n",
      "Epoch 309/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5503 - accuracy: 0.7143\n",
      "Epoch 310/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5502 - accuracy: 0.7143\n",
      "Epoch 311/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5502 - accuracy: 0.7143\n",
      "Epoch 312/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7143\n",
      "Epoch 313/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5501 - accuracy: 0.7143\n",
      "Epoch 314/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7143\n",
      "Epoch 315/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5500 - accuracy: 0.7143\n",
      "Epoch 316/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7143\n",
      "Epoch 317/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5499 - accuracy: 0.7143\n",
      "Epoch 318/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7143\n",
      "Epoch 319/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5498 - accuracy: 0.7143\n",
      "Epoch 320/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7143\n",
      "Epoch 321/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5497 - accuracy: 0.7143\n",
      "Epoch 322/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7143\n",
      "Epoch 323/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5496 - accuracy: 0.7143\n",
      "Epoch 324/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7143\n",
      "Epoch 325/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.7143\n",
      "Epoch 326/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7143\n",
      "Epoch 327/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5494 - accuracy: 0.7143\n",
      "Epoch 328/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7143\n",
      "Epoch 329/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5493 - accuracy: 0.7143\n",
      "Epoch 330/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5492 - accuracy: 0.7143\n",
      "Epoch 331/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7143\n",
      "Epoch 332/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5491 - accuracy: 0.7143\n",
      "Epoch 333/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7143\n",
      "Epoch 334/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5490 - accuracy: 0.7143\n",
      "Epoch 335/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7143\n",
      "Epoch 336/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5489 - accuracy: 0.7143\n",
      "Epoch 337/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7143\n",
      "Epoch 338/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5488 - accuracy: 0.7143\n",
      "Epoch 339/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7143\n",
      "Epoch 340/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5487 - accuracy: 0.7143\n",
      "Epoch 341/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7143\n",
      "Epoch 342/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5486 - accuracy: 0.7143\n",
      "Epoch 343/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7143\n",
      "Epoch 344/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5485 - accuracy: 0.7143\n",
      "Epoch 345/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7143\n",
      "Epoch 346/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5484 - accuracy: 0.7143\n",
      "Epoch 347/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7143\n",
      "Epoch 348/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5483 - accuracy: 0.7143\n",
      "Epoch 349/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7143\n",
      "Epoch 350/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5482 - accuracy: 0.7143\n",
      "Epoch 351/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7143\n",
      "Epoch 352/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5481 - accuracy: 0.7143\n",
      "Epoch 353/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5480 - accuracy: 0.7143\n",
      "Epoch 354/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5480 - accuracy: 0.7143\n",
      "Epoch 355/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7143\n",
      "Epoch 356/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5479 - accuracy: 0.7143\n",
      "Epoch 357/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5478 - accuracy: 0.7143\n",
      "Epoch 358/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5477 - accuracy: 0.7143\n",
      "Epoch 359/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5477 - accuracy: 0.7143\n",
      "Epoch 360/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7143\n",
      "Epoch 361/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5476 - accuracy: 0.7143\n",
      "Epoch 362/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7143\n",
      "Epoch 363/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5475 - accuracy: 0.7143\n",
      "Epoch 364/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7143\n",
      "Epoch 365/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5474 - accuracy: 0.7143\n",
      "Epoch 366/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5473 - accuracy: 0.7143\n",
      "Epoch 367/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5473 - accuracy: 0.7143\n",
      "Epoch 368/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7143\n",
      "Epoch 369/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5472 - accuracy: 0.7143\n",
      "Epoch 370/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7143\n",
      "Epoch 371/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5471 - accuracy: 0.7143\n",
      "Epoch 372/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7143\n",
      "Epoch 373/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5470 - accuracy: 0.7143\n",
      "Epoch 374/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7143\n",
      "Epoch 375/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5469 - accuracy: 0.7143\n",
      "Epoch 376/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7143\n",
      "Epoch 377/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5468 - accuracy: 0.7143\n",
      "Epoch 378/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7143\n",
      "Epoch 379/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5467 - accuracy: 0.7143\n",
      "Epoch 380/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7143\n",
      "Epoch 381/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5466 - accuracy: 0.7143\n",
      "Epoch 382/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7143\n",
      "Epoch 383/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5465 - accuracy: 0.7143\n",
      "Epoch 384/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7143\n",
      "Epoch 385/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5464 - accuracy: 0.7143\n",
      "Epoch 386/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7143\n",
      "Epoch 387/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5463 - accuracy: 0.7143\n",
      "Epoch 388/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7143\n",
      "Epoch 389/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5462 - accuracy: 0.7143\n",
      "Epoch 390/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5461 - accuracy: 0.7143\n",
      "Epoch 391/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7143\n",
      "Epoch 392/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5460 - accuracy: 0.7143\n",
      "Epoch 393/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7143\n",
      "Epoch 394/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5459 - accuracy: 0.7143\n",
      "Epoch 395/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7143\n",
      "Epoch 396/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5458 - accuracy: 0.7143\n",
      "Epoch 397/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5457 - accuracy: 0.7143\n",
      "Epoch 398/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5457 - accuracy: 0.7143\n",
      "Epoch 399/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5456 - accuracy: 0.7143\n",
      "Epoch 400/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5456 - accuracy: 0.7143\n",
      "Epoch 401/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7143\n",
      "Epoch 402/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5455 - accuracy: 0.7143\n",
      "Epoch 403/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7143\n",
      "Epoch 404/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5454 - accuracy: 0.7143\n",
      "Epoch 405/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7143\n",
      "Epoch 406/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5453 - accuracy: 0.7143\n",
      "Epoch 407/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5452 - accuracy: 0.7857\n",
      "Epoch 408/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5452 - accuracy: 0.7857\n",
      "Epoch 409/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7857\n",
      "Epoch 410/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5451 - accuracy: 0.7857\n",
      "Epoch 411/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7857\n",
      "Epoch 412/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5450 - accuracy: 0.7857\n",
      "Epoch 413/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7857\n",
      "Epoch 414/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5449 - accuracy: 0.7857\n",
      "Epoch 415/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7857\n",
      "Epoch 416/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5448 - accuracy: 0.7857\n",
      "Epoch 417/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7857\n",
      "Epoch 418/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5447 - accuracy: 0.7857\n",
      "Epoch 419/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5446 - accuracy: 0.7857\n",
      "Epoch 420/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5446 - accuracy: 0.7857\n",
      "Epoch 421/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7857\n",
      "Epoch 422/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5445 - accuracy: 0.7857\n",
      "Epoch 423/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7857\n",
      "Epoch 424/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5444 - accuracy: 0.7857\n",
      "Epoch 425/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7857\n",
      "Epoch 426/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5443 - accuracy: 0.7857\n",
      "Epoch 427/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7857\n",
      "Epoch 428/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5442 - accuracy: 0.7857\n",
      "Epoch 429/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5441 - accuracy: 0.7857\n",
      "Epoch 430/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5441 - accuracy: 0.7857\n",
      "Epoch 431/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7857\n",
      "Epoch 432/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5440 - accuracy: 0.7857\n",
      "Epoch 433/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7857\n",
      "Epoch 434/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5439 - accuracy: 0.7857\n",
      "Epoch 435/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5438 - accuracy: 0.7857\n",
      "Epoch 436/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5437 - accuracy: 0.7857\n",
      "Epoch 437/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5437 - accuracy: 0.7857\n",
      "Epoch 438/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5436 - accuracy: 0.7857\n",
      "Epoch 439/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5436 - accuracy: 0.7857\n",
      "Epoch 440/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5435 - accuracy: 0.7857\n",
      "Epoch 441/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5435 - accuracy: 0.7857\n",
      "Epoch 442/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7857\n",
      "Epoch 443/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5434 - accuracy: 0.7857\n",
      "Epoch 444/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7857\n",
      "Epoch 445/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5433 - accuracy: 0.7857\n",
      "Epoch 446/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7857\n",
      "Epoch 447/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5432 - accuracy: 0.7857\n",
      "Epoch 448/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7857\n",
      "Epoch 449/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5431 - accuracy: 0.7857\n",
      "Epoch 450/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5430 - accuracy: 0.7857\n",
      "Epoch 451/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5430 - accuracy: 0.7857\n",
      "Epoch 452/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7857\n",
      "Epoch 453/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5429 - accuracy: 0.7857\n",
      "Epoch 454/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7857\n",
      "Epoch 455/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5428 - accuracy: 0.7857\n",
      "Epoch 456/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7857\n",
      "Epoch 457/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5427 - accuracy: 0.7857\n",
      "Epoch 458/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5426 - accuracy: 0.7857\n",
      "Epoch 459/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5426 - accuracy: 0.7857\n",
      "Epoch 460/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7857\n",
      "Epoch 461/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5425 - accuracy: 0.7857\n",
      "Epoch 462/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7857\n",
      "Epoch 463/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5424 - accuracy: 0.7857\n",
      "Epoch 464/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7857\n",
      "Epoch 465/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5423 - accuracy: 0.7857\n",
      "Epoch 466/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7857\n",
      "Epoch 467/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5422 - accuracy: 0.7857\n",
      "Epoch 468/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7857\n",
      "Epoch 469/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5421 - accuracy: 0.7857\n",
      "Epoch 470/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7857\n",
      "Epoch 471/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5420 - accuracy: 0.7857\n",
      "Epoch 472/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7857\n",
      "Epoch 473/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5419 - accuracy: 0.7857\n",
      "Epoch 474/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5418 - accuracy: 0.7857\n",
      "Epoch 475/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5418 - accuracy: 0.7857\n",
      "Epoch 476/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7857\n",
      "Epoch 477/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5417 - accuracy: 0.7857\n",
      "Epoch 478/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7857\n",
      "Epoch 479/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5416 - accuracy: 0.7857\n",
      "Epoch 480/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7857\n",
      "Epoch 481/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5415 - accuracy: 0.7857\n",
      "Epoch 482/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7857\n",
      "Epoch 483/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5414 - accuracy: 0.7857\n",
      "Epoch 484/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7857\n",
      "Epoch 485/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5413 - accuracy: 0.7857\n",
      "Epoch 486/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5412 - accuracy: 0.7857\n",
      "Epoch 487/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5412 - accuracy: 0.7857\n",
      "Epoch 488/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7857\n",
      "Epoch 489/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5411 - accuracy: 0.7857\n",
      "Epoch 490/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7857\n",
      "Epoch 491/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5410 - accuracy: 0.7857\n",
      "Epoch 492/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7857\n",
      "Epoch 493/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7857\n",
      "Epoch 494/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7857\n",
      "Epoch 495/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5408 - accuracy: 0.7857\n",
      "Epoch 496/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7857\n",
      "Epoch 497/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5407 - accuracy: 0.7857\n",
      "Epoch 498/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5406 - accuracy: 0.7857\n",
      "Epoch 499/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5406 - accuracy: 0.7857\n",
      "Epoch 500/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7857\n",
      "Epoch 501/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5405 - accuracy: 0.7857\n",
      "Epoch 502/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7857\n",
      "Epoch 503/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5404 - accuracy: 0.7857\n",
      "Epoch 504/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7857\n",
      "Epoch 505/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5403 - accuracy: 0.7857\n",
      "Epoch 506/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7857\n",
      "Epoch 507/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5402 - accuracy: 0.7857\n",
      "Epoch 508/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7857\n",
      "Epoch 509/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5401 - accuracy: 0.7857\n",
      "Epoch 510/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7857\n",
      "Epoch 511/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5400 - accuracy: 0.7857\n",
      "Epoch 512/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7857\n",
      "Epoch 513/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5399 - accuracy: 0.7857\n",
      "Epoch 514/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5398 - accuracy: 0.7857\n",
      "Epoch 515/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5398 - accuracy: 0.7857\n",
      "Epoch 516/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7857\n",
      "Epoch 517/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5397 - accuracy: 0.7857\n",
      "Epoch 518/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5396 - accuracy: 0.7857\n",
      "Epoch 519/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5396 - accuracy: 0.7857\n",
      "Epoch 520/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5395 - accuracy: 0.7857\n",
      "Epoch 521/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5395 - accuracy: 0.7857\n",
      "Epoch 522/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7857\n",
      "Epoch 523/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5394 - accuracy: 0.7857\n",
      "Epoch 524/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5393 - accuracy: 0.7857\n",
      "Epoch 525/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5393 - accuracy: 0.7857\n",
      "Epoch 526/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7857\n",
      "Epoch 527/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5392 - accuracy: 0.7857\n",
      "Epoch 528/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7857\n",
      "Epoch 529/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5391 - accuracy: 0.7857\n",
      "Epoch 530/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7857\n",
      "Epoch 531/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5390 - accuracy: 0.7857\n",
      "Epoch 532/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7857\n",
      "Epoch 533/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.7857\n",
      "Epoch 534/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7857\n",
      "Epoch 535/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5388 - accuracy: 0.7857\n",
      "Epoch 536/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7857\n",
      "Epoch 537/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5387 - accuracy: 0.7857\n",
      "Epoch 538/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7857\n",
      "Epoch 539/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5386 - accuracy: 0.7857\n",
      "Epoch 540/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7857\n",
      "Epoch 541/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5385 - accuracy: 0.7857\n",
      "Epoch 542/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7857\n",
      "Epoch 543/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5384 - accuracy: 0.7857\n",
      "Epoch 544/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5383 - accuracy: 0.7857\n",
      "Epoch 545/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5383 - accuracy: 0.7857\n",
      "Epoch 546/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7857\n",
      "Epoch 547/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5382 - accuracy: 0.7857\n",
      "Epoch 548/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7857\n",
      "Epoch 549/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5381 - accuracy: 0.7857\n",
      "Epoch 550/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7857\n",
      "Epoch 551/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5380 - accuracy: 0.7857\n",
      "Epoch 552/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7857\n",
      "Epoch 553/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5379 - accuracy: 0.7857\n",
      "Epoch 554/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7857\n",
      "Epoch 555/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5378 - accuracy: 0.7857\n",
      "Epoch 556/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7857\n",
      "Epoch 557/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5377 - accuracy: 0.7857\n",
      "Epoch 558/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7857\n",
      "Epoch 559/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5376 - accuracy: 0.7857\n",
      "Epoch 560/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7857\n",
      "Epoch 561/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5375 - accuracy: 0.7857\n",
      "Epoch 562/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7857\n",
      "Epoch 563/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5374 - accuracy: 0.7857\n",
      "Epoch 564/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5373 - accuracy: 0.7857\n",
      "Epoch 565/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5373 - accuracy: 0.7857\n",
      "Epoch 566/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7857\n",
      "Epoch 567/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5372 - accuracy: 0.7857\n",
      "Epoch 568/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7857\n",
      "Epoch 569/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5371 - accuracy: 0.7857\n",
      "Epoch 570/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7857\n",
      "Epoch 571/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5370 - accuracy: 0.7857\n",
      "Epoch 572/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7857\n",
      "Epoch 573/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5369 - accuracy: 0.7857\n",
      "Epoch 574/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7857\n",
      "Epoch 575/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5368 - accuracy: 0.7857\n",
      "Epoch 576/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5367 - accuracy: 0.7857\n",
      "Epoch 577/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5367 - accuracy: 0.7857\n",
      "Epoch 578/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7857\n",
      "Epoch 579/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5366 - accuracy: 0.7857\n",
      "Epoch 580/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7857\n",
      "Epoch 581/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5365 - accuracy: 0.7857\n",
      "Epoch 582/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5364 - accuracy: 0.7857\n",
      "Epoch 583/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5364 - accuracy: 0.7857\n",
      "Epoch 584/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7857\n",
      "Epoch 585/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5363 - accuracy: 0.7857\n",
      "Epoch 586/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7857\n",
      "Epoch 587/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5362 - accuracy: 0.7857\n",
      "Epoch 588/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5361 - accuracy: 0.7857\n",
      "Epoch 589/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5361 - accuracy: 0.7857\n",
      "Epoch 590/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7857\n",
      "Epoch 591/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5360 - accuracy: 0.7857\n",
      "Epoch 592/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5359 - accuracy: 0.7857\n",
      "Epoch 593/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5359 - accuracy: 0.7857\n",
      "Epoch 594/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7857\n",
      "Epoch 595/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5358 - accuracy: 0.7857\n",
      "Epoch 596/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5357 - accuracy: 0.7857\n",
      "Epoch 597/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5357 - accuracy: 0.7857\n",
      "Epoch 598/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7857\n",
      "Epoch 599/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5356 - accuracy: 0.7857\n",
      "Epoch 600/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7857\n",
      "Epoch 601/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7857\n",
      "Epoch 602/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7857\n",
      "Epoch 603/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7857\n",
      "Epoch 604/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5354 - accuracy: 0.7857\n",
      "Epoch 605/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7857\n",
      "Epoch 606/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5353 - accuracy: 0.7857\n",
      "Epoch 607/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7857\n",
      "Epoch 608/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5352 - accuracy: 0.7857\n",
      "Epoch 609/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7857\n",
      "Epoch 610/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5351 - accuracy: 0.7857\n",
      "Epoch 611/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7857\n",
      "Epoch 612/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5350 - accuracy: 0.7857\n",
      "Epoch 613/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7857\n",
      "Epoch 614/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5349 - accuracy: 0.7857\n",
      "Epoch 615/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7857\n",
      "Epoch 616/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5348 - accuracy: 0.7857\n",
      "Epoch 617/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7857\n",
      "Epoch 618/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5347 - accuracy: 0.7857\n",
      "Epoch 619/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7857\n",
      "Epoch 620/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5346 - accuracy: 0.7857\n",
      "Epoch 621/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7857\n",
      "Epoch 622/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5345 - accuracy: 0.7857\n",
      "Epoch 623/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7857\n",
      "Epoch 624/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5344 - accuracy: 0.7857\n",
      "Epoch 625/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7857\n",
      "Epoch 626/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5343 - accuracy: 0.7857\n",
      "Epoch 627/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5342 - accuracy: 0.7857\n",
      "Epoch 628/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7857\n",
      "Epoch 629/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7857\n",
      "Epoch 630/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5341 - accuracy: 0.7857\n",
      "Epoch 631/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7857\n",
      "Epoch 632/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5340 - accuracy: 0.7857\n",
      "Epoch 633/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7857\n",
      "Epoch 634/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5339 - accuracy: 0.7857\n",
      "Epoch 635/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7857\n",
      "Epoch 636/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5338 - accuracy: 0.7857\n",
      "Epoch 637/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5337 - accuracy: 0.7857\n",
      "Epoch 638/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5337 - accuracy: 0.7857\n",
      "Epoch 639/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7857\n",
      "Epoch 640/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5336 - accuracy: 0.7857\n",
      "Epoch 641/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7857\n",
      "Epoch 642/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5335 - accuracy: 0.7857\n",
      "Epoch 643/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7857\n",
      "Epoch 644/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5334 - accuracy: 0.7857\n",
      "Epoch 645/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7857\n",
      "Epoch 646/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7857\n",
      "Epoch 647/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5333 - accuracy: 0.7857\n",
      "Epoch 648/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7857\n",
      "Epoch 649/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5332 - accuracy: 0.7857\n",
      "Epoch 650/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5331 - accuracy: 0.7857\n",
      "Epoch 651/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5331 - accuracy: 0.7857\n",
      "Epoch 652/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7857\n",
      "Epoch 653/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5330 - accuracy: 0.7857\n",
      "Epoch 654/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5329 - accuracy: 0.7857\n",
      "Epoch 655/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5329 - accuracy: 0.7857\n",
      "Epoch 656/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5328 - accuracy: 0.7857\n",
      "Epoch 657/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5328 - accuracy: 0.7857\n",
      "Epoch 658/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7857\n",
      "Epoch 659/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5327 - accuracy: 0.7857\n",
      "Epoch 660/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5326 - accuracy: 0.7857\n",
      "Epoch 661/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5326 - accuracy: 0.7857\n",
      "Epoch 662/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7857\n",
      "Epoch 663/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5325 - accuracy: 0.7857\n",
      "Epoch 664/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7857\n",
      "Epoch 665/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5324 - accuracy: 0.7857\n",
      "Epoch 666/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5323 - accuracy: 0.7857\n",
      "Epoch 667/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5323 - accuracy: 0.7857\n",
      "Epoch 668/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5322 - accuracy: 0.7857\n",
      "Epoch 669/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5322 - accuracy: 0.7857\n",
      "Epoch 670/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7857\n",
      "Epoch 671/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5321 - accuracy: 0.7857\n",
      "Epoch 672/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7857\n",
      "Epoch 673/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5320 - accuracy: 0.7857\n",
      "Epoch 674/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7857\n",
      "Epoch 675/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5319 - accuracy: 0.7857\n",
      "Epoch 676/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5318 - accuracy: 0.7857\n",
      "Epoch 677/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5318 - accuracy: 0.7857\n",
      "Epoch 678/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7857\n",
      "Epoch 679/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5317 - accuracy: 0.7857\n",
      "Epoch 680/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5317 - accuracy: 0.7857\n",
      "Epoch 681/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7857\n",
      "Epoch 682/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5316 - accuracy: 0.7857\n",
      "Epoch 683/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7857\n",
      "Epoch 684/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5315 - accuracy: 0.7857\n",
      "Epoch 685/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7857\n",
      "Epoch 686/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5314 - accuracy: 0.7857\n",
      "Epoch 687/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7857\n",
      "Epoch 688/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5313 - accuracy: 0.7857\n",
      "Epoch 689/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7857\n",
      "Epoch 690/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5312 - accuracy: 0.7857\n",
      "Epoch 691/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7857\n",
      "Epoch 692/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5311 - accuracy: 0.7857\n",
      "Epoch 693/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5310 - accuracy: 0.7857\n",
      "Epoch 694/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5310 - accuracy: 0.7857\n",
      "Epoch 695/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7857\n",
      "Epoch 696/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5309 - accuracy: 0.7857\n",
      "Epoch 697/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5308 - accuracy: 0.7857\n",
      "Epoch 698/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5308 - accuracy: 0.7857\n",
      "Epoch 699/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7857\n",
      "Epoch 700/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5307 - accuracy: 0.7857\n",
      "Epoch 701/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7857\n",
      "Epoch 702/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5306 - accuracy: 0.7857\n",
      "Epoch 703/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7857\n",
      "Epoch 704/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7857\n",
      "Epoch 705/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5305 - accuracy: 0.7857\n",
      "Epoch 706/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7857\n",
      "Epoch 707/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5304 - accuracy: 0.7857\n",
      "Epoch 708/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7857\n",
      "Epoch 709/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5303 - accuracy: 0.7857\n",
      "Epoch 710/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7857\n",
      "Epoch 711/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5302 - accuracy: 0.7857\n",
      "Epoch 712/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7857\n",
      "Epoch 713/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5301 - accuracy: 0.7857\n",
      "Epoch 714/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7857\n",
      "Epoch 715/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5300 - accuracy: 0.7857\n",
      "Epoch 716/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7857\n",
      "Epoch 717/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5299 - accuracy: 0.7857\n",
      "Epoch 718/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5298 - accuracy: 0.7857\n",
      "Epoch 719/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5298 - accuracy: 0.7857\n",
      "Epoch 720/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7857\n",
      "Epoch 721/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5297 - accuracy: 0.7857\n",
      "Epoch 722/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5296 - accuracy: 0.7857\n",
      "Epoch 723/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5296 - accuracy: 0.7857\n",
      "Epoch 724/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7857\n",
      "Epoch 725/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5295 - accuracy: 0.7857\n",
      "Epoch 726/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7857\n",
      "Epoch 727/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7857\n",
      "Epoch 728/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5294 - accuracy: 0.7857\n",
      "Epoch 729/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7857\n",
      "Epoch 730/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5293 - accuracy: 0.7857\n",
      "Epoch 731/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7857\n",
      "Epoch 732/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5292 - accuracy: 0.7857\n",
      "Epoch 733/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7857\n",
      "Epoch 734/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5291 - accuracy: 0.7857\n",
      "Epoch 735/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7857\n",
      "Epoch 736/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5290 - accuracy: 0.7857\n",
      "Epoch 737/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7857\n",
      "Epoch 738/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5289 - accuracy: 0.7857\n",
      "Epoch 739/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7857\n",
      "Epoch 740/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5288 - accuracy: 0.7857\n",
      "Epoch 741/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7857\n",
      "Epoch 742/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5287 - accuracy: 0.7857\n",
      "Epoch 743/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7857\n",
      "Epoch 744/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5286 - accuracy: 0.7857\n",
      "Epoch 745/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7857\n",
      "Epoch 746/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5285 - accuracy: 0.7857\n",
      "Epoch 747/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.7857\n",
      "Epoch 748/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.8214\n",
      "Epoch 749/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5284 - accuracy: 0.8214\n",
      "Epoch 750/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8214\n",
      "Epoch 751/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5283 - accuracy: 0.8214\n",
      "Epoch 752/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8214\n",
      "Epoch 753/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5282 - accuracy: 0.8214\n",
      "Epoch 754/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8214\n",
      "Epoch 755/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5281 - accuracy: 0.8214\n",
      "Epoch 756/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8214\n",
      "Epoch 757/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5280 - accuracy: 0.8214\n",
      "Epoch 758/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5279 - accuracy: 0.8214\n",
      "Epoch 759/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.8214\n",
      "Epoch 760/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5278 - accuracy: 0.8214\n",
      "Epoch 761/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5278 - accuracy: 0.8214\n",
      "Epoch 762/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8214\n",
      "Epoch 763/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5277 - accuracy: 0.8214\n",
      "Epoch 764/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5276 - accuracy: 0.8214\n",
      "Epoch 765/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5276 - accuracy: 0.8214\n",
      "Epoch 766/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8214\n",
      "Epoch 767/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8214\n",
      "Epoch 768/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5275 - accuracy: 0.8214\n",
      "Epoch 769/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.8214\n",
      "Epoch 770/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5274 - accuracy: 0.8214\n",
      "Epoch 771/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8214\n",
      "Epoch 772/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5273 - accuracy: 0.8214\n",
      "Epoch 773/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8214\n",
      "Epoch 774/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5272 - accuracy: 0.8214\n",
      "Epoch 775/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8214\n",
      "Epoch 776/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5271 - accuracy: 0.8214\n",
      "Epoch 777/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8214\n",
      "Epoch 778/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5270 - accuracy: 0.8214\n",
      "Epoch 779/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8214\n",
      "Epoch 780/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5269 - accuracy: 0.8214\n",
      "Epoch 781/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.8214\n",
      "Epoch 782/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5268 - accuracy: 0.8214\n",
      "Epoch 783/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8214\n",
      "Epoch 784/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5267 - accuracy: 0.8214\n",
      "Epoch 785/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5266 - accuracy: 0.8214\n",
      "Epoch 786/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5266 - accuracy: 0.8214\n",
      "Epoch 787/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5266 - accuracy: 0.8214\n",
      "Epoch 788/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8214\n",
      "Epoch 789/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5265 - accuracy: 0.8214\n",
      "Epoch 790/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8214\n",
      "Epoch 791/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5264 - accuracy: 0.8214\n",
      "Epoch 792/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.8214\n",
      "Epoch 793/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5263 - accuracy: 0.8214\n",
      "Epoch 794/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8214\n",
      "Epoch 795/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5262 - accuracy: 0.8214\n",
      "Epoch 796/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.8214\n",
      "Epoch 797/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5261 - accuracy: 0.8214\n",
      "Epoch 798/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.8214\n",
      "Epoch 799/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5260 - accuracy: 0.8214\n",
      "Epoch 800/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.8214\n",
      "Epoch 801/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5259 - accuracy: 0.8214\n",
      "Epoch 802/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5259 - accuracy: 0.8214\n",
      "Epoch 803/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8214\n",
      "Epoch 804/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5258 - accuracy: 0.8214\n",
      "Epoch 805/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8214\n",
      "Epoch 806/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5257 - accuracy: 0.8214\n",
      "Epoch 807/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8214\n",
      "Epoch 808/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5256 - accuracy: 0.8214\n",
      "Epoch 809/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8214\n",
      "Epoch 810/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5255 - accuracy: 0.8214\n",
      "Epoch 811/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5254 - accuracy: 0.8214\n",
      "Epoch 812/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5254 - accuracy: 0.8214\n",
      "Epoch 813/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8214\n",
      "Epoch 814/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5253 - accuracy: 0.8214\n",
      "Epoch 815/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5252 - accuracy: 0.8214\n",
      "Epoch 816/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5252 - accuracy: 0.8214\n",
      "Epoch 817/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8214\n",
      "Epoch 818/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8214\n",
      "Epoch 819/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5251 - accuracy: 0.8214\n",
      "Epoch 820/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.8214\n",
      "Epoch 821/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5250 - accuracy: 0.8214\n",
      "Epoch 822/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8214\n",
      "Epoch 823/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5249 - accuracy: 0.8214\n",
      "Epoch 824/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8214\n",
      "Epoch 825/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5248 - accuracy: 0.8214\n",
      "Epoch 826/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8214\n",
      "Epoch 827/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5247 - accuracy: 0.8214\n",
      "Epoch 828/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8214\n",
      "Epoch 829/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5246 - accuracy: 0.8214\n",
      "Epoch 830/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5245 - accuracy: 0.8214\n",
      "Epoch 831/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8214\n",
      "Epoch 832/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5245 - accuracy: 0.8214\n",
      "Epoch 833/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8214\n",
      "Epoch 834/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5244 - accuracy: 0.8214\n",
      "Epoch 835/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.8214\n",
      "Epoch 836/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5243 - accuracy: 0.8214\n",
      "Epoch 837/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.8214\n",
      "Epoch 838/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5242 - accuracy: 0.8214\n",
      "Epoch 839/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.8214\n",
      "Epoch 840/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5241 - accuracy: 0.8214\n",
      "Epoch 841/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8214\n",
      "Epoch 842/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5240 - accuracy: 0.8214\n",
      "Epoch 843/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8214\n",
      "Epoch 844/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5239 - accuracy: 0.8214\n",
      "Epoch 845/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5238 - accuracy: 0.8214\n",
      "Epoch 846/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5238 - accuracy: 0.8214\n",
      "Epoch 847/2500\n",
      "1/1 [==============================] - 0s 972us/step - loss: 0.5238 - accuracy: 0.8214\n",
      "Epoch 848/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8214\n",
      "Epoch 849/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5237 - accuracy: 0.8214\n",
      "Epoch 850/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.8214\n",
      "Epoch 851/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5236 - accuracy: 0.8214\n",
      "Epoch 852/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.8214\n",
      "Epoch 853/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.8214\n",
      "Epoch 854/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.8214\n",
      "Epoch 855/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5234 - accuracy: 0.8214\n",
      "Epoch 856/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8214\n",
      "Epoch 857/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5233 - accuracy: 0.8214\n",
      "Epoch 858/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8214\n",
      "Epoch 859/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8214\n",
      "Epoch 860/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5232 - accuracy: 0.8214\n",
      "Epoch 861/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.8214\n",
      "Epoch 862/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5231 - accuracy: 0.8214\n",
      "Epoch 863/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8214\n",
      "Epoch 864/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5230 - accuracy: 0.8214\n",
      "Epoch 865/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8214\n",
      "Epoch 866/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5229 - accuracy: 0.8214\n",
      "Epoch 867/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8214\n",
      "Epoch 868/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5228 - accuracy: 0.8214\n",
      "Epoch 869/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8214\n",
      "Epoch 870/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5227 - accuracy: 0.8214\n",
      "Epoch 871/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.8214\n",
      "Epoch 872/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5226 - accuracy: 0.8214\n",
      "Epoch 873/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5226 - accuracy: 0.8214\n",
      "Epoch 874/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8214\n",
      "Epoch 875/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5225 - accuracy: 0.8214\n",
      "Epoch 876/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5224 - accuracy: 0.8214\n",
      "Epoch 877/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5224 - accuracy: 0.8214\n",
      "Epoch 878/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8214\n",
      "Epoch 879/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5223 - accuracy: 0.8214\n",
      "Epoch 880/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5222 - accuracy: 0.8214\n",
      "Epoch 881/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5222 - accuracy: 0.8214\n",
      "Epoch 882/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8214\n",
      "Epoch 883/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.8214\n",
      "Epoch 884/2500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5220 - accuracy: 0.8214\n",
      "Epoch 885/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5220 - accuracy: 0.8214\n",
      "Epoch 886/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5220 - accuracy: 0.8214\n",
      "Epoch 887/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8214\n",
      "Epoch 888/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.8214\n",
      "Epoch 889/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5218 - accuracy: 0.8571\n",
      "Epoch 890/2500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.5218 - accuracy: 0.8571\n",
      "Epoch 891/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5217 - accuracy: 0.8571\n",
      "Epoch 892/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5217 - accuracy: 0.8571\n",
      "Epoch 893/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5216 - accuracy: 0.8571\n",
      "Epoch 894/2500\n",
      "1/1 [==============================] - 0s 11ms/step - loss: 0.5216 - accuracy: 0.8571\n",
      "Epoch 895/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5215 - accuracy: 0.8571\n",
      "Epoch 896/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5215 - accuracy: 0.8571\n",
      "Epoch 897/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5214 - accuracy: 0.8571\n",
      "Epoch 898/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5214 - accuracy: 0.8571\n",
      "Epoch 899/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5214 - accuracy: 0.8571\n",
      "Epoch 900/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5213 - accuracy: 0.8571\n",
      "Epoch 901/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5213 - accuracy: 0.8571\n",
      "Epoch 902/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5212 - accuracy: 0.8571\n",
      "Epoch 903/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5212 - accuracy: 0.8571\n",
      "Epoch 904/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.8571\n",
      "Epoch 905/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5211 - accuracy: 0.8571\n",
      "Epoch 906/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5210 - accuracy: 0.8571\n",
      "Epoch 907/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5210 - accuracy: 0.8571\n",
      "Epoch 908/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8571\n",
      "Epoch 909/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8571\n",
      "Epoch 910/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5209 - accuracy: 0.8571\n",
      "Epoch 911/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8571\n",
      "Epoch 912/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5208 - accuracy: 0.8571\n",
      "Epoch 913/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5207 - accuracy: 0.8571\n",
      "Epoch 914/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5207 - accuracy: 0.8571\n",
      "Epoch 915/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8571\n",
      "Epoch 916/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5206 - accuracy: 0.8571\n",
      "Epoch 917/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5205 - accuracy: 0.8571\n",
      "Epoch 918/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5205 - accuracy: 0.8571\n",
      "Epoch 919/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8571\n",
      "Epoch 920/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8571\n",
      "Epoch 921/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5204 - accuracy: 0.8571\n",
      "Epoch 922/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8571\n",
      "Epoch 923/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5203 - accuracy: 0.8571\n",
      "Epoch 924/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5202 - accuracy: 0.8571\n",
      "Epoch 925/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5202 - accuracy: 0.8571\n",
      "Epoch 926/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8571\n",
      "Epoch 927/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5201 - accuracy: 0.8571\n",
      "Epoch 928/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.8571\n",
      "Epoch 929/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5200 - accuracy: 0.8571\n",
      "Epoch 930/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8571\n",
      "Epoch 931/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8571\n",
      "Epoch 932/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5199 - accuracy: 0.8571\n",
      "Epoch 933/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5198 - accuracy: 0.8571\n",
      "Epoch 934/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.8571\n",
      "Epoch 935/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8571\n",
      "Epoch 936/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.8571\n",
      "Epoch 937/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5196 - accuracy: 0.8571\n",
      "Epoch 938/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5196 - accuracy: 0.8571\n",
      "Epoch 939/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5195 - accuracy: 0.8571\n",
      "Epoch 940/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5195 - accuracy: 0.8571\n",
      "Epoch 941/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5194 - accuracy: 0.8571\n",
      "Epoch 942/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8571\n",
      "Epoch 943/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5194 - accuracy: 0.8571\n",
      "Epoch 944/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8571\n",
      "Epoch 945/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5193 - accuracy: 0.8571\n",
      "Epoch 946/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8571\n",
      "Epoch 947/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5192 - accuracy: 0.8571\n",
      "Epoch 948/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8571\n",
      "Epoch 949/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5191 - accuracy: 0.8571\n",
      "Epoch 950/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.8571\n",
      "Epoch 951/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5190 - accuracy: 0.8571\n",
      "Epoch 952/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5189 - accuracy: 0.8571\n",
      "Epoch 953/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8571\n",
      "Epoch 954/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5189 - accuracy: 0.8571\n",
      "Epoch 955/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5188 - accuracy: 0.8571\n",
      "Epoch 956/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5188 - accuracy: 0.8571\n",
      "Epoch 957/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8571\n",
      "Epoch 958/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5187 - accuracy: 0.8571\n",
      "Epoch 959/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8571\n",
      "Epoch 960/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5186 - accuracy: 0.8571\n",
      "Epoch 961/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8571\n",
      "Epoch 962/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8571\n",
      "Epoch 963/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5185 - accuracy: 0.8571\n",
      "Epoch 964/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5184 - accuracy: 0.8571\n",
      "Epoch 965/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5184 - accuracy: 0.8571\n",
      "Epoch 966/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8571\n",
      "Epoch 967/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5183 - accuracy: 0.8571\n",
      "Epoch 968/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8571\n",
      "Epoch 969/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5182 - accuracy: 0.8571\n",
      "Epoch 970/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5181 - accuracy: 0.8571\n",
      "Epoch 971/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5181 - accuracy: 0.8571\n",
      "Epoch 972/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8571\n",
      "Epoch 973/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8571\n",
      "Epoch 974/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5180 - accuracy: 0.8571\n",
      "Epoch 975/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5179 - accuracy: 0.8571\n",
      "Epoch 976/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5179 - accuracy: 0.8571\n",
      "Epoch 977/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8571\n",
      "Epoch 978/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5178 - accuracy: 0.8571\n",
      "Epoch 979/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8571\n",
      "Epoch 980/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5177 - accuracy: 0.8571\n",
      "Epoch 981/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5176 - accuracy: 0.8571\n",
      "Epoch 982/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8571\n",
      "Epoch 983/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5176 - accuracy: 0.8571\n",
      "Epoch 984/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8571\n",
      "Epoch 985/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5175 - accuracy: 0.8571\n",
      "Epoch 986/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8571\n",
      "Epoch 987/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5174 - accuracy: 0.8571\n",
      "Epoch 988/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8571\n",
      "Epoch 989/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5173 - accuracy: 0.8571\n",
      "Epoch 990/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8571\n",
      "Epoch 991/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5172 - accuracy: 0.8571\n",
      "Epoch 992/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8571\n",
      "Epoch 993/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8571\n",
      "Epoch 994/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5171 - accuracy: 0.8571\n",
      "Epoch 995/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8571\n",
      "Epoch 996/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5170 - accuracy: 0.8571\n",
      "Epoch 997/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5169 - accuracy: 0.8571\n",
      "Epoch 998/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5169 - accuracy: 0.8571\n",
      "Epoch 999/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.8571\n",
      "Epoch 1000/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5168 - accuracy: 0.8571\n",
      "Epoch 1001/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8571\n",
      "Epoch 1002/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8571\n",
      "Epoch 1003/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5167 - accuracy: 0.8571\n",
      "Epoch 1004/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8571\n",
      "Epoch 1005/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5166 - accuracy: 0.8571\n",
      "Epoch 1006/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8571\n",
      "Epoch 1007/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5165 - accuracy: 0.8571\n",
      "Epoch 1008/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8571\n",
      "Epoch 1009/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5164 - accuracy: 0.8571\n",
      "Epoch 1010/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5163 - accuracy: 0.8571\n",
      "Epoch 1011/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5163 - accuracy: 0.8571\n",
      "Epoch 1012/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5163 - accuracy: 0.8571\n",
      "Epoch 1013/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.8571\n",
      "Epoch 1014/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.8571\n",
      "Epoch 1015/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5161 - accuracy: 0.8571\n",
      "Epoch 1016/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5161 - accuracy: 0.8571\n",
      "Epoch 1017/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.8571\n",
      "Epoch 1018/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5160 - accuracy: 0.8571\n",
      "Epoch 1019/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 1020/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 1021/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5159 - accuracy: 0.8571\n",
      "Epoch 1022/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.8571\n",
      "Epoch 1023/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5158 - accuracy: 0.8571\n",
      "Epoch 1024/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5157 - accuracy: 0.8571\n",
      "Epoch 1025/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5157 - accuracy: 0.8571\n",
      "Epoch 1026/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5156 - accuracy: 0.8571\n",
      "Epoch 1027/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5156 - accuracy: 0.8571\n",
      "Epoch 1028/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5155 - accuracy: 0.8571\n",
      "Epoch 1029/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5155 - accuracy: 0.8571\n",
      "Epoch 1030/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5155 - accuracy: 0.8571\n",
      "Epoch 1031/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8571\n",
      "Epoch 1032/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5154 - accuracy: 0.8571\n",
      "Epoch 1033/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8571\n",
      "Epoch 1034/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5153 - accuracy: 0.8571\n",
      "Epoch 1035/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8571\n",
      "Epoch 1036/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5152 - accuracy: 0.8571\n",
      "Epoch 1037/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8571\n",
      "Epoch 1038/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8571\n",
      "Epoch 1039/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5151 - accuracy: 0.8571\n",
      "Epoch 1040/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8571\n",
      "Epoch 1041/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5150 - accuracy: 0.8571\n",
      "Epoch 1042/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8571\n",
      "Epoch 1043/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5149 - accuracy: 0.8571\n",
      "Epoch 1044/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5148 - accuracy: 0.8571\n",
      "Epoch 1045/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.5148 - accuracy: 0.8571\n",
      "Epoch 1046/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5147 - accuracy: 0.8571\n",
      "Epoch 1047/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8571\n",
      "Epoch 1048/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5147 - accuracy: 0.8929\n",
      "Epoch 1049/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8929\n",
      "Epoch 1050/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5146 - accuracy: 0.8929\n",
      "Epoch 1051/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8929\n",
      "Epoch 1052/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5145 - accuracy: 0.8929\n",
      "Epoch 1053/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8929\n",
      "Epoch 1054/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5144 - accuracy: 0.8929\n",
      "Epoch 1055/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5144 - accuracy: 0.8929\n",
      "Epoch 1056/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8929\n",
      "Epoch 1057/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5143 - accuracy: 0.8929\n",
      "Epoch 1058/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.8929\n",
      "Epoch 1059/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5142 - accuracy: 0.8929\n",
      "Epoch 1060/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8929\n",
      "Epoch 1061/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5141 - accuracy: 0.8929\n",
      "Epoch 1062/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8929\n",
      "Epoch 1063/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8929\n",
      "Epoch 1064/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5140 - accuracy: 0.8929\n",
      "Epoch 1065/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5139 - accuracy: 0.8929\n",
      "Epoch 1066/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5139 - accuracy: 0.8929\n",
      "Epoch 1067/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.8929\n",
      "Epoch 1068/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5138 - accuracy: 0.8929\n",
      "Epoch 1069/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5137 - accuracy: 0.8929\n",
      "Epoch 1070/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5137 - accuracy: 0.8929\n",
      "Epoch 1071/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5136 - accuracy: 0.8929\n",
      "Epoch 1072/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8929\n",
      "Epoch 1073/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5136 - accuracy: 0.8929\n",
      "Epoch 1074/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8929\n",
      "Epoch 1075/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5135 - accuracy: 0.8929\n",
      "Epoch 1076/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8929\n",
      "Epoch 1077/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5134 - accuracy: 0.8929\n",
      "Epoch 1078/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8929\n",
      "Epoch 1079/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5133 - accuracy: 0.8929\n",
      "Epoch 1080/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5133 - accuracy: 0.8929\n",
      "Epoch 1081/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8929\n",
      "Epoch 1082/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5132 - accuracy: 0.8929\n",
      "Epoch 1083/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5131 - accuracy: 0.8929\n",
      "Epoch 1084/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.8929\n",
      "Epoch 1085/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8929\n",
      "Epoch 1086/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5130 - accuracy: 0.8929\n",
      "Epoch 1087/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8929\n",
      "Epoch 1088/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8929\n",
      "Epoch 1089/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5129 - accuracy: 0.8929\n",
      "Epoch 1090/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8929\n",
      "Epoch 1091/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5128 - accuracy: 0.8929\n",
      "Epoch 1092/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.8929\n",
      "Epoch 1093/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5127 - accuracy: 0.8929\n",
      "Epoch 1094/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8929\n",
      "Epoch 1095/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.8929\n",
      "Epoch 1096/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5126 - accuracy: 0.8929\n",
      "Epoch 1097/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8929\n",
      "Epoch 1098/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5125 - accuracy: 0.8929\n",
      "Epoch 1099/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5124 - accuracy: 0.8929\n",
      "Epoch 1100/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5124 - accuracy: 0.8929\n",
      "Epoch 1101/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8929\n",
      "Epoch 1102/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5123 - accuracy: 0.8929\n",
      "Epoch 1103/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.8929\n",
      "Epoch 1104/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8929\n",
      "Epoch 1105/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.8929\n",
      "Epoch 1106/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.8929\n",
      "Epoch 1107/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5121 - accuracy: 0.8929\n",
      "Epoch 1108/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5120 - accuracy: 0.8929\n",
      "Epoch 1109/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5120 - accuracy: 0.8929\n",
      "Epoch 1110/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8929\n",
      "Epoch 1111/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.5119 - accuracy: 0.8929\n",
      "Epoch 1112/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5119 - accuracy: 0.8929\n",
      "Epoch 1113/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8929\n",
      "Epoch 1114/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5118 - accuracy: 0.8929\n",
      "Epoch 1115/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8929\n",
      "Epoch 1116/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5117 - accuracy: 0.8929\n",
      "Epoch 1117/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8929\n",
      "Epoch 1118/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5116 - accuracy: 0.8929\n",
      "Epoch 1119/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5116 - accuracy: 0.8929\n",
      "Epoch 1120/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8929\n",
      "Epoch 1121/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.8929\n",
      "Epoch 1122/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8929\n",
      "Epoch 1123/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5114 - accuracy: 0.8929\n",
      "Epoch 1124/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5113 - accuracy: 0.8929\n",
      "Epoch 1125/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5113 - accuracy: 0.8929\n",
      "Epoch 1126/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5113 - accuracy: 0.8929\n",
      "Epoch 1127/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8929\n",
      "Epoch 1128/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5112 - accuracy: 0.8929\n",
      "Epoch 1129/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5111 - accuracy: 0.8929\n",
      "Epoch 1130/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5111 - accuracy: 0.8929\n",
      "Epoch 1131/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5110 - accuracy: 0.8929\n",
      "Epoch 1132/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8929\n",
      "Epoch 1133/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.8929\n",
      "Epoch 1134/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5109 - accuracy: 0.8929\n",
      "Epoch 1135/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5109 - accuracy: 0.8929\n",
      "Epoch 1136/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5108 - accuracy: 0.8929\n",
      "Epoch 1137/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5108 - accuracy: 0.8929\n",
      "Epoch 1138/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5107 - accuracy: 0.8929\n",
      "Epoch 1139/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5107 - accuracy: 0.8929\n",
      "Epoch 1140/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8929\n",
      "Epoch 1141/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5106 - accuracy: 0.8929\n",
      "Epoch 1142/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.8929\n",
      "Epoch 1143/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5105 - accuracy: 0.8929\n",
      "Epoch 1144/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.8929\n",
      "Epoch 1145/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8929\n",
      "Epoch 1146/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5104 - accuracy: 0.8929\n",
      "Epoch 1147/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8929\n",
      "Epoch 1148/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5103 - accuracy: 0.8929\n",
      "Epoch 1149/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5103 - accuracy: 0.8929\n",
      "Epoch 1150/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5102 - accuracy: 0.8929\n",
      "Epoch 1151/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5102 - accuracy: 0.8929\n",
      "Epoch 1152/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5101 - accuracy: 0.8929\n",
      "Epoch 1153/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5101 - accuracy: 0.8929\n",
      "Epoch 1154/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8929\n",
      "Epoch 1155/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.8929\n",
      "Epoch 1156/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5100 - accuracy: 0.8929\n",
      "Epoch 1157/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8929\n",
      "Epoch 1158/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5099 - accuracy: 0.8929\n",
      "Epoch 1159/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5098 - accuracy: 0.8929\n",
      "Epoch 1160/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5098 - accuracy: 0.8929\n",
      "Epoch 1161/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8929\n",
      "Epoch 1162/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5097 - accuracy: 0.8929\n",
      "Epoch 1163/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.8929\n",
      "Epoch 1164/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8929\n",
      "Epoch 1165/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.8929\n",
      "Epoch 1166/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8929\n",
      "Epoch 1167/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5095 - accuracy: 0.8929\n",
      "Epoch 1168/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8929\n",
      "Epoch 1169/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8929\n",
      "Epoch 1170/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5094 - accuracy: 0.8929\n",
      "Epoch 1171/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8929\n",
      "Epoch 1172/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5093 - accuracy: 0.8929\n",
      "Epoch 1173/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8929\n",
      "Epoch 1174/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5092 - accuracy: 0.8929\n",
      "Epoch 1175/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8929\n",
      "Epoch 1176/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8929\n",
      "Epoch 1177/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5091 - accuracy: 0.8929\n",
      "Epoch 1178/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8929\n",
      "Epoch 1179/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5090 - accuracy: 0.8929\n",
      "Epoch 1180/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8929\n",
      "Epoch 1181/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5089 - accuracy: 0.8929\n",
      "Epoch 1182/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.8929\n",
      "Epoch 1183/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8929\n",
      "Epoch 1184/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5088 - accuracy: 0.8929\n",
      "Epoch 1185/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8929\n",
      "Epoch 1186/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5087 - accuracy: 0.8929\n",
      "Epoch 1187/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8929\n",
      "Epoch 1188/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8929\n",
      "Epoch 1189/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5086 - accuracy: 0.8929\n",
      "Epoch 1190/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8929\n",
      "Epoch 1191/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5085 - accuracy: 0.8929\n",
      "Epoch 1192/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5084 - accuracy: 0.8929\n",
      "Epoch 1193/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.5084 - accuracy: 0.8929\n",
      "Epoch 1194/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8929\n",
      "Epoch 1195/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8929\n",
      "Epoch 1196/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5083 - accuracy: 0.8929\n",
      "Epoch 1197/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8929\n",
      "Epoch 1198/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8929\n",
      "Epoch 1199/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8929\n",
      "Epoch 1200/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5081 - accuracy: 0.8929\n",
      "Epoch 1201/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8929\n",
      "Epoch 1202/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5080 - accuracy: 0.8929\n",
      "Epoch 1203/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5080 - accuracy: 0.8929\n",
      "Epoch 1204/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5079 - accuracy: 0.8929\n",
      "Epoch 1205/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5079 - accuracy: 0.8929\n",
      "Epoch 1206/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5078 - accuracy: 0.8929\n",
      "Epoch 1207/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5078 - accuracy: 0.8929\n",
      "Epoch 1208/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8929\n",
      "Epoch 1209/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5077 - accuracy: 0.8929\n",
      "Epoch 1210/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5077 - accuracy: 0.8929\n",
      "Epoch 1211/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.8929\n",
      "Epoch 1212/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5076 - accuracy: 0.8929\n",
      "Epoch 1213/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5075 - accuracy: 0.8929\n",
      "Epoch 1214/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5075 - accuracy: 0.8929\n",
      "Epoch 1215/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.8929\n",
      "Epoch 1216/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8929\n",
      "Epoch 1217/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5074 - accuracy: 0.8929\n",
      "Epoch 1218/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.8929\n",
      "Epoch 1219/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5073 - accuracy: 0.8929\n",
      "Epoch 1220/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8929\n",
      "Epoch 1221/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5072 - accuracy: 0.8929\n",
      "Epoch 1222/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5072 - accuracy: 0.8929\n",
      "Epoch 1223/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8929\n",
      "Epoch 1224/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5071 - accuracy: 0.8929\n",
      "Epoch 1225/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8929\n",
      "Epoch 1226/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.8929\n",
      "Epoch 1227/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8929\n",
      "Epoch 1228/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5069 - accuracy: 0.8929\n",
      "Epoch 1229/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.8929\n",
      "Epoch 1230/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.8929\n",
      "Epoch 1231/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5068 - accuracy: 0.8929\n",
      "Epoch 1232/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5067 - accuracy: 0.8929\n",
      "Epoch 1233/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5067 - accuracy: 0.8929\n",
      "Epoch 1234/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8929\n",
      "Epoch 1235/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5066 - accuracy: 0.8929\n",
      "Epoch 1236/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5066 - accuracy: 0.8929\n",
      "Epoch 1237/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5065 - accuracy: 0.8929\n",
      "Epoch 1238/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5065 - accuracy: 0.8929\n",
      "Epoch 1239/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8929\n",
      "Epoch 1240/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5064 - accuracy: 0.8929\n",
      "Epoch 1241/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5064 - accuracy: 0.8929\n",
      "Epoch 1242/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.8929\n",
      "Epoch 1243/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.8929\n",
      "Epoch 1244/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5062 - accuracy: 0.8929\n",
      "Epoch 1245/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5062 - accuracy: 0.8929\n",
      "Epoch 1246/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8929\n",
      "Epoch 1247/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5061 - accuracy: 0.8929\n",
      "Epoch 1248/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5061 - accuracy: 0.8929\n",
      "Epoch 1249/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8929\n",
      "Epoch 1250/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5060 - accuracy: 0.8929\n",
      "Epoch 1251/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5059 - accuracy: 0.8929\n",
      "Epoch 1252/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.8929\n",
      "Epoch 1253/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5058 - accuracy: 0.8929\n",
      "Epoch 1254/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8929\n",
      "Epoch 1255/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5058 - accuracy: 0.8929\n",
      "Epoch 1256/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8929\n",
      "Epoch 1257/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5057 - accuracy: 0.8929\n",
      "Epoch 1258/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8929\n",
      "Epoch 1259/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.8929\n",
      "Epoch 1260/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5056 - accuracy: 0.8929\n",
      "Epoch 1261/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5055 - accuracy: 0.8929\n",
      "Epoch 1262/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5055 - accuracy: 0.8929\n",
      "Epoch 1263/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8929\n",
      "Epoch 1264/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5054 - accuracy: 0.8929\n",
      "Epoch 1265/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8929\n",
      "Epoch 1266/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8929\n",
      "Epoch 1267/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5053 - accuracy: 0.8929\n",
      "Epoch 1268/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8929\n",
      "Epoch 1269/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5052 - accuracy: 0.8929\n",
      "Epoch 1270/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5051 - accuracy: 0.8929\n",
      "Epoch 1271/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8929\n",
      "Epoch 1272/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5051 - accuracy: 0.8929\n",
      "Epoch 1273/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8929\n",
      "Epoch 1274/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5050 - accuracy: 0.8929\n",
      "Epoch 1275/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5049 - accuracy: 0.8929\n",
      "Epoch 1276/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5049 - accuracy: 0.8929\n",
      "Epoch 1277/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5048 - accuracy: 0.8929\n",
      "Epoch 1278/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8929\n",
      "Epoch 1279/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5048 - accuracy: 0.8929\n",
      "Epoch 1280/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8929\n",
      "Epoch 1281/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5047 - accuracy: 0.8929\n",
      "Epoch 1282/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8929\n",
      "Epoch 1283/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5046 - accuracy: 0.8929\n",
      "Epoch 1284/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5046 - accuracy: 0.8929\n",
      "Epoch 1285/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8929\n",
      "Epoch 1286/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5045 - accuracy: 0.8929\n",
      "Epoch 1287/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8929\n",
      "Epoch 1288/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5044 - accuracy: 0.8929\n",
      "Epoch 1289/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8929\n",
      "Epoch 1290/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8929\n",
      "Epoch 1291/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5043 - accuracy: 0.8929\n",
      "Epoch 1292/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5042 - accuracy: 0.8929\n",
      "Epoch 1293/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5042 - accuracy: 0.8929\n",
      "Epoch 1294/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8929\n",
      "Epoch 1295/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8929\n",
      "Epoch 1296/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5041 - accuracy: 0.8929\n",
      "Epoch 1297/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8929\n",
      "Epoch 1298/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5040 - accuracy: 0.8929\n",
      "Epoch 1299/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8929\n",
      "Epoch 1300/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8929\n",
      "Epoch 1301/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5039 - accuracy: 0.8929\n",
      "Epoch 1302/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8929\n",
      "Epoch 1303/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5038 - accuracy: 0.8929\n",
      "Epoch 1304/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8929\n",
      "Epoch 1305/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.8929\n",
      "Epoch 1306/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8929\n",
      "Epoch 1307/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8929\n",
      "Epoch 1308/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.8929\n",
      "Epoch 1309/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5035 - accuracy: 0.8929\n",
      "Epoch 1310/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5035 - accuracy: 0.8929\n",
      "Epoch 1311/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8929\n",
      "Epoch 1312/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8929\n",
      "Epoch 1313/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5034 - accuracy: 0.8929\n",
      "Epoch 1314/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8929\n",
      "Epoch 1315/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5033 - accuracy: 0.8929\n",
      "Epoch 1316/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8929\n",
      "Epoch 1317/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8929\n",
      "Epoch 1318/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5032 - accuracy: 0.8929\n",
      "Epoch 1319/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8929\n",
      "Epoch 1320/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5031 - accuracy: 0.8929\n",
      "Epoch 1321/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8929\n",
      "Epoch 1322/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5030 - accuracy: 0.8929\n",
      "Epoch 1323/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8929\n",
      "Epoch 1324/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8929\n",
      "Epoch 1325/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5029 - accuracy: 0.8929\n",
      "Epoch 1326/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8929\n",
      "Epoch 1327/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5028 - accuracy: 0.8929\n",
      "Epoch 1328/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8929\n",
      "Epoch 1329/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5027 - accuracy: 0.8929\n",
      "Epoch 1330/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5027 - accuracy: 0.8929\n",
      "Epoch 1331/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5026 - accuracy: 0.8929\n",
      "Epoch 1332/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5026 - accuracy: 0.8929\n",
      "Epoch 1333/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8929\n",
      "Epoch 1334/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8929\n",
      "Epoch 1335/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5025 - accuracy: 0.8929\n",
      "Epoch 1336/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8929\n",
      "Epoch 1337/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5024 - accuracy: 0.8929\n",
      "Epoch 1338/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.5023 - accuracy: 0.8929\n",
      "Epoch 1339/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5023 - accuracy: 0.8929\n",
      "Epoch 1340/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 1341/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 1342/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.8929\n",
      "Epoch 1343/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8929\n",
      "Epoch 1344/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5021 - accuracy: 0.8929\n",
      "Epoch 1345/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8929\n",
      "Epoch 1346/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5020 - accuracy: 0.8929\n",
      "Epoch 1347/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5020 - accuracy: 0.8929\n",
      "Epoch 1348/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5019 - accuracy: 0.8929\n",
      "Epoch 1349/2500\n",
      "1/1 [==============================] - 0s 13ms/step - loss: 0.5019 - accuracy: 0.8929\n",
      "Epoch 1350/2500\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5018 - accuracy: 0.8929\n",
      "Epoch 1351/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5018 - accuracy: 0.8929\n",
      "Epoch 1352/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5018 - accuracy: 0.8929\n",
      "Epoch 1353/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8929\n",
      "Epoch 1354/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5017 - accuracy: 0.8929\n",
      "Epoch 1355/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.5016 - accuracy: 0.8929\n",
      "Epoch 1356/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.8929\n",
      "Epoch 1357/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.5016 - accuracy: 0.8929\n",
      "Epoch 1358/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.5015 - accuracy: 0.8929\n",
      "Epoch 1359/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.5015 - accuracy: 0.8929\n",
      "Epoch 1360/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8929\n",
      "Epoch 1361/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5014 - accuracy: 0.8929\n",
      "Epoch 1362/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5014 - accuracy: 0.8929\n",
      "Epoch 1363/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5013 - accuracy: 0.8929\n",
      "Epoch 1364/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5013 - accuracy: 0.8929\n",
      "Epoch 1365/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.5012 - accuracy: 0.8929\n",
      "Epoch 1366/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5012 - accuracy: 0.8929\n",
      "Epoch 1367/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8929\n",
      "Epoch 1368/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8929\n",
      "Epoch 1369/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5011 - accuracy: 0.8929\n",
      "Epoch 1370/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8929\n",
      "Epoch 1371/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5010 - accuracy: 0.8929\n",
      "Epoch 1372/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8929\n",
      "Epoch 1373/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8929\n",
      "Epoch 1374/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5009 - accuracy: 0.8929\n",
      "Epoch 1375/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5008 - accuracy: 0.8929\n",
      "Epoch 1376/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5008 - accuracy: 0.8929\n",
      "Epoch 1377/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5007 - accuracy: 0.8929\n",
      "Epoch 1378/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8929\n",
      "Epoch 1379/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5007 - accuracy: 0.8929\n",
      "Epoch 1380/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.8929\n",
      "Epoch 1381/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5006 - accuracy: 0.8929\n",
      "Epoch 1382/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8929\n",
      "Epoch 1383/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5005 - accuracy: 0.8929\n",
      "Epoch 1384/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.8929\n",
      "Epoch 1385/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8929\n",
      "Epoch 1386/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.8929\n",
      "Epoch 1387/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8929\n",
      "Epoch 1388/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8929\n",
      "Epoch 1389/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5003 - accuracy: 0.8929\n",
      "Epoch 1390/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5002 - accuracy: 0.8929\n",
      "Epoch 1391/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5002 - accuracy: 0.8929\n",
      "Epoch 1392/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.5001 - accuracy: 0.8929\n",
      "Epoch 1393/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.8929\n",
      "Epoch 1394/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5001 - accuracy: 0.8929\n",
      "Epoch 1395/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8929\n",
      "Epoch 1396/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.5000 - accuracy: 0.8929\n",
      "Epoch 1397/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8929\n",
      "Epoch 1398/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8929\n",
      "Epoch 1399/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4999 - accuracy: 0.8929\n",
      "Epoch 1400/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4998 - accuracy: 0.8929\n",
      "Epoch 1401/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4998 - accuracy: 0.8929\n",
      "Epoch 1402/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8929\n",
      "Epoch 1403/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8929\n",
      "Epoch 1404/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4997 - accuracy: 0.8929\n",
      "Epoch 1405/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4996 - accuracy: 0.8929\n",
      "Epoch 1406/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4996 - accuracy: 0.8929\n",
      "Epoch 1407/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8929\n",
      "Epoch 1408/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8929\n",
      "Epoch 1409/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4995 - accuracy: 0.8929\n",
      "Epoch 1410/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8929\n",
      "Epoch 1411/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4994 - accuracy: 0.8929\n",
      "Epoch 1412/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8929\n",
      "Epoch 1413/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4993 - accuracy: 0.8929\n",
      "Epoch 1414/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8929\n",
      "Epoch 1415/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8929\n",
      "Epoch 1416/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4992 - accuracy: 0.8929\n",
      "Epoch 1417/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8929\n",
      "Epoch 1418/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4991 - accuracy: 0.8929\n",
      "Epoch 1419/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4990 - accuracy: 0.8929\n",
      "Epoch 1420/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4990 - accuracy: 0.8929\n",
      "Epoch 1421/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4990 - accuracy: 0.8929\n",
      "Epoch 1422/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4989 - accuracy: 0.8929\n",
      "Epoch 1423/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4989 - accuracy: 0.8929\n",
      "Epoch 1424/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8929\n",
      "Epoch 1425/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.8929\n",
      "Epoch 1426/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4988 - accuracy: 0.8929\n",
      "Epoch 1427/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4987 - accuracy: 0.8929\n",
      "Epoch 1428/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4987 - accuracy: 0.8929\n",
      "Epoch 1429/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4986 - accuracy: 0.8929\n",
      "Epoch 1430/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8929\n",
      "Epoch 1431/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4986 - accuracy: 0.8929\n",
      "Epoch 1432/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4985 - accuracy: 0.8929\n",
      "Epoch 1433/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4985 - accuracy: 0.8929\n",
      "Epoch 1434/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8929\n",
      "Epoch 1435/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8929\n",
      "Epoch 1436/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4984 - accuracy: 0.8929\n",
      "Epoch 1437/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8929\n",
      "Epoch 1438/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4983 - accuracy: 0.8929\n",
      "Epoch 1439/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8929\n",
      "Epoch 1440/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8929\n",
      "Epoch 1441/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.8929\n",
      "Epoch 1442/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8929\n",
      "Epoch 1443/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8929\n",
      "Epoch 1444/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4981 - accuracy: 0.8929\n",
      "Epoch 1445/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8929\n",
      "Epoch 1446/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4980 - accuracy: 0.8929\n",
      "Epoch 1447/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8929\n",
      "Epoch 1448/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8929\n",
      "Epoch 1449/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4979 - accuracy: 0.8929\n",
      "Epoch 1450/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8929\n",
      "Epoch 1451/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4978 - accuracy: 0.8929\n",
      "Epoch 1452/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8929\n",
      "Epoch 1453/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8929\n",
      "Epoch 1454/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4977 - accuracy: 0.8929\n",
      "Epoch 1455/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8929\n",
      "Epoch 1456/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4976 - accuracy: 0.8929\n",
      "Epoch 1457/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8929\n",
      "Epoch 1458/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8929\n",
      "Epoch 1459/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4975 - accuracy: 0.8929\n",
      "Epoch 1460/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8929\n",
      "Epoch 1461/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4974 - accuracy: 0.8929\n",
      "Epoch 1462/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.8929\n",
      "Epoch 1463/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8929\n",
      "Epoch 1464/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4973 - accuracy: 0.8929\n",
      "Epoch 1465/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8929\n",
      "Epoch 1466/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4972 - accuracy: 0.8929\n",
      "Epoch 1467/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4971 - accuracy: 0.8929\n",
      "Epoch 1468/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8929\n",
      "Epoch 1469/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4971 - accuracy: 0.8929\n",
      "Epoch 1470/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4970 - accuracy: 0.8929\n",
      "Epoch 1471/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4970 - accuracy: 0.8929\n",
      "Epoch 1472/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8929\n",
      "Epoch 1473/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8929\n",
      "Epoch 1474/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4969 - accuracy: 0.8929\n",
      "Epoch 1475/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8929\n",
      "Epoch 1476/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4968 - accuracy: 0.8929\n",
      "Epoch 1477/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8929\n",
      "Epoch 1478/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4967 - accuracy: 0.8929\n",
      "Epoch 1479/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4967 - accuracy: 0.8929\n",
      "Epoch 1480/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8929\n",
      "Epoch 1481/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4966 - accuracy: 0.8929\n",
      "Epoch 1482/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8929\n",
      "Epoch 1483/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4965 - accuracy: 0.8929\n",
      "Epoch 1484/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4965 - accuracy: 0.8929\n",
      "Epoch 1485/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8929\n",
      "Epoch 1486/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4964 - accuracy: 0.8929\n",
      "Epoch 1487/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8929\n",
      "Epoch 1488/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4963 - accuracy: 0.8929\n",
      "Epoch 1489/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4963 - accuracy: 0.8929\n",
      "Epoch 1490/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8929\n",
      "Epoch 1491/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8929\n",
      "Epoch 1492/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4962 - accuracy: 0.8929\n",
      "Epoch 1493/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4961 - accuracy: 0.8929\n",
      "Epoch 1494/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4961 - accuracy: 0.8929\n",
      "Epoch 1495/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4960 - accuracy: 0.8929\n",
      "Epoch 1496/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8929\n",
      "Epoch 1497/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4960 - accuracy: 0.8929\n",
      "Epoch 1498/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8929\n",
      "Epoch 1499/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4959 - accuracy: 0.8929\n",
      "Epoch 1500/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8929\n",
      "Epoch 1501/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8929\n",
      "Epoch 1502/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4958 - accuracy: 0.8929\n",
      "Epoch 1503/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4957 - accuracy: 0.8929\n",
      "Epoch 1504/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.8929\n",
      "Epoch 1505/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8929\n",
      "Epoch 1506/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8929\n",
      "Epoch 1507/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4956 - accuracy: 0.8929\n",
      "Epoch 1508/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8929\n",
      "Epoch 1509/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4955 - accuracy: 0.8929\n",
      "Epoch 1510/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8929\n",
      "Epoch 1511/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8929\n",
      "Epoch 1512/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4954 - accuracy: 0.8929\n",
      "Epoch 1513/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4953 - accuracy: 0.8929\n",
      "Epoch 1514/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4953 - accuracy: 0.8929\n",
      "Epoch 1515/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4953 - accuracy: 0.8929\n",
      "Epoch 1516/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8929\n",
      "Epoch 1517/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4952 - accuracy: 0.8929\n",
      "Epoch 1518/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8929\n",
      "Epoch 1519/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8929\n",
      "Epoch 1520/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4951 - accuracy: 0.8929\n",
      "Epoch 1521/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8929\n",
      "Epoch 1522/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4950 - accuracy: 0.8929\n",
      "Epoch 1523/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8929\n",
      "Epoch 1524/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8929\n",
      "Epoch 1525/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4949 - accuracy: 0.8929\n",
      "Epoch 1526/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8929\n",
      "Epoch 1527/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4948 - accuracy: 0.8929\n",
      "Epoch 1528/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8929\n",
      "Epoch 1529/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8929\n",
      "Epoch 1530/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4947 - accuracy: 0.8929\n",
      "Epoch 1531/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4946 - accuracy: 0.8929\n",
      "Epoch 1532/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4946 - accuracy: 0.8929\n",
      "Epoch 1533/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8929\n",
      "Epoch 1534/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8929\n",
      "Epoch 1535/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4945 - accuracy: 0.8929\n",
      "Epoch 1536/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8929\n",
      "Epoch 1537/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8929\n",
      "Epoch 1538/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4944 - accuracy: 0.8929\n",
      "Epoch 1539/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.8929\n",
      "Epoch 1540/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4943 - accuracy: 0.8929\n",
      "Epoch 1541/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8929\n",
      "Epoch 1542/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4942 - accuracy: 0.8929\n",
      "Epoch 1543/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4942 - accuracy: 0.8929\n",
      "Epoch 1544/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8929\n",
      "Epoch 1545/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4941 - accuracy: 0.8929\n",
      "Epoch 1546/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4940 - accuracy: 0.8929\n",
      "Epoch 1547/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8929\n",
      "Epoch 1548/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4940 - accuracy: 0.8929\n",
      "Epoch 1549/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8929\n",
      "Epoch 1550/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4939 - accuracy: 0.8929\n",
      "Epoch 1551/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8929\n",
      "Epoch 1552/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4938 - accuracy: 0.8929\n",
      "Epoch 1553/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4938 - accuracy: 0.8929\n",
      "Epoch 1554/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8929\n",
      "Epoch 1555/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8929\n",
      "Epoch 1556/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4937 - accuracy: 0.8929\n",
      "Epoch 1557/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8929\n",
      "Epoch 1558/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4936 - accuracy: 0.8929\n",
      "Epoch 1559/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8929\n",
      "Epoch 1560/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8929\n",
      "Epoch 1561/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.8929\n",
      "Epoch 1562/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8929\n",
      "Epoch 1563/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4934 - accuracy: 0.8929\n",
      "Epoch 1564/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8929\n",
      "Epoch 1565/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8929\n",
      "Epoch 1566/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4933 - accuracy: 0.8929\n",
      "Epoch 1567/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8929\n",
      "Epoch 1568/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4932 - accuracy: 0.8929\n",
      "Epoch 1569/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4932 - accuracy: 0.8929\n",
      "Epoch 1570/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8929\n",
      "Epoch 1571/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4931 - accuracy: 0.8929\n",
      "Epoch 1572/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8929\n",
      "Epoch 1573/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8929\n",
      "Epoch 1574/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4930 - accuracy: 0.8929\n",
      "Epoch 1575/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8929\n",
      "Epoch 1576/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4929 - accuracy: 0.8929\n",
      "Epoch 1577/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8929\n",
      "Epoch 1578/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8929\n",
      "Epoch 1579/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4928 - accuracy: 0.8929\n",
      "Epoch 1580/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8929\n",
      "Epoch 1581/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4927 - accuracy: 0.8929\n",
      "Epoch 1582/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4927 - accuracy: 0.8929\n",
      "Epoch 1583/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8929\n",
      "Epoch 1584/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.8929\n",
      "Epoch 1585/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8929\n",
      "Epoch 1586/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4925 - accuracy: 0.8929\n",
      "Epoch 1587/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4925 - accuracy: 0.8929\n",
      "Epoch 1588/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8929\n",
      "Epoch 1589/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4924 - accuracy: 0.8929\n",
      "Epoch 1590/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8929\n",
      "Epoch 1591/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4923 - accuracy: 0.8929\n",
      "Epoch 1592/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.8929\n",
      "Epoch 1593/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8929\n",
      "Epoch 1594/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8929\n",
      "Epoch 1595/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4922 - accuracy: 0.8929\n",
      "Epoch 1596/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4921 - accuracy: 0.8929\n",
      "Epoch 1597/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4921 - accuracy: 0.8929\n",
      "Epoch 1598/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8929\n",
      "Epoch 1599/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4920 - accuracy: 0.8929\n",
      "Epoch 1600/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4920 - accuracy: 0.8929\n",
      "Epoch 1601/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8929\n",
      "Epoch 1602/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8929\n",
      "Epoch 1603/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4919 - accuracy: 0.8929\n",
      "Epoch 1604/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8929\n",
      "Epoch 1605/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4918 - accuracy: 0.8929\n",
      "Epoch 1606/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8929\n",
      "Epoch 1607/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4917 - accuracy: 0.8929\n",
      "Epoch 1608/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4917 - accuracy: 0.8929\n",
      "Epoch 1609/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8929\n",
      "Epoch 1610/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4916 - accuracy: 0.8929\n",
      "Epoch 1611/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8929\n",
      "Epoch 1612/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8929\n",
      "Epoch 1613/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4915 - accuracy: 0.8929\n",
      "Epoch 1614/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8929\n",
      "Epoch 1615/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8929\n",
      "Epoch 1616/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4914 - accuracy: 0.8929\n",
      "Epoch 1617/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8929\n",
      "Epoch 1618/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4913 - accuracy: 0.8929\n",
      "Epoch 1619/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8929\n",
      "Epoch 1620/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8929\n",
      "Epoch 1621/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4912 - accuracy: 0.8929\n",
      "Epoch 1622/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8929\n",
      "Epoch 1623/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8929\n",
      "Epoch 1624/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4911 - accuracy: 0.8929\n",
      "Epoch 1625/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8929\n",
      "Epoch 1626/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4910 - accuracy: 0.8929\n",
      "Epoch 1627/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4909 - accuracy: 0.8929\n",
      "Epoch 1628/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8929\n",
      "Epoch 1629/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4909 - accuracy: 0.8929\n",
      "Epoch 1630/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8929\n",
      "Epoch 1631/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4908 - accuracy: 0.8929\n",
      "Epoch 1632/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8929\n",
      "Epoch 1633/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8929\n",
      "Epoch 1634/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8929\n",
      "Epoch 1635/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8929\n",
      "Epoch 1636/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4906 - accuracy: 0.8929\n",
      "Epoch 1637/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4906 - accuracy: 0.8929\n",
      "Epoch 1638/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8929\n",
      "Epoch 1639/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4905 - accuracy: 0.8929\n",
      "Epoch 1640/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8929\n",
      "Epoch 1641/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8929\n",
      "Epoch 1642/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4904 - accuracy: 0.8929\n",
      "Epoch 1643/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8929\n",
      "Epoch 1644/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8929\n",
      "Epoch 1645/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4903 - accuracy: 0.8929\n",
      "Epoch 1646/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8929\n",
      "Epoch 1647/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4902 - accuracy: 0.8929\n",
      "Epoch 1648/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8929\n",
      "Epoch 1649/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8929\n",
      "Epoch 1650/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4901 - accuracy: 0.8929\n",
      "Epoch 1651/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8929\n",
      "Epoch 1652/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8929\n",
      "Epoch 1653/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4900 - accuracy: 0.8929\n",
      "Epoch 1654/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8929\n",
      "Epoch 1655/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4899 - accuracy: 0.8929\n",
      "Epoch 1656/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8929\n",
      "Epoch 1657/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8929\n",
      "Epoch 1658/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4898 - accuracy: 0.8929\n",
      "Epoch 1659/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8929\n",
      "Epoch 1660/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4897 - accuracy: 0.8929\n",
      "Epoch 1661/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4897 - accuracy: 0.8929\n",
      "Epoch 1662/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8929\n",
      "Epoch 1663/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4896 - accuracy: 0.8929\n",
      "Epoch 1664/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8929\n",
      "Epoch 1665/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4895 - accuracy: 0.8929\n",
      "Epoch 1666/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4895 - accuracy: 0.8929\n",
      "Epoch 1667/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8929\n",
      "Epoch 1668/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8929\n",
      "Epoch 1669/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.8929\n",
      "Epoch 1670/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8929\n",
      "Epoch 1671/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4893 - accuracy: 0.8929\n",
      "Epoch 1672/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8929\n",
      "Epoch 1673/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4892 - accuracy: 0.8929\n",
      "Epoch 1674/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4892 - accuracy: 0.8929\n",
      "Epoch 1675/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8929\n",
      "Epoch 1676/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8929\n",
      "Epoch 1677/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4891 - accuracy: 0.8929\n",
      "Epoch 1678/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4890 - accuracy: 0.8929\n",
      "Epoch 1679/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4890 - accuracy: 0.8929\n",
      "Epoch 1680/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8929\n",
      "Epoch 1681/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4889 - accuracy: 0.8929\n",
      "Epoch 1682/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4889 - accuracy: 0.8929\n",
      "Epoch 1683/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 1684/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 1685/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4888 - accuracy: 0.8929\n",
      "Epoch 1686/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4887 - accuracy: 0.8929\n",
      "Epoch 1687/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.8929\n",
      "Epoch 1688/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8929\n",
      "Epoch 1689/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8929\n",
      "Epoch 1690/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4886 - accuracy: 0.8929\n",
      "Epoch 1691/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4885 - accuracy: 0.8929\n",
      "Epoch 1692/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8929\n",
      "Epoch 1693/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4885 - accuracy: 0.8929\n",
      "Epoch 1694/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8929\n",
      "Epoch 1695/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4884 - accuracy: 0.8929\n",
      "Epoch 1696/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8929\n",
      "Epoch 1697/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8929\n",
      "Epoch 1698/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4883 - accuracy: 0.8929\n",
      "Epoch 1699/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8929\n",
      "Epoch 1700/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8929\n",
      "Epoch 1701/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4882 - accuracy: 0.8929\n",
      "Epoch 1702/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8929\n",
      "Epoch 1703/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4881 - accuracy: 0.8929\n",
      "Epoch 1704/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8929\n",
      "Epoch 1705/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8929\n",
      "Epoch 1706/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4880 - accuracy: 0.8929\n",
      "Epoch 1707/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8929\n",
      "Epoch 1708/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8929\n",
      "Epoch 1709/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4879 - accuracy: 0.8929\n",
      "Epoch 1710/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8929\n",
      "Epoch 1711/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4878 - accuracy: 0.8929\n",
      "Epoch 1712/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8929\n",
      "Epoch 1713/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8929\n",
      "Epoch 1714/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4877 - accuracy: 0.8929\n",
      "Epoch 1715/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8929\n",
      "Epoch 1716/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8929\n",
      "Epoch 1717/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4876 - accuracy: 0.8929\n",
      "Epoch 1718/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8929\n",
      "Epoch 1719/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4875 - accuracy: 0.8929\n",
      "Epoch 1720/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4875 - accuracy: 0.8929\n",
      "Epoch 1721/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8929\n",
      "Epoch 1722/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4874 - accuracy: 0.8929\n",
      "Epoch 1723/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4873 - accuracy: 0.8929\n",
      "Epoch 1724/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8929\n",
      "Epoch 1725/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4873 - accuracy: 0.8929\n",
      "Epoch 1726/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8929\n",
      "Epoch 1727/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8929\n",
      "Epoch 1728/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4872 - accuracy: 0.8929\n",
      "Epoch 1729/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8929\n",
      "Epoch 1730/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4871 - accuracy: 0.8929\n",
      "Epoch 1731/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8929\n",
      "Epoch 1732/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4870 - accuracy: 0.8929\n",
      "Epoch 1733/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4870 - accuracy: 0.8929\n",
      "Epoch 1734/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8929\n",
      "Epoch 1735/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8929\n",
      "Epoch 1736/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4869 - accuracy: 0.8929\n",
      "Epoch 1737/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4868 - accuracy: 0.8929\n",
      "Epoch 1738/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4868 - accuracy: 0.8929\n",
      "Epoch 1739/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4868 - accuracy: 0.8929\n",
      "Epoch 1740/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4867 - accuracy: 0.8929\n",
      "Epoch 1741/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4867 - accuracy: 0.8929\n",
      "Epoch 1742/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8929\n",
      "Epoch 1743/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8929\n",
      "Epoch 1744/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4866 - accuracy: 0.8929\n",
      "Epoch 1745/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8929\n",
      "Epoch 1746/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4865 - accuracy: 0.8929\n",
      "Epoch 1747/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4865 - accuracy: 0.8929\n",
      "Epoch 1748/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8929\n",
      "Epoch 1749/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4864 - accuracy: 0.8929\n",
      "Epoch 1750/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8929\n",
      "Epoch 1751/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8929\n",
      "Epoch 1752/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4863 - accuracy: 0.8929\n",
      "Epoch 1753/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8929\n",
      "Epoch 1754/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8929\n",
      "Epoch 1755/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4862 - accuracy: 0.8929\n",
      "Epoch 1756/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8929\n",
      "Epoch 1757/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8929\n",
      "Epoch 1758/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4861 - accuracy: 0.8929\n",
      "Epoch 1759/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8929\n",
      "Epoch 1760/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4860 - accuracy: 0.8929\n",
      "Epoch 1761/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8929\n",
      "Epoch 1762/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8929\n",
      "Epoch 1763/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4859 - accuracy: 0.8929\n",
      "Epoch 1764/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4858 - accuracy: 0.8929\n",
      "Epoch 1765/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8929\n",
      "Epoch 1766/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4858 - accuracy: 0.8929\n",
      "Epoch 1767/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4857 - accuracy: 0.8929\n",
      "Epoch 1768/2500\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4857 - accuracy: 0.8929\n",
      "Epoch 1769/2500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4857 - accuracy: 0.8929\n",
      "Epoch 1770/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4856 - accuracy: 0.8929\n",
      "Epoch 1771/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4856 - accuracy: 0.8929\n",
      "Epoch 1772/2500\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 1773/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 1774/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4855 - accuracy: 0.8929\n",
      "Epoch 1775/2500\n",
      "1/1 [==============================] - 0s 8ms/step - loss: 0.4854 - accuracy: 0.8929\n",
      "Epoch 1776/2500\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.4854 - accuracy: 0.8929\n",
      "Epoch 1777/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4854 - accuracy: 0.8929\n",
      "Epoch 1778/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4853 - accuracy: 0.8929\n",
      "Epoch 1779/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4853 - accuracy: 0.8929\n",
      "Epoch 1780/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.8929\n",
      "Epoch 1781/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.8929\n",
      "Epoch 1782/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.8929\n",
      "Epoch 1783/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4851 - accuracy: 0.8929\n",
      "Epoch 1784/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4851 - accuracy: 0.8929\n",
      "Epoch 1785/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4851 - accuracy: 0.8929\n",
      "Epoch 1786/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8929\n",
      "Epoch 1787/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4850 - accuracy: 0.8929\n",
      "Epoch 1788/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4850 - accuracy: 0.8929\n",
      "Epoch 1789/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8929\n",
      "Epoch 1790/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4849 - accuracy: 0.8929\n",
      "Epoch 1791/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4849 - accuracy: 0.8929\n",
      "Epoch 1792/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4848 - accuracy: 0.8929\n",
      "Epoch 1793/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4848 - accuracy: 0.8929\n",
      "Epoch 1794/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8929\n",
      "Epoch 1795/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4847 - accuracy: 0.8929\n",
      "Epoch 1796/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8929\n",
      "Epoch 1797/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8929\n",
      "Epoch 1798/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.8929\n",
      "Epoch 1799/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4846 - accuracy: 0.8929\n",
      "Epoch 1800/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8929\n",
      "Epoch 1801/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8929\n",
      "Epoch 1802/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4845 - accuracy: 0.8929\n",
      "Epoch 1803/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8929\n",
      "Epoch 1804/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4844 - accuracy: 0.8929\n",
      "Epoch 1805/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8929\n",
      "Epoch 1806/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8929\n",
      "Epoch 1807/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4843 - accuracy: 0.8929\n",
      "Epoch 1808/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8929\n",
      "Epoch 1809/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8929\n",
      "Epoch 1810/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.8929\n",
      "Epoch 1811/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8929\n",
      "Epoch 1812/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8929\n",
      "Epoch 1813/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4841 - accuracy: 0.8929\n",
      "Epoch 1814/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4840 - accuracy: 0.8929\n",
      "Epoch 1815/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4840 - accuracy: 0.8929\n",
      "Epoch 1816/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8929\n",
      "Epoch 1817/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8929\n",
      "Epoch 1818/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4839 - accuracy: 0.8929\n",
      "Epoch 1819/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8929\n",
      "Epoch 1820/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8929\n",
      "Epoch 1821/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4838 - accuracy: 0.8929\n",
      "Epoch 1822/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8929\n",
      "Epoch 1823/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8929\n",
      "Epoch 1824/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4837 - accuracy: 0.8929\n",
      "Epoch 1825/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4836 - accuracy: 0.8929\n",
      "Epoch 1826/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4836 - accuracy: 0.8929\n",
      "Epoch 1827/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8929\n",
      "Epoch 1828/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8929\n",
      "Epoch 1829/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4835 - accuracy: 0.8929\n",
      "Epoch 1830/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8929\n",
      "Epoch 1831/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4834 - accuracy: 0.8929\n",
      "Epoch 1832/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4834 - accuracy: 0.8929\n",
      "Epoch 1833/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8929\n",
      "Epoch 1834/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8929\n",
      "Epoch 1835/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4833 - accuracy: 0.8929\n",
      "Epoch 1836/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8929\n",
      "Epoch 1837/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8929\n",
      "Epoch 1838/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4832 - accuracy: 0.8929\n",
      "Epoch 1839/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8929\n",
      "Epoch 1840/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4831 - accuracy: 0.8929\n",
      "Epoch 1841/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8929\n",
      "Epoch 1842/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4830 - accuracy: 0.8929\n",
      "Epoch 1843/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4830 - accuracy: 0.8929\n",
      "Epoch 1844/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8929\n",
      "Epoch 1845/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4829 - accuracy: 0.8929\n",
      "Epoch 1846/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4829 - accuracy: 0.8929\n",
      "Epoch 1847/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8929\n",
      "Epoch 1848/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4828 - accuracy: 0.8929\n",
      "Epoch 1849/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4828 - accuracy: 0.8929\n",
      "Epoch 1850/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8929\n",
      "Epoch 1851/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8929\n",
      "Epoch 1852/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4827 - accuracy: 0.8929\n",
      "Epoch 1853/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4826 - accuracy: 0.8929\n",
      "Epoch 1854/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4826 - accuracy: 0.8929\n",
      "Epoch 1855/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8929\n",
      "Epoch 1856/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8929\n",
      "Epoch 1857/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4825 - accuracy: 0.8929\n",
      "Epoch 1858/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8929\n",
      "Epoch 1859/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8929\n",
      "Epoch 1860/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4824 - accuracy: 0.8929\n",
      "Epoch 1861/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8929\n",
      "Epoch 1862/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8929\n",
      "Epoch 1863/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4823 - accuracy: 0.8929\n",
      "Epoch 1864/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 1865/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 1866/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4822 - accuracy: 0.8929\n",
      "Epoch 1867/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8929\n",
      "Epoch 1868/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4821 - accuracy: 0.8929\n",
      "Epoch 1869/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8929\n",
      "Epoch 1870/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4820 - accuracy: 0.8929\n",
      "Epoch 1871/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4820 - accuracy: 0.8929\n",
      "Epoch 1872/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8929\n",
      "Epoch 1873/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8929\n",
      "Epoch 1874/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4819 - accuracy: 0.8929\n",
      "Epoch 1875/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8929\n",
      "Epoch 1876/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8929\n",
      "Epoch 1877/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4818 - accuracy: 0.8929\n",
      "Epoch 1878/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8929\n",
      "Epoch 1879/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8929\n",
      "Epoch 1880/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4817 - accuracy: 0.8929\n",
      "Epoch 1881/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8929\n",
      "Epoch 1882/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8929\n",
      "Epoch 1883/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4816 - accuracy: 0.8929\n",
      "Epoch 1884/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8929\n",
      "Epoch 1885/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.8929\n",
      "Epoch 1886/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4814 - accuracy: 0.8929\n",
      "Epoch 1887/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4814 - accuracy: 0.8929\n",
      "Epoch 1888/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.8929\n",
      "Epoch 1889/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4813 - accuracy: 0.8929\n",
      "Epoch 1890/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4813 - accuracy: 0.8929\n",
      "Epoch 1891/2500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4813 - accuracy: 0.8929\n",
      "Epoch 1892/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4812 - accuracy: 0.8929\n",
      "Epoch 1893/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4812 - accuracy: 0.8929\n",
      "Epoch 1894/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4812 - accuracy: 0.8929\n",
      "Epoch 1895/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8929\n",
      "Epoch 1896/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8929\n",
      "Epoch 1897/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4811 - accuracy: 0.8929\n",
      "Epoch 1898/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8929\n",
      "Epoch 1899/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4810 - accuracy: 0.8929\n",
      "Epoch 1900/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8929\n",
      "Epoch 1901/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8929\n",
      "Epoch 1902/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8929\n",
      "Epoch 1903/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8929\n",
      "Epoch 1904/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4808 - accuracy: 0.8929\n",
      "Epoch 1905/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4808 - accuracy: 0.8929\n",
      "Epoch 1906/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4807 - accuracy: 0.8929\n",
      "Epoch 1907/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4807 - accuracy: 0.8929\n",
      "Epoch 1908/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4807 - accuracy: 0.8929\n",
      "Epoch 1909/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8929\n",
      "Epoch 1910/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4806 - accuracy: 0.8929\n",
      "Epoch 1911/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4806 - accuracy: 0.8929\n",
      "Epoch 1912/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4805 - accuracy: 0.8929\n",
      "Epoch 1913/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4805 - accuracy: 0.8929\n",
      "Epoch 1914/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4805 - accuracy: 0.8929\n",
      "Epoch 1915/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4804 - accuracy: 0.8929\n",
      "Epoch 1916/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4804 - accuracy: 0.8929\n",
      "Epoch 1917/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4804 - accuracy: 0.8929\n",
      "Epoch 1918/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4803 - accuracy: 0.8929\n",
      "Epoch 1919/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4803 - accuracy: 0.8929\n",
      "Epoch 1920/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8929\n",
      "Epoch 1921/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4802 - accuracy: 0.8929\n",
      "Epoch 1922/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4802 - accuracy: 0.8929\n",
      "Epoch 1923/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8929\n",
      "Epoch 1924/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4801 - accuracy: 0.8929\n",
      "Epoch 1925/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4801 - accuracy: 0.8929\n",
      "Epoch 1926/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8929\n",
      "Epoch 1927/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8929\n",
      "Epoch 1928/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4800 - accuracy: 0.8929\n",
      "Epoch 1929/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8929\n",
      "Epoch 1930/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8929\n",
      "Epoch 1931/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4799 - accuracy: 0.8929\n",
      "Epoch 1932/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8929\n",
      "Epoch 1933/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4798 - accuracy: 0.8929\n",
      "Epoch 1934/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4798 - accuracy: 0.8929\n",
      "Epoch 1935/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8929\n",
      "Epoch 1936/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8929\n",
      "Epoch 1937/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4797 - accuracy: 0.8929\n",
      "Epoch 1938/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4796 - accuracy: 0.8929\n",
      "Epoch 1939/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4796 - accuracy: 0.8929\n",
      "Epoch 1940/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8929\n",
      "Epoch 1941/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4795 - accuracy: 0.8929\n",
      "Epoch 1942/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4795 - accuracy: 0.8929\n",
      "Epoch 1943/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8929\n",
      "Epoch 1944/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4794 - accuracy: 0.8929\n",
      "Epoch 1945/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.8929\n",
      "Epoch 1946/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8929\n",
      "Epoch 1947/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4793 - accuracy: 0.8929\n",
      "Epoch 1948/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4793 - accuracy: 0.8929\n",
      "Epoch 1949/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8929\n",
      "Epoch 1950/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8929\n",
      "Epoch 1951/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4792 - accuracy: 0.8929\n",
      "Epoch 1952/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8929\n",
      "Epoch 1953/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8929\n",
      "Epoch 1954/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4791 - accuracy: 0.8929\n",
      "Epoch 1955/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 1956/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 1957/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4790 - accuracy: 0.8929\n",
      "Epoch 1958/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8929\n",
      "Epoch 1959/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8929\n",
      "Epoch 1960/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4789 - accuracy: 0.8929\n",
      "Epoch 1961/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4788 - accuracy: 0.8929\n",
      "Epoch 1962/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4788 - accuracy: 0.8929\n",
      "Epoch 1963/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8929\n",
      "Epoch 1964/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8929\n",
      "Epoch 1965/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4787 - accuracy: 0.8929\n",
      "Epoch 1966/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8929\n",
      "Epoch 1967/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8929\n",
      "Epoch 1968/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4786 - accuracy: 0.8929\n",
      "Epoch 1969/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8929\n",
      "Epoch 1970/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8929\n",
      "Epoch 1971/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4785 - accuracy: 0.8929\n",
      "Epoch 1972/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8929\n",
      "Epoch 1973/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4784 - accuracy: 0.8929\n",
      "Epoch 1974/2500\n",
      "1/1 [==============================] - 0s 994us/step - loss: 0.4784 - accuracy: 0.8929\n",
      "Epoch 1975/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4783 - accuracy: 0.8929\n",
      "Epoch 1976/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8929\n",
      "Epoch 1977/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.8929\n",
      "Epoch 1978/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4782 - accuracy: 0.8929\n",
      "Epoch 1979/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4782 - accuracy: 0.8929\n",
      "Epoch 1980/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4782 - accuracy: 0.8929\n",
      "Epoch 1981/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4781 - accuracy: 0.8929\n",
      "Epoch 1982/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8929\n",
      "Epoch 1983/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4781 - accuracy: 0.8929\n",
      "Epoch 1984/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4780 - accuracy: 0.8929\n",
      "Epoch 1985/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8929\n",
      "Epoch 1986/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4780 - accuracy: 0.8929\n",
      "Epoch 1987/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8929\n",
      "Epoch 1988/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4779 - accuracy: 0.8929\n",
      "Epoch 1989/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8929\n",
      "Epoch 1990/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8929\n",
      "Epoch 1991/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4778 - accuracy: 0.8929\n",
      "Epoch 1992/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8929\n",
      "Epoch 1993/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8929\n",
      "Epoch 1994/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4777 - accuracy: 0.8929\n",
      "Epoch 1995/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8929\n",
      "Epoch 1996/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8929\n",
      "Epoch 1997/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4776 - accuracy: 0.8929\n",
      "Epoch 1998/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "Epoch 1999/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "Epoch 2000/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4775 - accuracy: 0.8929\n",
      "Epoch 2001/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8929\n",
      "Epoch 2002/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8929\n",
      "Epoch 2003/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4774 - accuracy: 0.8929\n",
      "Epoch 2004/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8929\n",
      "Epoch 2005/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8929\n",
      "Epoch 2006/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4773 - accuracy: 0.8929\n",
      "Epoch 2007/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8929\n",
      "Epoch 2008/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4772 - accuracy: 0.8929\n",
      "Epoch 2009/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4772 - accuracy: 0.8929\n",
      "Epoch 2010/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4771 - accuracy: 0.8929\n",
      "Epoch 2011/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4771 - accuracy: 0.8929\n",
      "Epoch 2012/2500\n",
      "1/1 [==============================] - 0s 977us/step - loss: 0.4771 - accuracy: 0.8929\n",
      "Epoch 2013/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8929\n",
      "Epoch 2014/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8929\n",
      "Epoch 2015/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4770 - accuracy: 0.8929\n",
      "Epoch 2016/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4769 - accuracy: 0.8929\n",
      "Epoch 2017/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8929\n",
      "Epoch 2018/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4769 - accuracy: 0.8929\n",
      "Epoch 2019/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8929\n",
      "Epoch 2020/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8929\n",
      "Epoch 2021/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4768 - accuracy: 0.8929\n",
      "Epoch 2022/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4767 - accuracy: 0.8929\n",
      "Epoch 2023/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4767 - accuracy: 0.8929\n",
      "Epoch 2024/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8929\n",
      "Epoch 2025/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8929\n",
      "Epoch 2026/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4766 - accuracy: 0.8929\n",
      "Epoch 2027/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8929\n",
      "Epoch 2028/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8929\n",
      "Epoch 2029/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4765 - accuracy: 0.8929\n",
      "Epoch 2030/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8929\n",
      "Epoch 2031/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8929\n",
      "Epoch 2032/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4764 - accuracy: 0.8929\n",
      "Epoch 2033/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8929\n",
      "Epoch 2034/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4763 - accuracy: 0.8929\n",
      "Epoch 2035/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4763 - accuracy: 0.8929\n",
      "Epoch 2036/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8929\n",
      "Epoch 2037/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8929\n",
      "Epoch 2038/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4762 - accuracy: 0.8929\n",
      "Epoch 2039/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8929\n",
      "Epoch 2040/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8929\n",
      "Epoch 2041/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4761 - accuracy: 0.8929\n",
      "Epoch 2042/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8929\n",
      "Epoch 2043/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8929\n",
      "Epoch 2044/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4760 - accuracy: 0.8929\n",
      "Epoch 2045/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 2046/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 2047/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.8929\n",
      "Epoch 2048/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8929\n",
      "Epoch 2049/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8929\n",
      "Epoch 2050/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4758 - accuracy: 0.8929\n",
      "Epoch 2051/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8929\n",
      "Epoch 2052/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8929\n",
      "Epoch 2053/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4757 - accuracy: 0.8929\n",
      "Epoch 2054/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8929\n",
      "Epoch 2055/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8929\n",
      "Epoch 2056/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.8929\n",
      "Epoch 2057/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4755 - accuracy: 0.8929\n",
      "Epoch 2058/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8929\n",
      "Epoch 2059/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4755 - accuracy: 0.8929\n",
      "Epoch 2060/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8929\n",
      "Epoch 2061/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4754 - accuracy: 0.8929\n",
      "Epoch 2062/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4754 - accuracy: 0.8929\n",
      "Epoch 2063/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8929\n",
      "Epoch 2064/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8929\n",
      "Epoch 2065/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4753 - accuracy: 0.8929\n",
      "Epoch 2066/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8929\n",
      "Epoch 2067/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8929\n",
      "Epoch 2068/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8929\n",
      "Epoch 2069/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8929\n",
      "Epoch 2070/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8929\n",
      "Epoch 2071/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4751 - accuracy: 0.8929\n",
      "Epoch 2072/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8929\n",
      "Epoch 2073/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8929\n",
      "Epoch 2074/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4750 - accuracy: 0.8929\n",
      "Epoch 2075/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4749 - accuracy: 0.8929\n",
      "Epoch 2076/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8929\n",
      "Epoch 2077/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4749 - accuracy: 0.8929\n",
      "Epoch 2078/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8929\n",
      "Epoch 2079/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8929\n",
      "Epoch 2080/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4748 - accuracy: 0.8929\n",
      "Epoch 2081/2500\n",
      "1/1 [==============================] - 0s 958us/step - loss: 0.4747 - accuracy: 0.8929\n",
      "Epoch 2082/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8929\n",
      "Epoch 2083/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4747 - accuracy: 0.8929\n",
      "Epoch 2084/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8929\n",
      "Epoch 2085/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4746 - accuracy: 0.8929\n",
      "Epoch 2086/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4746 - accuracy: 0.8929\n",
      "Epoch 2087/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8929\n",
      "Epoch 2088/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4745 - accuracy: 0.8929\n",
      "Epoch 2089/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8929\n",
      "Epoch 2090/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4744 - accuracy: 0.8929\n",
      "Epoch 2091/2500\n",
      "1/1 [==============================] - 0s 997us/step - loss: 0.4744 - accuracy: 0.8929\n",
      "Epoch 2092/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4743 - accuracy: 0.8929\n",
      "Epoch 2093/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8929\n",
      "Epoch 2094/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4743 - accuracy: 0.8929\n",
      "Epoch 2095/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8929\n",
      "Epoch 2096/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8929\n",
      "Epoch 2097/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4742 - accuracy: 0.8929\n",
      "Epoch 2098/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8929\n",
      "Epoch 2099/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8929\n",
      "Epoch 2100/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4741 - accuracy: 0.8929\n",
      "Epoch 2101/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8929\n",
      "Epoch 2102/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4740 - accuracy: 0.8929\n",
      "Epoch 2103/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4740 - accuracy: 0.8929\n",
      "Epoch 2104/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8929\n",
      "Epoch 2105/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8929\n",
      "Epoch 2106/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4739 - accuracy: 0.8929\n",
      "Epoch 2107/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4738 - accuracy: 0.8929\n",
      "Epoch 2108/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4738 - accuracy: 0.8929\n",
      "Epoch 2109/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4738 - accuracy: 0.8929\n",
      "Epoch 2110/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8929\n",
      "Epoch 2111/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8929\n",
      "Epoch 2112/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4737 - accuracy: 0.8929\n",
      "Epoch 2113/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8929\n",
      "Epoch 2114/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8929\n",
      "Epoch 2115/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4736 - accuracy: 0.8929\n",
      "Epoch 2116/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8929\n",
      "Epoch 2117/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8929\n",
      "Epoch 2118/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4735 - accuracy: 0.8929\n",
      "Epoch 2119/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4734 - accuracy: 0.8929\n",
      "Epoch 2120/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4734 - accuracy: 0.8929\n",
      "Epoch 2121/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4734 - accuracy: 0.8929\n",
      "Epoch 2122/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4733 - accuracy: 0.8929\n",
      "Epoch 2123/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8929\n",
      "Epoch 2124/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4733 - accuracy: 0.8929\n",
      "Epoch 2125/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8929\n",
      "Epoch 2126/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8929\n",
      "Epoch 2127/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4732 - accuracy: 0.8929\n",
      "Epoch 2128/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4731 - accuracy: 0.8929\n",
      "Epoch 2129/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4731 - accuracy: 0.8929\n",
      "Epoch 2130/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4731 - accuracy: 0.8929\n",
      "Epoch 2131/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8929\n",
      "Epoch 2132/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8929\n",
      "Epoch 2133/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4730 - accuracy: 0.8929\n",
      "Epoch 2134/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2135/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2136/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2137/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4729 - accuracy: 0.8929\n",
      "Epoch 2138/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8929\n",
      "Epoch 2139/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8929\n",
      "Epoch 2140/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4728 - accuracy: 0.8929\n",
      "Epoch 2141/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 2142/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 2143/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4727 - accuracy: 0.8929\n",
      "Epoch 2144/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8929\n",
      "Epoch 2145/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4726 - accuracy: 0.8929\n",
      "Epoch 2146/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4726 - accuracy: 0.8929\n",
      "Epoch 2147/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4725 - accuracy: 0.8929\n",
      "Epoch 2148/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4725 - accuracy: 0.8929\n",
      "Epoch 2149/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8929\n",
      "Epoch 2150/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8929\n",
      "Epoch 2151/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8929\n",
      "Epoch 2152/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4724 - accuracy: 0.8929\n",
      "Epoch 2153/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8929\n",
      "Epoch 2154/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8929\n",
      "Epoch 2155/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4723 - accuracy: 0.8929\n",
      "Epoch 2156/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4722 - accuracy: 0.8929\n",
      "Epoch 2157/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8929\n",
      "Epoch 2158/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.8929\n",
      "Epoch 2159/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8929\n",
      "Epoch 2160/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8929\n",
      "Epoch 2161/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4721 - accuracy: 0.8929\n",
      "Epoch 2162/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4720 - accuracy: 0.8929\n",
      "Epoch 2163/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8929\n",
      "Epoch 2164/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4720 - accuracy: 0.8929\n",
      "Epoch 2165/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8929\n",
      "Epoch 2166/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8929\n",
      "Epoch 2167/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4719 - accuracy: 0.8929\n",
      "Epoch 2168/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8929\n",
      "Epoch 2169/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8929\n",
      "Epoch 2170/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4718 - accuracy: 0.8929\n",
      "Epoch 2171/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4717 - accuracy: 0.8929\n",
      "Epoch 2172/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4717 - accuracy: 0.8929\n",
      "Epoch 2173/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4717 - accuracy: 0.8929\n",
      "Epoch 2174/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8929\n",
      "Epoch 2175/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4716 - accuracy: 0.8929\n",
      "Epoch 2176/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4716 - accuracy: 0.8929\n",
      "Epoch 2177/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4715 - accuracy: 0.8929\n",
      "Epoch 2178/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4715 - accuracy: 0.8929\n",
      "Epoch 2179/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4715 - accuracy: 0.8929\n",
      "Epoch 2180/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.8929\n",
      "Epoch 2181/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4714 - accuracy: 0.8929\n",
      "Epoch 2182/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4714 - accuracy: 0.8929\n",
      "Epoch 2183/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4713 - accuracy: 0.8929\n",
      "Epoch 2184/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4713 - accuracy: 0.8929\n",
      "Epoch 2185/2500\n",
      "1/1 [==============================] - 0s 7ms/step - loss: 0.4713 - accuracy: 0.8929\n",
      "Epoch 2186/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.8929\n",
      "Epoch 2187/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8929\n",
      "Epoch 2188/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.8929\n",
      "Epoch 2189/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.8929\n",
      "Epoch 2190/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4711 - accuracy: 0.8929\n",
      "Epoch 2191/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4711 - accuracy: 0.8929\n",
      "Epoch 2192/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4710 - accuracy: 0.8929\n",
      "Epoch 2193/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4710 - accuracy: 0.8929\n",
      "Epoch 2194/2500\n",
      "1/1 [==============================] - 0s 6ms/step - loss: 0.4710 - accuracy: 0.8929\n",
      "Epoch 2195/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4709 - accuracy: 0.8929\n",
      "Epoch 2196/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4709 - accuracy: 0.8929\n",
      "Epoch 2197/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4709 - accuracy: 0.8929\n",
      "Epoch 2198/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8929\n",
      "Epoch 2199/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.8929\n",
      "Epoch 2200/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4708 - accuracy: 0.8929\n",
      "Epoch 2201/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2202/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2203/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2204/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4707 - accuracy: 0.8929\n",
      "Epoch 2205/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4706 - accuracy: 0.8929\n",
      "Epoch 2206/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4706 - accuracy: 0.8929\n",
      "Epoch 2207/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4706 - accuracy: 0.8929\n",
      "Epoch 2208/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8929\n",
      "Epoch 2209/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8929\n",
      "Epoch 2210/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4705 - accuracy: 0.8929\n",
      "Epoch 2211/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8929\n",
      "Epoch 2212/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8929\n",
      "Epoch 2213/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.8929\n",
      "Epoch 2214/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8929\n",
      "Epoch 2215/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8929\n",
      "Epoch 2216/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4703 - accuracy: 0.8929\n",
      "Epoch 2217/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8929\n",
      "Epoch 2218/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4702 - accuracy: 0.8929\n",
      "Epoch 2219/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4702 - accuracy: 0.8929\n",
      "Epoch 2220/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8929\n",
      "Epoch 2221/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4701 - accuracy: 0.8929\n",
      "Epoch 2222/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4701 - accuracy: 0.8929\n",
      "Epoch 2223/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8929\n",
      "Epoch 2224/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8929\n",
      "Epoch 2225/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8929\n",
      "Epoch 2226/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8929\n",
      "Epoch 2227/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8929\n",
      "Epoch 2228/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4699 - accuracy: 0.8929\n",
      "Epoch 2229/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8929\n",
      "Epoch 2230/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8929\n",
      "Epoch 2231/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4698 - accuracy: 0.8929\n",
      "Epoch 2232/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8929\n",
      "Epoch 2233/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8929\n",
      "Epoch 2234/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4697 - accuracy: 0.8929\n",
      "Epoch 2235/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2236/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2237/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2238/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4696 - accuracy: 0.8929\n",
      "Epoch 2239/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4695 - accuracy: 0.8929\n",
      "Epoch 2240/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4695 - accuracy: 0.8929\n",
      "Epoch 2241/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4695 - accuracy: 0.8929\n",
      "Epoch 2242/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4694 - accuracy: 0.8929\n",
      "Epoch 2243/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8929\n",
      "Epoch 2244/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4694 - accuracy: 0.8929\n",
      "Epoch 2245/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8929\n",
      "Epoch 2246/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4693 - accuracy: 0.8929\n",
      "Epoch 2247/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4693 - accuracy: 0.8929\n",
      "Epoch 2248/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4692 - accuracy: 0.8929\n",
      "Epoch 2249/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8929\n",
      "Epoch 2250/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4692 - accuracy: 0.8929\n",
      "Epoch 2251/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4691 - accuracy: 0.8929\n",
      "Epoch 2252/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4691 - accuracy: 0.8929\n",
      "Epoch 2253/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4691 - accuracy: 0.8929\n",
      "Epoch 2254/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4690 - accuracy: 0.8929\n",
      "Epoch 2255/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8929\n",
      "Epoch 2256/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4690 - accuracy: 0.8929\n",
      "Epoch 2257/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8929\n",
      "Epoch 2258/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8929\n",
      "Epoch 2259/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4689 - accuracy: 0.8929\n",
      "Epoch 2260/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8929\n",
      "Epoch 2261/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8929\n",
      "Epoch 2262/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4688 - accuracy: 0.8929\n",
      "Epoch 2263/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2264/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2265/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2266/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4687 - accuracy: 0.8929\n",
      "Epoch 2267/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8929\n",
      "Epoch 2268/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8929\n",
      "Epoch 2269/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.8929\n",
      "Epoch 2270/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8929\n",
      "Epoch 2271/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.8929\n",
      "Epoch 2272/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4685 - accuracy: 0.9286\n",
      "Epoch 2273/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.9286\n",
      "Epoch 2274/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4684 - accuracy: 0.9286\n",
      "Epoch 2275/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4684 - accuracy: 0.9286\n",
      "Epoch 2276/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.9286\n",
      "Epoch 2277/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4683 - accuracy: 0.9286\n",
      "Epoch 2278/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4683 - accuracy: 0.9286\n",
      "Epoch 2279/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9286\n",
      "Epoch 2280/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9286\n",
      "Epoch 2281/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4682 - accuracy: 0.9286\n",
      "Epoch 2282/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4681 - accuracy: 0.9286\n",
      "Epoch 2283/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4681 - accuracy: 0.9286\n",
      "Epoch 2284/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4681 - accuracy: 0.9286\n",
      "Epoch 2285/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2286/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2287/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2288/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4680 - accuracy: 0.9286\n",
      "Epoch 2289/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9286\n",
      "Epoch 2290/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9286\n",
      "Epoch 2291/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.9286\n",
      "Epoch 2292/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.9286\n",
      "Epoch 2293/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.9286\n",
      "Epoch 2294/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.9286\n",
      "Epoch 2295/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.9286\n",
      "Epoch 2296/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.9286\n",
      "Epoch 2297/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4677 - accuracy: 0.9286\n",
      "Epoch 2298/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.9286\n",
      "Epoch 2299/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.9286\n",
      "Epoch 2300/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.9286\n",
      "Epoch 2301/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.9286\n",
      "Epoch 2302/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.9286\n",
      "Epoch 2303/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4675 - accuracy: 0.9286\n",
      "Epoch 2304/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.9286\n",
      "Epoch 2305/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.9286\n",
      "Epoch 2306/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4674 - accuracy: 0.9286\n",
      "Epoch 2307/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2308/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2309/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2310/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4673 - accuracy: 0.9286\n",
      "Epoch 2311/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.9286\n",
      "Epoch 2312/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.9286\n",
      "Epoch 2313/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4672 - accuracy: 0.9286\n",
      "Epoch 2314/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.9286\n",
      "Epoch 2315/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.9286\n",
      "Epoch 2316/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4671 - accuracy: 0.9286\n",
      "Epoch 2317/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4670 - accuracy: 0.9286\n",
      "Epoch 2318/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.9286\n",
      "Epoch 2319/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4670 - accuracy: 0.9286\n",
      "Epoch 2320/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9286\n",
      "Epoch 2321/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9286\n",
      "Epoch 2322/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4669 - accuracy: 0.9286\n",
      "Epoch 2323/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.9286\n",
      "Epoch 2324/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9286\n",
      "Epoch 2325/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.9286\n",
      "Epoch 2326/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2327/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2328/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2329/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4667 - accuracy: 0.9286\n",
      "Epoch 2330/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4666 - accuracy: 0.9286\n",
      "Epoch 2331/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9286\n",
      "Epoch 2332/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4666 - accuracy: 0.9286\n",
      "Epoch 2333/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.9286\n",
      "Epoch 2334/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4665 - accuracy: 0.9286\n",
      "Epoch 2335/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4665 - accuracy: 0.9286\n",
      "Epoch 2336/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9286\n",
      "Epoch 2337/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4664 - accuracy: 0.9286\n",
      "Epoch 2338/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.9286\n",
      "Epoch 2339/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9286\n",
      "Epoch 2340/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9286\n",
      "Epoch 2341/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4663 - accuracy: 0.9286\n",
      "Epoch 2342/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2343/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2344/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2345/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4662 - accuracy: 0.9286\n",
      "Epoch 2346/2500\n",
      "1/1 [==============================] - 0s 5ms/step - loss: 0.4661 - accuracy: 0.9286\n",
      "Epoch 2347/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9286\n",
      "Epoch 2348/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4661 - accuracy: 0.9286\n",
      "Epoch 2349/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9286\n",
      "Epoch 2350/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.9286\n",
      "Epoch 2351/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4660 - accuracy: 0.9286\n",
      "Epoch 2352/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9286\n",
      "Epoch 2353/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4659 - accuracy: 0.9286\n",
      "Epoch 2354/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.9286\n",
      "Epoch 2355/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.9286\n",
      "Epoch 2356/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9286\n",
      "Epoch 2357/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.9286\n",
      "Epoch 2358/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2359/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2360/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2361/2500\n",
      "1/1 [==============================] - 0s 4ms/step - loss: 0.4657 - accuracy: 0.9286\n",
      "Epoch 2362/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9286\n",
      "Epoch 2363/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9286\n",
      "Epoch 2364/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4656 - accuracy: 0.9286\n",
      "Epoch 2365/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9286\n",
      "Epoch 2366/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9286\n",
      "Epoch 2367/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4655 - accuracy: 0.9286\n",
      "Epoch 2368/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9286\n",
      "Epoch 2369/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4654 - accuracy: 0.9286\n",
      "Epoch 2370/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4654 - accuracy: 0.9286\n",
      "Epoch 2371/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4653 - accuracy: 0.9286\n",
      "Epoch 2372/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9286\n",
      "Epoch 2373/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.9286\n",
      "Epoch 2374/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2375/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2376/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2377/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4652 - accuracy: 0.9286\n",
      "Epoch 2378/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4651 - accuracy: 0.9286\n",
      "Epoch 2379/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9286\n",
      "Epoch 2380/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4651 - accuracy: 0.9286\n",
      "Epoch 2381/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9286\n",
      "Epoch 2382/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9286\n",
      "Epoch 2383/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4650 - accuracy: 0.9286\n",
      "Epoch 2384/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9286\n",
      "Epoch 2385/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9286\n",
      "Epoch 2386/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4649 - accuracy: 0.9286\n",
      "Epoch 2387/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2388/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2389/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2390/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4648 - accuracy: 0.9286\n",
      "Epoch 2391/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9286\n",
      "Epoch 2392/2500\n",
      "1/1 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.9286\n",
      "Epoch 2393/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4647 - accuracy: 0.9286\n",
      "Epoch 2394/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4646 - accuracy: 0.9286\n",
      "Epoch 2395/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9286\n",
      "Epoch 2396/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4646 - accuracy: 0.9286\n",
      "Epoch 2397/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9286\n",
      "Epoch 2398/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9286\n",
      "Epoch 2399/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4645 - accuracy: 0.9286\n",
      "Epoch 2400/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.9286\n",
      "Epoch 2401/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4644 - accuracy: 0.9286\n",
      "Epoch 2402/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4644 - accuracy: 0.9286\n",
      "Epoch 2403/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2404/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2405/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2406/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4643 - accuracy: 0.9286\n",
      "Epoch 2407/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4642 - accuracy: 0.9286\n",
      "Epoch 2408/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.9286\n",
      "Epoch 2409/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4642 - accuracy: 0.9286\n",
      "Epoch 2410/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4641 - accuracy: 0.9286\n",
      "Epoch 2411/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9286\n",
      "Epoch 2412/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4641 - accuracy: 0.9286\n",
      "Epoch 2413/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9286\n",
      "Epoch 2414/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9286\n",
      "Epoch 2415/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4640 - accuracy: 0.9286\n",
      "Epoch 2416/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2417/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2418/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2419/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4639 - accuracy: 0.9286\n",
      "Epoch 2420/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9286\n",
      "Epoch 2421/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4638 - accuracy: 0.9286\n",
      "Epoch 2422/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4638 - accuracy: 0.9286\n",
      "Epoch 2423/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4637 - accuracy: 0.9286\n",
      "Epoch 2424/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9286\n",
      "Epoch 2425/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4637 - accuracy: 0.9286\n",
      "Epoch 2426/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9286\n",
      "Epoch 2427/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9286\n",
      "Epoch 2428/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4636 - accuracy: 0.9286\n",
      "Epoch 2429/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2430/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2431/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2432/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.9286\n",
      "Epoch 2433/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9286\n",
      "Epoch 2434/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9286\n",
      "Epoch 2435/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4634 - accuracy: 0.9286\n",
      "Epoch 2436/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4633 - accuracy: 0.9286\n",
      "Epoch 2437/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.9286\n",
      "Epoch 2438/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4633 - accuracy: 0.9286\n",
      "Epoch 2439/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2440/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2441/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2442/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4632 - accuracy: 0.9286\n",
      "Epoch 2443/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9286\n",
      "Epoch 2444/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9286\n",
      "Epoch 2445/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4631 - accuracy: 0.9286\n",
      "Epoch 2446/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.9286\n",
      "Epoch 2447/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.9286\n",
      "Epoch 2448/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4630 - accuracy: 0.9286\n",
      "Epoch 2449/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.9286\n",
      "Epoch 2450/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4629 - accuracy: 0.9286\n",
      "Epoch 2451/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.9286\n",
      "Epoch 2452/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2453/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2454/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2455/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4628 - accuracy: 0.9286\n",
      "Epoch 2456/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.9286\n",
      "Epoch 2457/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.9286\n",
      "Epoch 2458/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4627 - accuracy: 0.9286\n",
      "Epoch 2459/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.9286\n",
      "Epoch 2460/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.9286\n",
      "Epoch 2461/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4626 - accuracy: 0.9286\n",
      "Epoch 2462/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2463/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2464/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2465/2500\n",
      "1/1 [==============================] - 0s 999us/step - loss: 0.4625 - accuracy: 0.9286\n",
      "Epoch 2466/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.9286\n",
      "Epoch 2467/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4624 - accuracy: 0.9286\n",
      "Epoch 2468/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4624 - accuracy: 0.9286\n",
      "Epoch 2469/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.9286\n",
      "Epoch 2470/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.9286\n",
      "Epoch 2471/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4623 - accuracy: 0.9286\n",
      "Epoch 2472/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.9286\n",
      "Epoch 2473/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.9286\n",
      "Epoch 2474/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4622 - accuracy: 0.9286\n",
      "Epoch 2475/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2476/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2477/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2478/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4621 - accuracy: 0.9286\n",
      "Epoch 2479/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.9286\n",
      "Epoch 2480/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4620 - accuracy: 0.9286\n",
      "Epoch 2481/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4620 - accuracy: 0.9286\n",
      "Epoch 2482/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.9286\n",
      "Epoch 2483/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.9286\n",
      "Epoch 2484/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4619 - accuracy: 0.9286\n",
      "Epoch 2485/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2486/2500\n",
      "1/1 [==============================] - 0s 1000us/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2487/2500\n",
      "1/1 [==============================] - 0s 1ms/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2488/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.9286\n",
      "Epoch 2489/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4617 - accuracy: 0.9286\n",
      "Epoch 2490/2500\n",
      "1/1 [==============================] - 0s 998us/step - loss: 0.4617 - accuracy: 0.9286\n",
      "Epoch 2491/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4617 - accuracy: 0.9286\n",
      "Epoch 2492/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.9286\n",
      "Epoch 2493/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.9286\n",
      "Epoch 2494/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4616 - accuracy: 0.9286\n",
      "Epoch 2495/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2496/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2497/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2498/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4615 - accuracy: 0.9286\n",
      "Epoch 2499/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.9286\n",
      "Epoch 2500/2500\n",
      "1/1 [==============================] - 0s 2ms/step - loss: 0.4614 - accuracy: 0.9286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a62b5df8b0>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X.to_numpy(), y.to_numpy(), epochs=2500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aaf32f-9ff8-4895-9ad2-4da5be51e174",
   "metadata": {},
   "source": [
    "Nach dem Training (anpassen der w's und b's) haben sich die Gewichte verändert. <br>\n",
    "Das Model kann alle Weights ausgeben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e270eb7-0c3c-4095-8d52-a9f4f2c857e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[4.2917147],\n",
       "        [1.2697676]], dtype=float32),\n",
       " array([-2.4975893], dtype=float32)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('L1a2').get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e67d7150-2c7c-4d11-9caa-53fbe612f61b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.2917147],\n",
       "       [1.2697676]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef, b = model.get_layer('L1a2').get_weights()\n",
    "coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "db8a0fa8-a654-47ad-9cec-5a18d534ba3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 70ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54037255]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict([ [0.22, 1] ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b86c517c-5763-4973-8597-32dbd86bf239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aktivierungsfunktion. \n",
    "def sidmoid(x):\n",
    "    return 1 / (1 + math.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca563b77-d164-42df-8463-8efb0157333d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5403725601709111"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mit den gebenen Weights:\n",
    "res = 1.749332 * 0.22 + 0.76867884 * 1 + (-0.9916893)\n",
    "sidmoid(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "443ad71e-6682-4053-9cf2-1ed7091a836c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ True]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(model.predict([ [0.22, 1] ])) == sidmoid(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a885bd-fbde-454d-90b6-4adbf85a79a2",
   "metadata": {},
   "source": [
    "Man sieht deutlich, dass die Ergebnisse gleich sind. <br>\n",
    "Bei internen Unterschieden kann es vorkommen, dass sich das Ergebnis minimal unterscheidet."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d160e3-c918-4e1d-9596-6690e3a0ed7a",
   "metadata": {},
   "source": [
    "<h2>Python-NN</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83342153-faa6-4a0c-a31c-898d550903d6",
   "metadata": {},
   "source": [
    "Mit diesem Wissen und zusätzlich mit dem Gradientenabstieg kann einfach ein neurales Netz in Python programmiert werden.\n",
    "\n",
    "Quellen zum Nachlesen:\n",
    "> Understanding the Mathematics behind Gradient Descent: https://towardsdatascience.com/understanding-the-mathematics-behind-gradient-descent-dde5dc9be06e [Letzter Zugriff: 24.06.2024]\n",
    "\n",
    "> Gradient descent: https://en.wikipedia.org/wiki/Gradient_descent [Letzter Zugriff: 24.06.2024]\n",
    "\n",
    "> Logistic regression for binary classification with Core APIs: https://www.tensorflow.org/guide/core/logistic_regression_core [Letzter Zugriff: 24.06.2024]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b677ad2c-d977-4876-aea0-ab8a4e1d91d2",
   "metadata": {},
   "source": [
    "Dank Numpy's Matrixmultiplikationen können wir uns hier viel Arbeit sparen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6364ef79-000f-476b-9725-b387a38cc155",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradienabstieg.\n",
    "# - Für w1, w2 und b.\n",
    "def gradienten_abstieg(age, afford, y_true, epochs, loss_thr:float=2.0, lr:float=0.01):\n",
    "    # w1, 2w und Bais.\n",
    "    # - age, affordibility, y_true sind Vektoren.\n",
    "    w1   = w2 = 1  # Random, meist mit 1. \n",
    "    bias = 0  # Meist mit 0 \n",
    "    n = len(afford)  # Länge der Samples.\n",
    "\n",
    "    for i in range(epochs): # Für jede Epoche mach das:\n",
    "        # Weight-Sum. Siehe Abbildung 1 oben. \n",
    "        # - Jedes Neuron hat 2 Komponenten- Summe und Aktivierungsfunktion. \n",
    "        weight_sum = w1 * age + w2 * afford + bias  # Vektor Operation.\n",
    "        y_pred = sigmoid_funk(weight_sum)  # Aktivierungsfunktion.\n",
    "        \n",
    "        # Berechne Loss, hier Log-Loss\n",
    "        # - Oben definiert. \n",
    "        loss = logloss(y_pred, y_true)\n",
    "\n",
    "        # Dann nutzen wir die Ableitung. \n",
    "        # - Vereinfachte Ableitung. \n",
    "        # - Oder als Schleife.\n",
    "        w1d =  (1/n) * np.dot(np.transpose(age) ,    (y_pred-y_true))           \n",
    "        w2d =  (1/n) * np.dot(np.transpose(afford) , (y_pred-y_true)) \n",
    "        bias_d = np.mean(y_pred-y_true)\n",
    "\n",
    "        w1 = w1 - lr * w1d  # Formel von Oben.\n",
    "        w2 = w2 - lr * w2d  # - Hier werden die Gewichte angepasst - Die ganze Magie dahinter. \n",
    "        bias = bias - lr * bias_d\n",
    "\n",
    "        # Wie bei TF wollen wir auch Ausgaben sehen.\n",
    "        print(f\"epoche: {i}, w1: {w1}, w2: {w2}, bias: {bias}, loss: {loss}\")\n",
    "\n",
    "        if loss <= loss_thr:\n",
    "            break\n",
    "    return w1, w2, bias\n",
    "\n",
    "def sigmoid_funk(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ab98770-e48b-4bc3-ae65-b0c821101226",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, w1: 0.9762849575718682, w2: 0.9413816587881323, bias: -0.11723219144694776, loss: 0.71595572538616\n",
      "epoche: 1, w1: 0.9585899606042918, w2: 0.8931885694836231, bias: -0.2191259515368365, loss: 0.6829875086265863\n",
      "epoche: 2, w1: 0.9464149777228181, w2: 0.8547036125789471, bias: -0.30702265178471283, loss: 0.6589217086986395\n",
      "epoche: 3, w1: 0.9391383692699615, w2: 0.8249187940412019, bias: -0.38253896783203234, loss: 0.6416822511323294\n",
      "epoche: 4, w1: 0.9360948301666506, w2: 0.8026921496785079, bias: -0.4473753028623717, loss: 0.6294529652627155\n",
      "epoche: 5, w1: 0.9366346644985458, w2: 0.7868725699850446, bias: -0.5031736709956828, loss: 0.6207751606893134\n",
      "epoche: 6, w1: 0.9401607708239514, w2: 0.7763814668731136, bias: -0.5514315265930735, loss: 0.6145491275476828\n",
      "epoche: 7, w1: 0.9461466946820075, w2: 0.7702560384753816, bias: -0.5934618343566833, loss: 0.6099834810303708\n",
      "epoche: 8, w1: 0.954141456340729, w2: 0.7676648564070271, bias: -0.6303847592529248, loss: 0.6065276757013168\n",
      "epoche: 9, w1: 0.9637664517522821, w2: 0.7679063148049593, bias: -0.6631378798968053, loss: 0.6038079530817342\n",
      "epoche: 10, w1: 0.9747083310088303, w2: 0.7703979331115388, bias: -0.6924954774838189, loss: 0.6015749693364817\n",
      "epoche: 11, w1: 0.9867103584261395, w2: 0.7746617534011894, bias: -0.7190909476098314, loss: 0.5996644256615059\n",
      "epoche: 12, w1: 0.9995636937987874, w2: 0.7803089200364081, bias: -0.7434389789778153, loss: 0.5979689848393459\n",
      "epoche: 13, w1: 1.013099330277909, w2: 0.7870250787974431, bias: -0.7659558320778166, loss: 0.5964189169716717\n",
      "epoche: 14, w1: 1.0271809992881886, w2: 0.7945573421598614, bias: -0.7869770551959033, loss: 0.5949690691974582\n",
      "epoche: 15, w1: 1.041699115120877, w2: 0.8027030592497458, bias: -0.8067725273857667, loss: 0.5935902340209914\n",
      "epoche: 16, w1: 1.056565709679365, w2: 0.811300360093811, bias: -0.8255589949994384, loss: 0.5922634963089803\n",
      "epoche: 17, w1: 1.0717102529851525, w2: 0.820220315993876, bias: -0.8435103872263123, loss: 0.5909765610643756\n",
      "epoche: 18, w1: 1.0870762373292722, w2: 0.8293605092853291, bias: -0.8607662290025561, loss: 0.5897213818339175\n",
      "epoche: 19, w1: 1.1026184044934702, w2: 0.8386397992758673, bias: -0.8774384589438693, loss: 0.5884926355293281\n",
      "epoche: 20, w1: 1.118300506056648, w2: 0.8479940853731878, bias: -0.8936169294930595, loss: 0.5872867445382833\n",
      "epoche: 21, w1: 1.1340935008285877, w2: 0.8573728913365836, bias: -0.9093738292060501, loss: 0.5861012510685376\n",
      "epoche: 22, w1: 1.149974107965514, w2: 0.8667366198121979, bias: -0.9247672296944903, loss: 0.5849344174217753\n",
      "epoche: 23, w1: 1.1659236478819142, w2: 0.8760543505926367, bias: -0.9398439253530088, loss: 0.5837849708279206\n",
      "epoche: 24, w1: 1.181927115075068, w2: 0.8853020779095938, bias: -0.9546417038628001, loss: 0.5826519406126269\n",
      "epoche: 25, w1: 1.1979724372618215, w2: 0.8944613010162257, bias: -0.9691911598165757, loss: 0.5815345542661167\n",
      "epoche: 26, w1: 1.2140498838539258, w2: 0.9035178983365907, bias: -0.9835171423971467, loss: 0.5804321710549764\n",
      "epoche: 27, w1: 1.230151593932721, w2: 0.9124612287839202, bias: -0.9976399103957359, loss: 0.5793442395511553\n",
      "epoche: 28, w1: 1.2462711997251532, w2: 0.9212834148051873, bias: -1.011576053447038, loss: 0.5782702703942325\n",
      "epoche: 29, w1: 1.2624035263309465, w2: 0.9299787706437079, bias: -1.025339226670031, loss: 0.5772098187563245\n",
      "epoche: 30, w1: 1.2785443522893492, w2: 0.9385433465536165, bias: -1.0389407364687462, loss: 0.5761624729888272\n",
      "epoche: 31, w1: 1.294690218665101, w2: 0.946974565544332, bias: -1.05239000765875, loss: 0.575127847210206\n",
      "epoche: 32, w1: 1.3108382768152496, w2: 0.9552709339336141, bias: -1.0656949559981583, loss: 0.5741055764087999\n",
      "epoche: 33, w1: 1.3269861669867828, w2: 0.9634318107588048, bias: -1.0788622853294036, loss: 0.573095313153089\n",
      "epoche: 34, w1: 1.3431319214852517, w2: 0.9714572241154047, bias: -1.0918977246434252, loss: 0.572096725331731\n",
      "epoche: 35, w1: 1.3592738874247026, w2: 0.9793477249064761, bias: -1.1048062172686968, loss: 0.5711094945555183\n",
      "epoche: 36, w1: 1.3754106650828124, w2: 0.9871042704147335, bias: -1.1175920719073082, loss: 0.5701333149869384\n",
      "epoche: 37, w1: 1.3915410586933423, w2: 0.9947281316481379, bias: -1.1302590832631496, loss: 0.5691678924479512\n",
      "epoche: 38, w1: 1.4076640371522064, w2: 1.002220819637284, bias: -1.1428106284317694, loss: 0.5682129437106813\n",
      "epoche: 39, w1: 1.4237787026266868, w2: 1.0095840268414777, bias: -1.1552497439664873, loss: 0.567268195910123\n",
      "epoche: 40, w1: 1.439884265466134, w2: 1.016819580600401, bias: -1.1675791875358126, loss: 0.5663333860398768\n",
      "epoche: 41, w1: 1.4559800241380902, w2: 1.0239294061898248, bias: -1.1798014872912554, loss: 0.5654082605058878\n",
      "epoche: 42, w1: 1.4720653491730684, w2: 1.0309154975351178, bias: -1.1919189814307745, loss: 0.5644925747220518\n",
      "epoche: 43, w1: 1.4881396703077114, w2: 1.0377798940309326, bias: -1.2039338499383556, loss: 0.5635860927372274\n",
      "epoche: 44, w1: 1.5042024661805242, w2: 1.0445246622299096, bias: -1.2158481400782477, loss: 0.5626885868868012\n",
      "epoche: 45, w1: 1.5202532560653508, w2: 1.051151881413821, bias: -1.2276637869022196, loss: 0.5617998374642751\n",
      "epoche: 46, w1: 1.536291593232114, w2: 1.0576636322602815, bias: -1.2393826297731931, loss: 0.5609196324098137\n",
      "epoche: 47, w1: 1.5523170596074611, w2: 1.0640619879773263, bias: -1.2510064257054307, loss: 0.5600477670136363\n",
      "epoche: 48, w1: 1.5683292614741942, w2: 1.0703490074050517, bias: -1.262536860159576, loss: 0.559184043632756\n",
      "epoche: 49, w1: 1.5843278260011515, w2: 1.0765267296846839, bias: -1.2739755558018289, loss: 0.5583282714199483\n",
      "epoche: 50, w1: 1.6003123984372822, w2: 1.0825971701761263, bias: -1.2853240796337064, loss: 0.557480266064102\n",
      "epoche: 51, w1: 1.616282639837202, w2: 1.0885623173693868, bias: -1.2965839488168436, loss: 0.5566398495412577\n",
      "epoche: 52, w1: 1.632238225212267, w2: 1.0944241305866267, bias: -1.3077566354519186, loss: 0.5558068498757675\n",
      "epoche: 53, w1: 1.6481788420225363, w2: 1.1001845383125366, bias: -1.3188435705186372, loss: 0.5549811009110736\n",
      "epoche: 54, w1: 1.6641041889420203, w2: 1.1058454370234425, bias: -1.3298461471421121, loss: 0.5541624420896621\n",
      "epoche: 55, w1: 1.680013974843183, w2: 1.1114086904116431, bias: -1.340765723317776, loss: 0.5533507182417892\n",
      "epoche: 56, w1: 1.6959079179575178, w2: 1.1168761289223184, bias: -1.3516036242004785, loss: 0.5525457793826015\n",
      "epoche: 57, w1: 1.7117857451776601, w2: 1.1222495495369946, bias: -1.3623611440422583, loss: 0.5517474805172987\n",
      "epoche: 58, w1: 1.7276471914734153, w2: 1.127530715750842, bias: -1.373039547846403, loss: 0.5509556814540068\n",
      "epoche: 59, w1: 1.7434919993995963, w2: 1.1327213577017066, bias: -1.3836400727919107, loss: 0.5501702466240413\n",
      "epoche: 60, w1: 1.7593199186779789, w2: 1.137823172417261, bias: -1.3941639294716976, loss: 0.5493910449092638\n",
      "epoche: 61, w1: 1.7751307058391974, w2: 1.1428378241534503, bias: -1.4046123029792807, loss: 0.5486179494762363\n",
      "epoche: 62, w1: 1.7909241239132294, w2: 1.1477669448028254, bias: -1.414986353871782, loss: 0.5478508376169026\n",
      "epoche: 63, w1: 1.8066999421593621, w2: 1.1526121343556983, bias: -1.4252872190315977, loss: 0.5470895905955274\n",
      "epoche: 64, w1: 1.8224579358283377, w2: 1.157374961400522, bias: -1.4355160124446757, loss: 0.5463340935016423\n",
      "epoche: 65, w1: 1.8381978859508143, w2: 1.1620569636526688, bias: -1.4456738259098199, loss: 0.545584235108752\n",
      "epoche: 66, w1: 1.8539195791474314, w2: 1.1666596485030025, bias: -1.455761729690625, loss: 0.5448399077385692\n",
      "epoche: 67, w1: 1.8696228074566918, w2: 1.171184493579418, bias: -1.4657807731193904, loss: 0.5441010071305534\n",
      "epoche: 68, w1: 1.8853073681776116, w2: 1.1756329473159355, bias: -1.4757319851605522, loss: 0.5433674323165382\n",
      "epoche: 69, w1: 1.90097306372468, w2: 1.1800064295250816, bias: -1.485616374939728, loss: 0.5426390855002413\n",
      "epoche: 70, w1: 1.916619701493147, w2: 1.1843063319701936, bias: -1.4954349322433091, loss: 0.5419158719414601\n",
      "epoche: 71, w1: 1.9322470937330354, w2: 1.188534018935014, bias: -1.5051886279926034, loss: 0.5411976998447616\n",
      "epoche: 72, w1: 1.9478550574305795, w2: 1.1926908277885213, bias: -1.5148784146957868, loss: 0.5404844802524873\n",
      "epoche: 73, w1: 1.963443414196037, w2: 1.1967780695434145, bias: -1.5245052268803239, loss: 0.5397761269418961\n",
      "epoche: 74, w1: 1.979011990157019, w2: 1.2007970294070347, bias: -1.5340699815080343, loss: 0.5390725563262807\n",
      "epoche: 75, w1: 1.9945606158566365, w2: 1.204748967323808, bias: -1.5435735783745976, loss: 0.5383736873598947\n",
      "epoche: 76, w1: 2.0100891261558957, w2: 1.2086351185085324, bias: -1.5530169004949752, loss: 0.5376794414465402\n",
      "epoche: 77, w1: 2.025597360139867, w2: 1.2124566939700172, bias: -1.5624008144759807, loss: 0.5369897423516634\n",
      "epoche: 78, w1: 2.041085161027247, w2: 1.2162148810247393, bias: -1.571726170877026, loss: 0.5363045161178243\n",
      "epoche: 79, w1: 2.056552376082984, w2: 1.2199108438002961, bias: -1.580993804559907, loss: 0.5356236909833977\n",
      "epoche: 80, w1: 2.071998856533708, w2: 1.223545723728533, bias: -1.590204535028361, loss: 0.5349471973043814\n",
      "epoche: 81, w1: 2.0874244574857364, w2: 1.2271206400282983, bias: -1.5993591667580227, loss: 0.5342749674791847\n",
      "epoche: 82, w1: 2.1028290378454635, w2: 1.2306366901778385, bias: -1.6084584895173175, loss: 0.5336069358762775\n",
      "epoche: 83, w1: 2.1182124602419803, w2: 1.2340949503768903, bias: -1.6175032786797578, loss: 0.5329430387645884\n",
      "epoche: 84, w1: 2.1335745909517803, w2: 1.2374964759985692, bias: -1.6264942955280564, loss: 0.5322832142465398\n",
      "epoche: 85, w1: 2.1489152998254353, w2: 1.2408423020311738, bias: -1.6354322875504157, loss: 0.5316274021936149\n",
      "epoche: 86, w1: 2.164234460216138, w2: 1.2441334435100557, bias: -1.6443179887293216, loss: 0.5309755441843597\n",
      "epoche: 87, w1: 2.17953194891002, w2: 1.2473708959397127, bias: -1.6531521198231298, loss: 0.5303275834447163\n",
      "epoche: 88, w1: 2.194807646058162, w2: 1.250555635706283, bias: -1.661935388640714, loss: 0.5296834647906044\n",
      "epoche: 89, w1: 2.2100614351102315, w2: 1.2536886204806221, bias: -1.6706684903094138, loss: 0.5290431345726528\n",
      "epoche: 90, w1: 2.2252932027496732, w2: 1.2567707896121498, bias: -1.6793521075365123, loss: 0.5284065406230041\n",
      "epoche: 91, w1: 2.2405028388304045, w2: 1.2598030645136624, bias: -1.687986910864449, loss: 0.5277736322041034\n",
      "epoche: 92, w1: 2.2556902363149516, w2: 1.2627863490373046, bias: -1.6965735589199615, loss: 0.5271443599594009\n",
      "epoche: 93, w1: 2.2708552912139846, w2: 1.265721529841896, bias: -1.7051126986573433, loss: 0.5265186758658851\n",
      "epoche: 94, w1: 2.285997902527202, w2: 1.268609476751809, bias: -1.713604965595987, loss: 0.5258965331883829\n",
      "epoche: 95, w1: 2.301117972185521, w2: 1.2714510431075912, bias: -1.72205098405238, loss: 0.5252778864355494\n",
      "epoche: 96, w1: 2.316215404994538, w2: 1.2742470661085263, bias: -1.7304513673667086, loss: 0.5246626913174889\n",
      "epoche: 97, w1: 2.3312901085792146, w2: 1.276998367147324, bias: -1.7388067181242182, loss: 0.5240509047049378\n",
      "epoche: 98, w1: 2.3463419933297587, w2: 1.2797057521371236, bias: -1.7471176283714775, loss: 0.5234424845899525\n",
      "epoche: 99, w1: 2.3613709723486647, w2: 1.2823700118309993, bias: -1.75538467982768, loss: 0.5228373900480411\n",
      "epoche: 100, w1: 2.3763769613988805, w2: 1.284991922134146, bias: -1.7636084440911166, loss: 0.5222355812016855\n",
      "epoche: 101, w1: 2.39135987885307, w2: 1.2875722444089237, bias: -1.7717894828409502, loss: 0.521637019185197\n",
      "epoche: 102, w1: 2.406319645643941, w2: 1.2901117257729362, bias: -1.7799283480344106, loss: 0.5210416661108577\n",
      "epoche: 103, w1: 2.4212561852156123, w2: 1.2926110993903108, bias: -1.7880255820995339, loss: 0.520449485036295\n",
      "epoche: 104, w1: 2.436169423475991, w2: 1.2950710847563496, bias: -1.7960817181235582, loss: 0.5198604399330428\n",
      "epoche: 105, w1: 2.4510592887501326, w2: 1.297492387975712, bias: -1.80409728003709, loss: 0.5192744956562453\n",
      "epoche: 106, w1: 2.4659257117345597, w2: 1.2998757020342908, bias: -1.8120727827941474, loss: 0.5186916179154573\n",
      "epoche: 107, w1: 2.480768625452516, w2: 1.3022217070649333, bias: -1.8200087325481875, loss: 0.5181117732465002\n",
      "epoche: 108, w1: 2.495587965210131, w2: 1.3045310706071627, bias: -1.8279056268242182, loss: 0.517534928984334\n",
      "epoche: 109, w1: 2.510383668553471, w2: 1.306804447861045, bias: -1.8357639546870945, loss: 0.5169610532369054\n",
      "epoche: 110, w1: 2.5251556752264555, w2: 1.3090424819353481, bias: -1.8435841969060938, loss: 0.5163901148599374\n",
      "epoche: 111, w1: 2.53990392712962, w2: 1.3112458040901316, bias: -1.8513668261158651, loss: 0.5158220834326187\n",
      "epoche: 112, w1: 2.5546283682796993, w2: 1.3134150339739061, bias: -1.8591123069738433, loss: 0.5152569292341681\n",
      "epoche: 113, w1: 2.569328944770016, w2: 1.3155507798554957, bias: -1.8668210963142136, loss: 0.5146946232212323\n",
      "epoche: 114, w1: 2.584005604731653, w2: 1.317653638850733, bias: -1.8744936432985144, loss: 0.5141351370060901\n",
      "epoche: 115, w1: 2.5986582982953896, w2: 1.3197241971441145, bias: -1.8821303895629624, loss: 0.5135784428356321\n",
      "epoche: 116, w1: 2.6132869775543854, w2: 1.3217630302055412, bias: -1.8897317693625777, loss: 0.5130245135710865\n",
      "epoche: 117, w1: 2.6278915965275926, w2: 1.3237707030022632, bias: -1.8972982097121907, loss: 0.5124733226684618\n",
      "epoche: 118, w1: 2.6424721111238805, w2: 1.3257477702061466, bias: -1.9048301305244053, loss: 0.5119248441596823\n",
      "epoche: 119, w1: 2.657028479106855, w2: 1.3276947763963785, bias: -1.9123279447445942, loss: 0.5113790526343877\n",
      "epoche: 120, w1: 2.6715606600603565, w2: 1.3296122562577193, bias: -1.9197920584829977, loss: 0.5108359232223747\n",
      "epoche: 121, w1: 2.6860686153546203, w2: 1.3315007347744132, bias: -1.9272228711439967, loss: 0.5102954315766537\n",
      "epoche: 122, w1: 2.7005523081130858, w2: 1.3333607274198622, bias: -1.9346207755526292, loss: 0.5097575538571013\n",
      "epoche: 123, w1: 2.715011703179838, w2: 1.3351927403421655, bias: -1.9419861580784152, loss: 0.5092222667146837\n",
      "epoche: 124, w1: 2.729446767087667, w2: 1.3369972705456261, bias: -1.9493193987565562, loss: 0.5086895472762308\n",
      "epoche: 125, w1: 2.743857468026732, w2: 1.3387748060683227, bias: -1.9566208714065731, loss: 0.5081593731297416\n",
      "epoche: 126, w1: 2.7582437758138156, w2: 1.3405258261558406, bias: -1.9638909437484413, loss: 0.5076317223102\n",
      "epoche: 127, w1: 2.7726056618621566, w2: 1.3422508014312555, bias: -1.971129977516285, loss: 0.5071065732858836\n",
      "epoche: 128, w1: 2.786943099151845, w2: 1.3439501940614618, bias: -1.9783383285696885, loss: 0.5065839049451448\n",
      "epoche: 129, w1: 2.8012560622007707, w2: 1.3456244579199292, bias: -1.985516347002681, loss: 0.5060636965836517\n",
      "epoche: 130, w1: 2.8155445270361117, w2: 1.3472740387459798, bias: -1.9926643772504486, loss: 0.5055459278920662\n",
      "epoche: 131, w1: 2.829808471166348, w2: 1.3488993743006625, bias: -1.9997827581938294, loss: 0.5050305789441486\n",
      "epoche: 132, w1: 2.8440478735537953, w2: 1.3505008945193109, bias: -2.0068718232616427, loss: 0.5045176301852686\n",
      "epoche: 133, w1: 2.858262714587639, w2: 1.3520790216608614, bias: -2.0139319005309027, loss: 0.5040070624213123\n",
      "epoche: 134, w1: 2.872452976057467, w2: 1.3536341704540098, bias: -2.020963312824968, loss: 0.5034988568079679\n",
      "epoche: 135, w1: 2.8866186411272805, w2: 1.355166748240281, bias: -2.0279663778096735, loss: 0.5029929948403764\n",
      "epoche: 136, w1: 2.900759694309985, w2: 1.3566771551140848, bias: -2.0349414080874895, loss: 0.5024894583431359\n",
      "epoche: 137, w1: 2.914876121442335, w2: 1.3581657840598298, bias: -2.041888711289761, loss: 0.5019882294606461\n",
      "epoche: 138, w1: 2.92896790966034, w2: 1.3596330210861642, bias: -2.048808590167064, loss: 0.5014892906477794\n",
      "epoche: 139, w1: 2.9430350473751083, w2: 1.361079245357411, bias: -2.0557013426777244, loss: 0.5009926246608691\n",
      "epoche: 140, w1: 2.957077524249128, w2: 1.3625048293222641, bias: -2.0625672620745448, loss: 0.5004982145490007\n",
      "epoche: 141, w1: 2.9710953311729713, w2: 1.3639101388398103, bias: -2.0694066369897763, loss: 0.5000060436455989\n",
      "epoche: 142, w1: 2.985088460242416, w2: 1.3652955333029357, bias: -2.0762197515183782, loss: 0.4995160955602955\n",
      "epoche: 143, w1: 2.9990569047359736, w2: 1.366661365759184, bias: -2.0830068852996018, loss: 0.49902835417107283\n",
      "epoche: 144, w1: 3.013000659092818, w2: 1.3680079830291183, bias: -2.0897683135969403, loss: 0.49854280361666853\n",
      "epoche: 145, w1: 3.0269197188911035, w2: 1.3693357258222523, bias: -2.096504307376478, loss: 0.49805942828923533\n",
      "epoche: 146, w1: 3.040814080826666, w2: 1.3706449288505997, bias: -2.103215133383677, loss: 0.49757821282724635\n",
      "epoche: 147, w1: 3.0546837426920996, w2: 1.3719359209399022, bias: -2.109901054218636, loss: 0.4970991421086351\n",
      "epoche: 148, w1: 3.0685287033562023, w2: 1.373209025138586, bias: -2.1165623284098567, loss: 0.4966222012441651\n",
      "epoche: 149, w1: 3.0823489627437795, w2: 1.3744645588245021, bias: -2.1231992104865474, loss: 0.4961473755710193\n",
      "epoche: 150, w1: 3.0961445218158, w2: 1.3757028338094976, bias: -2.129811951049503, loss: 0.49567465064660027\n",
      "epoche: 151, w1: 3.1099153825499024, w2: 1.3769241564418702, bias: -2.1364007968405856, loss: 0.4952040122425369\n",
      "epoche: 152, w1: 3.123661547921234, w2: 1.3781288277067532, bias: -2.1429659908108434, loss: 0.4947354463388879\n",
      "epoche: 153, w1: 3.137383021883628, w2: 1.3793171433244773, bias: -2.149507772187292, loss: 0.4942689391185352\n",
      "epoche: 154, w1: 3.1510798093511028, w2: 1.3804893938469571, bias: -2.1560263765383945, loss: 0.4938044769617633\n",
      "epoche: 155, w1: 3.1647519161796818, w2: 1.3816458647521437, bias: -2.1625220358382604, loss: 0.4933420464410137\n",
      "epoche: 156, w1: 3.1783993491495273, w2: 1.3827868365365894, bias: -2.1689949785296, loss: 0.492881634315813\n",
      "epoche: 157, w1: 3.19202211594738, w2: 1.383912584806167, bias: -2.175445429585457, loss: 0.4924232275278645\n",
      "epoche: 158, w1: 3.2056202251493, w2: 1.3850233803649836, bias: -2.1818736105697427, loss: 0.4919668131963007\n",
      "epoche: 159, w1: 3.2191936862037043, w2: 1.3861194893025288, bias: -2.1882797396966094, loss: 0.49151237861308933\n",
      "epoche: 160, w1: 3.232742509414693, w2: 1.3872011730791, bias: -2.194664031888671, loss: 0.4910599112385886\n",
      "epoche: 161, w1: 3.246266705925661, w2: 1.388268688609539, bias: -2.2010266988341143, loss: 0.49060939869724535\n",
      "epoche: 162, w1: 3.259766287703185, w2: 1.3893222883453191, bias: -2.207367949042707, loss: 0.490160828773432\n",
      "epoche: 163, w1: 3.27324126752119, w2: 1.39036222035502, bias: -2.213687987900743, loss: 0.4897141894074188\n",
      "epoche: 164, w1: 3.286691658945378, w2: 1.3913887284032245, bias: -2.219987017724934, loss: 0.489269468691473\n",
      "epoche: 165, w1: 3.300117476317924, w2: 1.392402052027872, bias: -2.226265237815277, loss: 0.48882665486608473\n",
      "epoche: 166, w1: 3.3135187347424297, w2: 1.3934024266161034, bias: -2.232522844506919, loss: 0.4883857363163126\n",
      "epoche: 167, w1: 3.32689545006913, w2: 1.3943900834786296, bias: -2.2387600312210383, loss: 0.4879467015682456\n",
      "epoche: 168, w1: 3.340247638880349, w2: 1.3953652499226556, bias: -2.244976988514764, loss: 0.48750953928557816\n",
      "epoche: 169, w1: 3.3535753184762007, w2: 1.3963281493233928, bias: -2.251173904130155, loss: 0.48707423826629287\n",
      "epoche: 170, w1: 3.3668785068605294, w2: 1.3972790011941871, bias: -2.2573509630422555, loss: 0.4866407874394491\n",
      "epoche: 171, w1: 3.3801572227270844, w2: 1.3982180212552981, bias: -2.263508347506251, loss: 0.48620917586207163\n",
      "epoche: 172, w1: 3.3934114854459287, w2: 1.3991454215013517, bias: -2.2696462371037387, loss: 0.4857793927161385\n",
      "epoche: 173, w1: 3.4066413150500714, w2: 1.4000614102675002, bias: -2.2757648087881335, loss: 0.48535142730566294\n",
      "epoche: 174, w1: 3.4198467322223256, w2: 1.400966192294315, bias: -2.2818642369292284, loss: 0.4849252690538656\n",
      "epoche: 175, w1: 3.4330277582823836, w2: 1.4018599687914384, bias: -2.287944693356923, loss: 0.4845009075004372\n",
      "epoche: 176, w1: 3.446184415174109, w2: 1.4027429375000227, bias: -2.2940063474041428, loss: 0.48407833229888386\n",
      "epoche: 177, w1: 3.4593167254530375, w2: 1.403615292753982, bias: -2.300049365948961, loss: 0.4836575332139574\n",
      "epoche: 178, w1: 3.472424712274086, w2: 1.40447722554008, bias: -2.3060739134559407, loss: 0.4832385001191627\n",
      "epoche: 179, w1: 3.4855083993794675, w2: 1.4053289235568804, bias: -2.312080152016718, loss: 0.4828212229943444\n",
      "epoche: 180, w1: 3.4985678110868017, w2: 1.4061705712725845, bias: -2.318068241389832, loss: 0.4824056919233461\n",
      "epoche: 181, w1: 3.5116029722774273, w2: 1.4070023499817752, bias: -2.3240383390398276, loss: 0.48199189709174217\n",
      "epoche: 182, w1: 3.5246139083849037, w2: 1.4078244378610962, bias: -2.329990600175638, loss: 0.4815798287846394\n",
      "epoche: 183, w1: 3.5376006453837032, w2: 1.4086370100238834, bias: -2.335925177788266, loss: 0.4811694773845443\n",
      "epoche: 184, w1: 3.5505632097780913, w2: 1.4094402385737739, bias: -2.341842222687776, loss: 0.4807608333692976\n",
      "epoche: 185, w1: 3.5635016285911876, w2: 1.4102342926573117, bias: -2.347741883539612, loss: 0.480353887310069\n",
      "epoche: 186, w1: 3.57641592935421, w2: 1.4110193385155725, bias: -2.3536243069002554, loss: 0.47994862986941395\n",
      "epoche: 187, w1: 3.5893061400958923, w2: 1.4117955395348254, bias: -2.359489637252232, loss: 0.47954505179938917\n",
      "epoche: 188, w1: 3.6021722893320787, w2: 1.4125630562962554, bias: -2.3653380170384883, loss: 0.47914314393972346\n",
      "epoche: 189, w1: 3.6150144060554865, w2: 1.4133220466247614, bias: -2.371169586696144, loss: 0.478742897216045\n",
      "epoche: 190, w1: 3.62783251972564, w2: 1.4140726656368514, bias: -2.376984484689635, loss: 0.47834430263816036\n",
      "epoche: 191, w1: 3.640626660258966, w2: 1.4148150657876537, bias: -2.382782847543256, loss: 0.47794735129838506\n",
      "epoche: 192, w1: 3.653396858019054, w2: 1.4155493969170603, bias: -2.388564809873126, loss: 0.4775520343699241\n",
      "epoche: 193, w1: 3.666143143807076, w2: 1.4162758062950207, bias: -2.3943305044185683, loss: 0.47715834310529953\n",
      "epoche: 194, w1: 3.678865548852361, w2: 1.4169944386660052, bias: -2.400080062072937, loss: 0.4767662688348248\n",
      "epoche: 195, w1: 3.691564104803127, w2: 1.4177054362926504, bias: -2.4058136119138878, loss: 0.476375802965124\n",
      "epoche: 196, w1: 3.7042388437173615, w2: 1.4184089389986092, bias: -2.4115312812331084, loss: 0.4759869369776936\n",
      "epoche: 197, w1: 3.716889798053853, w2: 1.4191050842106148, bias: -2.4172331955655193, loss: 0.4755996624275083\n",
      "epoche: 198, w1: 3.729517000663368, w2: 1.41979400699978, bias: -2.422919478717954, loss: 0.4752139709416631\n",
      "epoche: 199, w1: 3.742120484779974, w2: 1.4204758401221445, bias: -2.428590252797331, loss: 0.4748298542180597\n",
      "epoche: 200, w1: 3.7547002840125017, w2: 1.4211507140584836, bias: -2.4342456382383237, loss: 0.47444730402412694\n",
      "epoche: 201, w1: 3.7672564323361493, w2: 1.4218187570533978, bias: -2.439885753830543, loss: 0.4740663121955794\n",
      "epoche: 202, w1: 3.7797889640842213, w2: 1.422480095153693, bias: -2.445510716745238, loss: 0.4736868706352115\n",
      "epoche: 203, w1: 3.7922979139400046, w2: 1.4231348522460665, bias: -2.4511206425615226, loss: 0.47330897131172567\n",
      "epoche: 204, w1: 3.8047833169287752, w2: 1.4237831500941158, bias: -2.4567156452921464, loss: 0.4729326062585938\n",
      "epoche: 205, w1: 3.8172452084099366, w2: 1.4244251083746773, bias: -2.4622958374088064, loss: 0.4725577675729502\n",
      "epoche: 206, w1: 3.8296836240692866, w2: 1.4250608447135142, bias: -2.467861329867016, loss: 0.47218444741451726\n",
      "epoche: 207, w1: 3.8420985999114095, w2: 1.4256904747203634, bias: -2.473412232130539, loss: 0.4718126380045586\n",
      "epoche: 208, w1: 3.854490172252193, w2: 1.4263141120233525, bias: -2.478948652195394, loss: 0.4714423316248643\n",
      "epoche: 209, w1: 3.8668583777114685, w2: 1.4269318683028038, bias: -2.484470696613441, loss: 0.4710735206167618\n",
      "epoche: 210, w1: 3.8792032532057683, w2: 1.427543853324433, bias: -2.4899784705155548, loss: 0.4707061973801553\n",
      "epoche: 211, w1: 3.8915248359412042, w2: 1.4281501749719545, bias: -2.495472077634395, loss: 0.4703403543725911\n",
      "epoche: 212, w1: 3.9038231634064617, w2: 1.4287509392791093, bias: -2.500951620326779, loss: 0.4699759841083489\n",
      "epoche: 213, w1: 3.916098273365907, w2: 1.4293462504611207, bias: -2.50641719959567, loss: 0.46961307915755757\n",
      "epoche: 214, w1: 3.9283502038528098, w2: 1.4299362109455929, bias: -2.511868915111778, loss: 0.46925163214533416\n",
      "epoche: 215, w1: 3.9405789931626725, w2: 1.4305209214028614, bias: -2.5173068652347914, loss: 0.46889163575094717\n",
      "epoche: 216, w1: 3.9527846798466735, w2: 1.4311004807758072, bias: -2.522731147034237, loss: 0.46853308270700167\n",
      "epoche: 217, w1: 3.964967302705214, w2: 1.4316749863091431, bias: -2.528141856309985, loss: 0.468175965798646\n",
      "epoche: 218, w1: 3.9771269007815713, w2: 1.432244533578184, bias: -2.533539087612395, loss: 0.4678202778627996\n",
      "epoche: 219, w1: 3.989263513355657, w2: 1.4328092165171087, bias: -2.5389229342621196, loss: 0.4674660117874012\n",
      "epoche: 220, w1: 4.001377179937877, w2: 1.4333691274467275, bias: -2.544293488369564, loss: 0.467113160510677\n",
      "epoche: 221, w1: 4.013467940263091, w2: 1.4339243571017588, bias: -2.5496508408540133, loss: 0.46676171702042674\n",
      "epoche: 222, w1: 4.025535834284673, w2: 1.4344749946576292, bias: -2.5549950814624314, loss: 0.46641167435333036\n",
      "epoche: 223, w1: 4.037580902168668, w2: 1.4350211277568024, bias: -2.560326298787938, loss: 0.46606302559426965\n",
      "epoche: 224, w1: 4.049603184288043, w2: 1.4355628425346492, bias: -2.5656445802879686, loss: 0.4657157638756706\n",
      "epoche: 225, w1: 4.061602721217038, w2: 1.4361002236448641, bias: -2.5709500123021267, loss: 0.46536988237685867\n",
      "epoche: 226, w1: 4.073579553725603, w2: 1.4366333542844392, bias: -2.5762426800697287, loss: 0.4650253743234343\n",
      "epoche: 227, w1: 4.08553372277393, w2: 1.4371623162182021, bias: -2.581522667747053, loss: 0.46468223298666084\n",
      "epoche: 228, w1: 4.097465269507078, w2: 1.4376871898029275, bias: -2.586790058424292, loss: 0.4643404516828694\n",
      "epoche: 229, w1: 4.1093742352496765, w2: 1.4382080540110294, bias: -2.5920449341422205, loss: 0.46400002377287847\n",
      "epoche: 230, w1: 4.121260661500731, w2: 1.4387249864538414, bias: -2.597287375908576, loss: 0.463660942661427\n",
      "epoche: 231, w1: 4.133124589928501, w2: 1.439238063404495, bias: -2.6025174637141677, loss: 0.46332320179662206\n",
      "epoche: 232, w1: 4.14496606236547, w2: 1.4397473598203996, bias: -2.6077352765487074, loss: 0.46298679466939924\n",
      "epoche: 233, w1: 4.156785120803396, w2: 1.4402529493653355, bias: -2.6129408924163764, loss: 0.4626517148129972\n",
      "epoche: 234, w1: 4.168581807388445, w2: 1.4407549044311638, bias: -2.6181343883511263, loss: 0.46231795580244317\n",
      "epoche: 235, w1: 4.180356164416403, w2: 1.441253296159163, bias: -2.6233158404317267, loss: 0.4619855112540526\n",
      "epoche: 236, w1: 4.192108234327972, w2: 1.441748194460997, bias: -2.6284853237965544, loss: 0.4616543748249384\n",
      "epoche: 237, w1: 4.2038380597041405, w2: 1.442239668039322, bias: -2.633642912658137, loss: 0.46132454021253383\n",
      "epoche: 238, w1: 4.215545683261628, w2: 1.4427277844080402, bias: -2.638788680317452, loss: 0.46099600115412503\n",
      "epoche: 239, w1: 4.227231147848414, w2: 1.4432126099122045, bias: -2.6439226991779834, loss: 0.46066875142639496\n",
      "epoche: 240, w1: 4.2388944964393325, w2: 1.443694209747582, bias: -2.649045040759547, loss: 0.46034278484497754\n",
      "epoche: 241, w1: 4.250535772131747, w2: 1.4441726479798827, bias: -2.65415577571188, loss: 0.46001809526402176\n",
      "epoche: 242, w1: 4.262155018141293, w2: 1.4446479875636582, bias: -2.6592549738280074, loss: 0.4596946765757669\n",
      "epoche: 243, w1: 4.2737522777976915, w2: 1.4451202903608782, bias: -2.6643427040573817, loss: 0.4593725227101245\n",
      "epoche: 244, w1: 4.285327594540639, w2: 1.4455896171591884, bias: -2.6694190345188056, loss: 0.4590516276342726\n",
      "epoche: 245, w1: 4.296881011915756, w2: 1.4460560276898582, bias: -2.6744840325131385, loss: 0.45873198535225723\n",
      "epoche: 246, w1: 4.308412573570617, w2: 1.4465195806454214, bias: -2.6795377645357923, loss: 0.4584135899046026\n",
      "epoche: 247, w1: 4.319922323250832, w2: 1.446980333697017, bias: -2.684580296289018, loss: 0.4580964353679303\n",
      "epoche: 248, w1: 4.331410304796206, w2: 1.4474383435114349, bias: -2.689611692693991, loss: 0.45778051585458657\n",
      "epoche: 249, w1: 4.342876562136956, w2: 1.4478936657678712, bias: -2.6946320179026912, loss: 0.4574658255122766\n",
      "epoche: 250, w1: 4.354321139289998, w2: 1.4483463551744002, bias: -2.6996413353095936, loss: 0.457152358523708\n",
      "epoche: 251, w1: 4.365744080355291, w2: 1.4487964654841663, bias: -2.704639707563157, loss: 0.45684010910624057\n",
      "epoche: 252, w1: 4.377145429512247, w2: 1.4492440495113008, bias: -2.709627196577131, loss: 0.45652907151154365\n",
      "epoche: 253, w1: 4.388525231016199, w2: 1.4496891591465704, bias: -2.714603863541667, loss: 0.4562192400252605\n",
      "epoche: 254, w1: 4.399883529194932, w2: 1.4501318453727605, bias: -2.719569768934256, loss: 0.4559106089666793\n",
      "epoche: 255, w1: 4.411220368445272, w2: 1.4505721582797981, bias: -2.72452497253048, loss: 0.4556031726884111\n",
      "epoche: 256, w1: 4.422535793229729, w2: 1.4510101470796195, bias: -2.7294695334145844, loss: 0.45529692557607415\n",
      "epoche: 257, w1: 4.433829848073205, w2: 1.4514458601207878, bias: -2.7344035099898854, loss: 0.454991862047984\n",
      "epoche: 258, w1: 4.445102577559753, w2: 1.4518793449028629, bias: -2.7393269599889956, loss: 0.4546879765548499\n",
      "epoche: 259, w1: 4.456354026329394, w2: 1.4523106480905301, bias: -2.7442399404838906, loss: 0.45438526357947745\n",
      "epoche: 260, w1: 4.467584239074984, w2: 1.452739815527491, bias: -2.749142507895806, loss: 0.45408371763647576\n",
      "epoche: 261, w1: 4.478793260539145, w2: 1.4531668922501206, bias: -2.754034718004972, loss: 0.4537833332719723\n",
      "epoche: 262, w1: 4.489981135511237, w2: 1.4535919225008944, bias: -2.758916625960192, loss: 0.45348410506333064\n",
      "epoche: 263, w1: 4.5011479088243895, w2: 1.454014949741591, bias: -2.7637882862882623, loss: 0.45318602761887483\n",
      "epoche: 264, w1: 4.5122936253525845, w2: 1.4544360166662729, bias: -2.768649752903238, loss: 0.4528890955776186\n",
      "epoche: 265, w1: 4.523418330007788, w2: 1.4548551652140493, bias: -2.7735010791155474, loss: 0.45259330360899924\n",
      "epoche: 266, w1: 4.53452206773713, w2: 1.4552724365816259, bias: -2.7783423176409605, loss: 0.45229864641261713\n",
      "epoche: 267, w1: 4.545604883520137, w2: 1.4556878712356434, bias: -2.7831735206094086, loss: 0.4520051187179782\n",
      "epoche: 268, w1: 4.5566668223660125, w2: 1.456101508924811, bias: -2.7879947395736613, loss: 0.45171271528424245\n",
      "epoche: 269, w1: 4.567707929310961, w2: 1.4565133886918367, bias: -2.7928060255178635, loss: 0.4514214308999763\n",
      "epoche: 270, w1: 4.578728249415565, w2: 1.4569235488851568, bias: -2.797607428865933, loss: 0.45113126038290907\n",
      "epoche: 271, w1: 4.5897278277622044, w2: 1.457332027170473, bias: -2.8023989994898217, loss: 0.4508421985796938\n",
      "epoche: 272, w1: 4.60070670945252, w2: 1.4577388605420936, bias: -2.8071807867176424, loss: 0.45055424036567215\n",
      "epoche: 273, w1: 4.611664939604926, w2: 1.4581440853340872, bias: -2.8119528393416666, loss: 0.45026738064464294\n",
      "epoche: 274, w1: 4.622602563352165, w2: 1.4585477372312514, bias: -2.81671520562619, loss: 0.44998161434863426\n",
      "epoche: 275, w1: 4.633519625838904, w2: 1.4589498512798973, bias: -2.8214679333152737, loss: 0.44969693643768066\n",
      "epoche: 276, w1: 4.644416172219379, w2: 1.4593504618984556, bias: -2.826211069640357, loss: 0.44941334189960197\n",
      "epoche: 277, w1: 4.655292247655072, w2: 1.459749602887907, bias: -2.83094466132775, loss: 0.44913082574978697\n",
      "epoche: 278, w1: 4.66614789731244, w2: 1.4601473074420368, bias: -2.835668754606007, loss: 0.44884938303098026\n",
      "epoche: 279, w1: 4.67698316636068, w2: 1.4605436081575227, bias: -2.840383395213176, loss: 0.4485690088130715\n",
      "epoche: 280, w1: 4.687798099969531, w2: 1.4609385370438526, bias: -2.845088628403937, loss: 0.44828969819289\n",
      "epoche: 281, w1: 4.698592743307125, w2: 1.4613321255330785, bias: -2.8497844989566214, loss: 0.4480114462939993\n",
      "epoche: 282, w1: 4.7093671415378635, w2: 1.4617244044894098, bias: -2.854471051180124, loss: 0.44773424826649855\n",
      "epoche: 283, w1: 4.720121339820346, w2: 1.4621154042186466, bias: -2.8591483289206963, loss: 0.44745809928682295\n",
      "epoche: 284, w1: 4.730855383305329, w2: 1.4625051544774572, bias: -2.8638163755686397, loss: 0.4471829945575504\n",
      "epoche: 285, w1: 4.741569317133722, w2: 1.4628936844825022, bias: -2.8684752340648845, loss: 0.44690892930720905\n",
      "epoche: 286, w1: 4.752263186434624, w2: 1.463281022919407, bias: -2.8731249469074682, loss: 0.44663589879008797\n",
      "epoche: 287, w1: 4.762937036323391, w2: 1.4636671979515874, bias: -2.8777655561579083, loss: 0.44636389828605144\n",
      "epoche: 288, w1: 4.7735909118997455, w2: 1.4640522372289282, bias: -2.8823971034474725, loss: 0.44609292310035376\n",
      "epoche: 289, w1: 4.7842248582459135, w2: 1.4644361678963194, bias: -2.887019629983352, loss: 0.4458229685634591\n",
      "epoche: 290, w1: 4.794838920424804, w2: 1.46481901660205, bias: -2.891633176554733, loss: 0.44555403003086225\n",
      "epoche: 291, w1: 4.805433143478216, w2: 1.4652008095060658, bias: -2.896237783538774, loss: 0.44528610288291137\n",
      "epoche: 292, w1: 4.816007572425081, w2: 1.4655815722880887, bias: -2.9008334909064857, loss: 0.4450191825246353\n",
      "epoche: 293, w1: 4.826562252259739, w2: 1.4659613301556036, bias: -2.90542033822852, loss: 0.44475326438557017\n",
      "epoche: 294, w1: 4.8370972279502515, w2: 1.466340107851713, bias: -2.909998364680866, loss: 0.44448834391959136\n",
      "epoche: 295, w1: 4.847612544436733, w2: 1.4667179296628636, bias: -2.9145676090504535, loss: 0.44422441660474465\n",
      "epoche: 296, w1: 4.85810824662973, w2: 1.4670948194264435, bias: -2.9191281097406727, loss: 0.4439614779430815\n",
      "epoche: 297, w1: 4.8685843794086185, w2: 1.4674708005382566, bias: -2.9236799047768005, loss: 0.4436995234604964\n",
      "epoche: 298, w1: 4.879040987620042, w2: 1.4678458959598732, bias: -2.9282230318113456, loss: 0.44343854870656424\n",
      "epoche: 299, w1: 4.8894781160763685, w2: 1.4682201282258596, bias: -2.932757528129306, loss: 0.44317854925438255\n",
      "epoche: 300, w1: 4.89989580955419, w2: 1.468593519450889, bias: -2.9372834306533466, loss: 0.4429195207004132\n",
      "epoche: 301, w1: 4.910294112792838, w2: 1.4689660913367368, bias: -2.941800775948891, loss: 0.44266145866432743\n",
      "epoche: 302, w1: 4.920673070492938, w2: 1.469337865179159, bias: -2.9463096002291373, loss: 0.44240435878885176\n",
      "epoche: 303, w1: 4.931032727314984, w2: 1.4697088618746597, bias: -2.950809939359991, loss: 0.44214821673961696\n",
      "epoche: 304, w1: 4.941373127877951, w2: 1.4700791019271462, bias: -2.9553018288649233, loss: 0.4418930282050072\n",
      "epoche: 305, w1: 4.951694316757923, w2: 1.4704486054544759, bias: -2.9597853039297513, loss: 0.441638788896012\n",
      "epoche: 306, w1: 4.961996338486755, w2: 1.4708173921948953, bias: -2.964260399407343, loss: 0.4413854945460799\n",
      "epoche: 307, w1: 4.972279237550762, w2: 1.4711854815133742, bias: -2.9687271498222505, loss: 0.4411331409109723\n",
      "epoche: 308, w1: 4.982543058389429, w2: 1.4715528924078356, bias: -2.973185589375267, loss: 0.44088172376862156\n",
      "epoche: 309, w1: 4.992787845394155, w2: 1.4719196435152835, bias: -2.977635751947914, loss: 0.4406312389189881\n",
      "epoche: 310, w1: 5.003013642907012, w2: 1.4722857531178306, bias: -2.982077671106862, loss: 0.44038168218391965\n",
      "epoche: 311, w1: 5.013220495219536, w2: 1.472651239148628, bias: -2.9865113801082743, loss: 0.44013304940701403\n",
      "epoche: 312, w1: 5.023408446571541, w2: 1.4730161191976967, bias: -2.9909369119020894, loss: 0.4398853364534796\n",
      "epoche: 313, w1: 5.033577541149959, w2: 1.4733804105176649, bias: -2.995354299136234, loss: 0.43963853921000073\n",
      "epoche: 314, w1: 5.043727823087695, w2: 1.4737441300294107, bias: -2.9997635741607693, loss: 0.439392653584603\n",
      "epoche: 315, w1: 5.05385933646252, w2: 1.4741072943276134, bias: -3.0041647690319757, loss: 0.4391476755065195\n",
      "epoche: 316, w1: 5.063972125295972, w2: 1.4744699196862128, bias: -3.008557915516371, loss: 0.4389036009260591\n",
      "epoche: 317, w1: 5.074066233552292, w2: 1.4748320220637807, bias: -3.0129430450946657, loss: 0.43866042581447645\n",
      "epoche: 318, w1: 5.084141705137375, w2: 1.4751936171088047, bias: -3.0173201889656602, loss: 0.43841814616384156\n",
      "epoche: 319, w1: 5.094198583897743, w2: 1.475554720164884, bias: -3.0216893780500786, loss: 0.438176757986913\n",
      "epoche: 320, w1: 5.104236913619545, w2: 1.4759153462758423, bias: -3.0260506429943432, loss: 0.4379362573170104\n",
      "epoche: 321, w1: 5.114256738027572, w2: 1.4762755101907572, bias: -3.030404014174291, loss: 0.43769664020788873\n",
      "epoche: 322, w1: 5.124258100784298, w2: 1.4766352263689055, bias: -3.0347495216988323, loss: 0.43745790273361457\n",
      "epoche: 323, w1: 5.134241045488941, w2: 1.476994508984631, bias: -3.039087195413554, loss: 0.43722004098844186\n",
      "epoche: 324, w1: 5.144205615676537, w2: 1.47735337193213, bias: -3.043417064904266, loss: 0.436983051086691\n",
      "epoche: 325, w1: 5.154151854817045, w2: 1.4777118288301603, bias: -3.0477391595004892, loss: 0.43674692916262675\n",
      "epoche: 326, w1: 5.164079806314466, w2: 1.4780698930266742, bias: -3.0520535082788993, loss: 0.4365116713703391\n",
      "epoche: 327, w1: 5.17398951350598, w2: 1.478427577603374, bias: -3.056360140066706, loss: 0.436277273883624\n",
      "epoche: 328, w1: 5.183881019661104, w2: 1.4787848953801943, bias: -3.0606590834449876, loss: 0.43604373289586584\n",
      "epoche: 329, w1: 5.193754367980872, w2: 1.4791418589197125, bias: -3.064950366751973, loss: 0.4358110446199205\n",
      "epoche: 330, w1: 5.203609601597026, w2: 1.4794984805314848, bias: -3.0692340180862696, loss: 0.4355792052879999\n",
      "epoche: 331, w1: 5.213446763571231, w2: 1.4798547722763145, bias: -3.073510065310047, loss: 0.43534821115155725\n",
      "epoche: 332, w1: 5.2232658968943095, w2: 1.4802107459704483, bias: -3.077778536052167, loss: 0.4351180584811726\n",
      "epoche: 333, w1: 5.233067044485485, w2: 1.4805664131897063, bias: -3.082039457711269, loss: 0.43488874356644136\n",
      "epoche: 334, w1: 5.242850249191651, w2: 1.4809217852735432, bias: -3.0862928574588047, loss: 0.43466026271586145\n",
      "epoche: 335, w1: 5.252615553786656, w2: 1.4812768733290453, bias: -3.09053876224203, loss: 0.43443261225672253\n",
      "epoche: 336, w1: 5.262363000970601, w2: 1.4816316882348601, bias: -3.094777198786949, loss: 0.4342057885349965\n",
      "epoche: 337, w1: 5.272092633369156, w2: 1.481986240645064, bias: -3.0990081936012115, loss: 0.4339797879152281\n",
      "epoche: 338, w1: 5.281804493532896, w2: 1.4823405409929655, bias: -3.103231772976971, loss: 0.43375460678042616\n",
      "epoche: 339, w1: 5.291498623936645, w2: 1.482694599494849, bias: -3.1074479629936933, loss: 0.4335302415319576\n",
      "epoche: 340, w1: 5.301175066978848, w2: 1.4830484261536545, bias: -3.111656789520927, loss: 0.43330668858943966\n",
      "epoche: 341, w1: 5.3108338649809435, w2: 1.4834020307625997, bias: -3.1158582782210273, loss: 0.43308394439063463\n",
      "epoche: 342, w1: 5.320475060186763, w2: 1.4837554229087426, bias: -3.120052454551844, loss: 0.4328620053913454\n",
      "epoche: 343, w1: 5.330098694761943, w2: 1.4841086119764864, bias: -3.124239343769362, loss: 0.43264086806531116\n",
      "epoche: 344, w1: 5.339704810793344, w2: 1.4844616071510264, bias: -3.128418970930308, loss: 0.432420528904104\n",
      "epoche: 345, w1: 5.349293450288498, w2: 1.4848144174217426, bias: -3.132591360894713, loss: 0.432200984417027\n",
      "epoche: 346, w1: 5.358864655175059, w2: 1.4851670515855362, bias: -3.1367565383284375, loss: 0.43198223113101214\n",
      "epoche: 347, w1: 5.368418467300267, w2: 1.4855195182501113, bias: -3.14091452770566, loss: 0.4317642655905197\n",
      "epoche: 348, w1: 5.377954928430439, w2: 1.4858718258372048, bias: -3.145065353311324, loss: 0.43154708435743805\n",
      "epoche: 349, w1: 5.387474080250458, w2: 1.4862239825857622, bias: -3.1492090392435523, loss: 0.4313306840109841\n",
      "epoche: 350, w1: 5.396975964363283, w2: 1.4865759965550627, bias: -3.1533456094160224, loss: 0.4311150611476053\n",
      "epoche: 351, w1: 5.406460622289472, w2: 1.486927875627794, bias: -3.1574750875603055, loss: 0.43090021238088067\n",
      "epoche: 352, w1: 5.415928095466721, w2: 1.4872796275130755, bias: -3.1615974972281724, loss: 0.4306861343414245\n",
      "epoche: 353, w1: 5.425378425249403, w2: 1.4876312597494346, bias: -3.165712861793862, loss: 0.4304728236767898\n",
      "epoche: 354, w1: 5.434811652908137, w2: 1.487982779707732, bias: -3.1698212044563188, loss: 0.4302602770513713\n",
      "epoche: 355, w1: 5.444227819629357, w2: 1.488334194594043, bias: -3.173922548241393, loss: 0.43004849114631266\n",
      "epoche: 356, w1: 5.453626966514898, w2: 1.4886855114524875, bias: -3.178016916004011, loss: 0.4298374626594092\n",
      "epoche: 357, w1: 5.4630091345815925, w2: 1.4890367371680187, bias: -3.182104330430312, loss: 0.42962718830501645\n",
      "epoche: 358, w1: 5.47237436476088, w2: 1.4893878784691625, bias: -3.18618481403975, loss: 0.4294176648139557\n",
      "epoche: 359, w1: 5.481722697898426, w2: 1.4897389419307154, bias: -3.190258389187171, loss: 0.42920888893342196\n",
      "epoche: 360, w1: 5.491054174753755, w2: 1.4900899339763969, bias: -3.1943250780648498, loss: 0.4290008574268918\n",
      "epoche: 361, w1: 5.500368835999893, w2: 1.4904408608814588, bias: -3.1983849027045053, loss: 0.428793567074033\n",
      "epoche: 362, w1: 5.509666722223023, w2: 1.4907917287752535, bias: -3.202437884979279, loss: 0.42858701467061283\n",
      "epoche: 363, w1: 5.518947873922146, w2: 1.4911425436437586, bias: -3.2064840466056888, loss: 0.4283811970284087\n",
      "epoche: 364, w1: 5.52821233150876, w2: 1.4914933113320625, bias: -3.21052340914555, loss: 0.42817611097511893\n",
      "epoche: 365, w1: 5.537460135306544, w2: 1.491844037546808, bias: -3.2145559940078705, loss: 0.42797175335427334\n",
      "epoche: 366, w1: 5.546691325551055, w2: 1.492194727858597, bias: -3.218581822450715, loss: 0.4277681210251461\n",
      "epoche: 367, w1: 5.555905942389432, w2: 1.4925453877043557, bias: -3.2226009155830444, loss: 0.4275652108626666\n",
      "epoche: 368, w1: 5.565104025880119, w2: 1.4928960223896621, bias: -3.226613294366526, loss: 0.4273630197573345\n",
      "epoche: 369, w1: 5.574285615992582, w2: 1.4932466370910347, bias: -3.2306189796173186, loss: 0.4271615446151313\n",
      "epoche: 370, w1: 5.5834507526070505, w2: 1.4935972368581847, bias: -3.234617992007826, loss: 0.42696078235743595\n",
      "epoche: 371, w1: 5.592599475514262, w2: 1.4939478266162316, bias: -3.2386103520684344, loss: 0.4267607299209387\n",
      "epoche: 372, w1: 5.601731824415214, w2: 1.494298411167882, bias: -3.2425960801892124, loss: 0.4265613842575568\n",
      "epoche: 373, w1: 5.610847838920933, w2: 1.4946489951955741, bias: -3.246575196621596, loss: 0.42636274233434984\n",
      "epoche: 374, w1: 5.619947558552241, w2: 1.4949995832635863, bias: -3.250547721480041, loss: 0.42616480113343697\n",
      "epoche: 375, w1: 5.629031022739539, w2: 1.495350179820112, bias: -3.254513674743658, loss: 0.4259675576519125\n",
      "epoche: 376, w1: 5.638098270822599, w2: 1.495700789199301, bias: -3.2584730762578165, loss: 0.4257710089017649\n",
      "epoche: 377, w1: 5.647149342050364, w2: 1.496051415623267, bias: -3.2624259457357305, loss: 0.425575151909793\n",
      "epoche: 378, w1: 5.656184275580749, w2: 1.4964020632040627, bias: -3.266372302760018, loss: 0.4253799837175261\n",
      "epoche: 379, w1: 5.665203110480464, w2: 1.4967527359456227, bias: -3.27031216678424, loss: 0.42518550138114175\n",
      "epoche: 380, w1: 5.674205885724832, w2: 1.4971034377456758, bias: -3.274245557134414, loss: 0.42499170197138586\n",
      "epoche: 381, w1: 5.683192640197624, w2: 1.497454172397624, bias: -3.2781724930105067, loss: 0.42479858257349257\n",
      "epoche: 382, w1: 5.692163412690896, w2: 1.4978049435923928, bias: -3.282092993487908, loss: 0.42460614028710486\n",
      "epoche: 383, w1: 5.70111824190484, w2: 1.4981557549202509, bias: -3.2860070775188763, loss: 0.4244143722261949\n",
      "epoche: 384, w1: 5.710057166447633, w2: 1.4985066098725999, bias: -3.28991476393397, loss: 0.4242232755189867\n",
      "epoche: 385, w1: 5.718980224835306, w2: 1.4988575118437348, bias: -3.293816071443453, loss: 0.42403284730787705\n",
      "epoche: 386, w1: 5.727887455491607, w2: 1.4992084641325767, bias: -3.2977110186386835, loss: 0.4238430847493584\n",
      "epoche: 387, w1: 5.736778896747882, w2: 1.4995594699443762, bias: -3.3015996239934804, loss: 0.42365398501394197\n",
      "epoche: 388, w1: 5.74565458684296, w2: 1.4999105323923894, bias: -3.305481905865469, loss: 0.4234655452860806\n",
      "epoche: 389, w1: 5.754514563923038, w2: 1.500261654499527, bias: -3.3093578824974106, loss: 0.42327776276409346\n",
      "epoche: 390, w1: 5.763358866041586, w2: 1.5006128391999767, bias: -3.313227572018509, loss: 0.4230906346600896\n",
      "epoche: 391, w1: 5.772187531159246, w2: 1.5009640893407967, bias: -3.3170909924457, loss: 0.4229041581998928\n",
      "epoche: 392, w1: 5.781000597143745, w2: 1.5013154076834876, bias: -3.320948161684924, loss: 0.42271833062296765\n",
      "epoche: 393, w1: 5.789798101769813, w2: 1.5016667969055342, bias: -3.324799097532376, loss: 0.4225331491823444\n",
      "epoche: 394, w1: 5.7985800827191065, w2: 1.5020182596019251, bias: -3.3286438176757405, loss: 0.42234861114454564\n",
      "epoche: 395, w1: 5.807346577580137, w2: 1.5023697982866464, bias: -3.3324823396954084, loss: 0.42216471378951254\n",
      "epoche: 396, w1: 5.8160976238482105, w2: 1.502721415394151, bias: -3.3363146810656765, loss: 0.4219814544105319\n",
      "epoche: 397, w1: 5.824833258925366, w2: 1.503073113280804, bias: -3.3401408591559276, loss: 0.42179883031416404\n",
      "epoche: 398, w1: 5.833553520120329, w2: 1.5034248942263042, bias: -3.3439608912317964, loss: 0.4216168388201706\n",
      "epoche: 399, w1: 5.8422584446484604, w2: 1.5037767604350833, bias: -3.3477747944563174, loss: 0.4214354772614425\n",
      "epoche: 400, w1: 5.850948069631719, w2: 1.5041287140376813, bias: -3.351582585891057, loss: 0.42125474298392895\n",
      "epoche: 401, w1: 5.859622432098625, w2: 1.5044807570920993, bias: -3.355384282497228, loss: 0.4210746333465671\n",
      "epoche: 402, w1: 5.868281568984236, w2: 1.504832891585131, bias: -3.35917990113679, loss: 0.4208951457212106\n",
      "epoche: 403, w1: 5.8769255171301165, w2: 1.505185119433672, bias: -3.3629694585735335, loss: 0.4207162774925612\n",
      "epoche: 404, w1: 5.885554313284325, w2: 1.5055374424860077, bias: -3.366752971474146, loss: 0.42053802605809754\n",
      "epoche: 405, w1: 5.894167994101397, w2: 1.5058898625230794, bias: -3.370530456409268, loss: 0.420360388828007\n",
      "epoche: 406, w1: 5.902766596142342, w2: 1.5062423812597312, bias: -3.374301929854531, loss: 0.42018336322511685\n",
      "epoche: 407, w1: 5.911350155874636, w2: 1.5065950003459347, bias: -3.37806740819158, loss: 0.4200069466848258\n",
      "epoche: 408, w1: 5.919918709672226, w2: 1.5069477213679954, bias: -3.381826907709081, loss: 0.41983113665503596\n",
      "epoche: 409, w1: 5.928472293815536, w2: 1.5073005458497377, bias: -3.38558044460372, loss: 0.4196559305960858\n",
      "epoche: 410, w1: 5.937010944491479, w2: 1.5076534752536714, bias: -3.3893280349811805, loss: 0.4194813259806825\n",
      "epoche: 411, w1: 5.945534697793475, w2: 1.5080065109821392, bias: -3.3930696948571106, loss: 0.4193073202938352\n",
      "epoche: 412, w1: 5.95404358972147, w2: 1.5083596543784443, bias: -3.396805440158077, loss: 0.4191339110327892\n",
      "epoche: 413, w1: 5.962537656181962, w2: 1.5087129067279608, bias: -3.4005352867225054, loss: 0.4189610957069593\n",
      "epoche: 414, w1: 5.971016932988032, w2: 1.5090662692592245, bias: -3.4042592503016054, loss: 0.41878887183786506\n",
      "epoche: 415, w1: 5.979481455859378, w2: 1.5094197431450076, bias: -3.407977346560285, loss: 0.41861723695906494\n",
      "epoche: 416, w1: 5.987931260422351, w2: 1.5097733295033733, bias: -3.4116895910780527, loss: 0.41844618861609134\n",
      "epoche: 417, w1: 5.9963663822100015, w2: 1.5101270293987155, bias: -3.4153959993499035, loss: 0.41827572436638694\n",
      "epoche: 418, w1: 6.004786856662125, w2: 1.5104808438427793, bias: -3.419096586787196, loss: 0.4181058417792403\n",
      "epoche: 419, w1: 6.013192719125314, w2: 1.5108347737956667, bias: -3.4227913687185154, loss: 0.4179365384357215\n",
      "epoche: 420, w1: 6.021584004853009, w2: 1.5111888201668235, bias: -3.4264803603905256, loss: 0.4177678119286198\n",
      "epoche: 421, w1: 6.0299607490055624, w2: 1.5115429838160122, bias: -3.430163576968809, loss: 0.41759965986238023\n",
      "epoche: 422, w1: 6.038322986650297, w2: 1.5118972655542666, bias: -3.4338410335386937, loss: 0.4174320798530409\n",
      "epoche: 423, w1: 6.0466707527615755, w2: 1.512251666144833, bias: -3.437512745106071, loss: 0.41726506952817116\n",
      "epoche: 424, w1: 6.055004082220868, w2: 1.512606186304094, bias: -3.4411787265981997, loss: 0.417098626526809\n",
      "epoche: 425, w1: 6.063323009816826, w2: 1.5129608267024777, bias: -3.444838992864501, loss: 0.41693274849940043\n",
      "epoche: 426, w1: 6.071627570245361, w2: 1.513315587965352, bias: -3.4484935586773418, loss: 0.4167674331077376\n",
      "epoche: 427, w1: 6.079917798109722, w2: 1.513670470673904, bias: -3.452142438732806, loss: 0.4166026780248983\n",
      "epoche: 428, w1: 6.088193727920585, w2: 1.5140254753660047, bias: -3.455785647651457, loss: 0.41643848093518565\n",
      "epoche: 429, w1: 6.096455394096132, w2: 1.51438060253706, bias: -3.459423199979089, loss: 0.4162748395340675\n",
      "epoche: 430, w1: 6.10470283096215, w2: 1.5147358526408468, bias: -3.4630551101874674, loss: 0.4161117515281168\n",
      "epoche: 431, w1: 6.1129360727521185, w2: 1.515091226090335, bias: -3.4666813926750604, loss: 0.4159492146349528\n",
      "epoche: 432, w1: 6.121155153607309, w2: 1.5154467232584976, bias: -3.4703020617677587, loss: 0.4157872265831809\n",
      "epoche: 433, w1: 6.1293601075768835, w2: 1.5158023444791053, bias: -3.473917131719588, loss: 0.4156257851123348\n",
      "epoche: 434, w1: 6.137550968617999, w2: 1.5161580900475091, bias: -3.4775266167134085, loss: 0.41546488797281755\n",
      "epoche: 435, w1: 6.145727770595912, w2: 1.51651396022141, bias: -3.4811305308616083, loss: 0.41530453292584374\n",
      "epoche: 436, w1: 6.153890547284088, w2: 1.5168699552216145, bias: -3.4847288882067846, loss: 0.4151447177433813\n",
      "epoche: 437, w1: 6.162039332364311, w2: 1.51722607523278, bias: -3.4883217027224163, loss: 0.41498544020809497\n",
      "epoche: 438, w1: 6.170174159426802, w2: 1.517582320404145, bias: -3.4919089883135292, loss: 0.41482669811328793\n",
      "epoche: 439, w1: 6.17829506197033, w2: 1.517938690850249, bias: -3.495490758817351, loss: 0.41466848926284616\n",
      "epoche: 440, w1: 6.186402073402336, w2: 1.51829518665164, bias: -3.4990670280039557, loss: 0.414510811471182\n",
      "epoche: 441, w1: 6.194495227039054, w2: 1.5186518078555702, bias: -3.5026378095769033, loss: 0.4143536625631762\n",
      "epoche: 442, w1: 6.2025745561056365, w2: 1.5190085544766792, bias: -3.506203117173867, loss: 0.41419704037412475\n",
      "epoche: 443, w1: 6.210640093736279, w2: 1.5193654264976673, bias: -3.5097629643672534, loss: 0.41404094274968173\n",
      "epoche: 444, w1: 6.218691872974352, w2: 1.5197224238699565, bias: -3.513317364664817, loss: 0.4138853675458042\n",
      "epoche: 445, w1: 6.226729926772533, w2: 1.5200795465143406, bias: -3.5168663315102604, loss: 0.4137303126286979\n",
      "epoche: 446, w1: 6.23475428799294, w2: 1.5204367943216255, bias: -3.520409878283833, loss: 0.4135757758747625\n",
      "epoche: 447, w1: 6.24276498940727, w2: 1.520794167153256, bias: -3.523948018302918, loss: 0.413421755170537\n",
      "epoche: 448, w1: 6.250762063696933, w2: 1.5211516648419356, bias: -3.527480764822612, loss: 0.4132682484126463\n",
      "epoche: 449, w1: 6.258745543453199, w2: 1.5215092871922336, bias: -3.5310081310362977, loss: 0.4131152535077473\n",
      "epoche: 450, w1: 6.266715461177338, w2: 1.5218670339811822, bias: -3.5345301300762086, loss: 0.41296276837247564\n",
      "epoche: 451, w1: 6.274671849280764, w2: 1.5222249049588648, bias: -3.5380467750139863, loss: 0.4128107909333923\n",
      "epoche: 452, w1: 6.282614740085187, w2: 1.5225828998489928, bias: -3.54155807886123, loss: 0.41265931912693177\n",
      "epoche: 453, w1: 6.290544165822757, w2: 1.5229410183494743, bias: -3.545064054570041, loss: 0.4125083508993485\n",
      "epoche: 454, w1: 6.298460158636219, w2: 1.5232992601329716, bias: -3.5485647150335544, loss: 0.41235788420666564\n",
      "epoche: 455, w1: 6.306362750579065, w2: 1.5236576248474507, bias: -3.552060073086471, loss: 0.4122079170146228\n",
      "epoche: 456, w1: 6.314251973615687, w2: 1.5240161121167204, bias: -3.555550141505578, loss: 0.41205844729862445\n",
      "epoche: 457, w1: 6.3221278596215384, w2: 1.524374721540963, bias: -3.5590349330102633, loss: 0.4119094730436892\n",
      "epoche: 458, w1: 6.329990440383288, w2: 1.5247334526972565, bias: -3.5625144602630225, loss: 0.41176099224439777\n",
      "epoche: 459, w1: 6.337839747598982, w2: 1.525092305140086, bias: -3.5659887358699622, loss: 0.4116130029048436\n",
      "epoche: 460, w1: 6.345675812878207, w2: 1.5254512784018486, bias: -3.5694577723812935, loss: 0.41146550303858137\n",
      "epoche: 461, w1: 6.3534986677422545, w2: 1.525810371993349, bias: -3.5729215822918206, loss: 0.4113184906685779\n",
      "epoche: 462, w1: 6.361308343624283, w2: 1.5261695854042858, bias: -3.5763801780414233, loss: 0.4111719638271611\n",
      "epoche: 463, w1: 6.369104871869486, w2: 1.5265289181037314, bias: -3.5798335720155325, loss: 0.41102592055597137\n",
      "epoche: 464, w1: 6.376888283735263, w2: 1.5268883695406013, bias: -3.5832817765456, loss: 0.41088035890591207\n",
      "epoche: 465, w1: 6.384658610391386, w2: 1.5272479391441176, bias: -3.5867248039095623, loss: 0.41073527693710066\n",
      "epoche: 466, w1: 6.392415882920174, w2: 1.527607626324264, bias: -3.5901626663322967, loss: 0.4105906727188196\n",
      "epoche: 467, w1: 6.400160132316663, w2: 1.5279674304722317, bias: -3.5935953759860753, loss: 0.4104465443294683\n",
      "epoche: 468, w1: 6.407891389488782, w2: 1.52832735096086, bias: -3.5970229449910103, loss: 0.41030288985651486\n",
      "epoche: 469, w1: 6.415609685257528, w2: 1.528687387145067, bias: -3.6004453854154934, loss: 0.41015970739644814\n",
      "epoche: 470, w1: 6.423315050357144, w2: 1.5290475383622752, bias: -3.603862709276631, loss: 0.4100169950547296\n",
      "epoche: 471, w1: 6.431007515435295, w2: 1.5294078039328274, bias: -3.6072749285406744, loss: 0.4098747509457475\n",
      "epoche: 472, w1: 6.438687111053248, w2: 1.5297681831603978, bias: -3.6106820551234415, loss: 0.40973297319276764\n",
      "epoche: 473, w1: 6.446353867686057, w2: 1.5301286753323944, bias: -3.6140841008907363, loss: 0.40959165992788854\n",
      "epoche: 474, w1: 6.454007815722736, w2: 1.530489279720355, bias: -3.6174810776587623, loss: 0.4094508092919936\n",
      "epoche: 475, w1: 6.461648985466452, w2: 1.5308499955803374, bias: -3.6208729971945295, loss: 0.40931041943470536\n",
      "epoche: 476, w1: 6.469277407134701, w2: 1.5312108221533003, bias: -3.6242598712162573, loss: 0.4091704885143392\n",
      "epoche: 477, w1: 6.476893110859499, w2: 1.5315717586654807, bias: -3.627641711393772, loss: 0.4090310146978577\n",
      "epoche: 478, w1: 6.4844961266875645, w2: 1.531932804328762, bias: -3.6310185293489003, loss: 0.40889199616082517\n",
      "epoche: 479, w1: 6.492086484580508, w2: 1.5322939583410387, bias: -3.634390336655856, loss: 0.4087534310873621\n",
      "epoche: 480, w1: 6.499664214415019, w2: 1.532655219886571, bias: -3.6377571448416224, loss: 0.4086153176701008\n",
      "epoche: 481, w1: 6.507229345983058, w2: 1.5330165881363376, bias: -3.6411189653863323, loss: 0.40847765411013964\n",
      "epoche: 482, w1: 6.514781908992042, w2: 1.5333780622483781, bias: -3.6444758097236396, loss: 0.4083404386169994\n",
      "epoche: 483, w1: 6.522321933065038, w2: 1.5337396413681335, bias: -3.6478276892410895, loss: 0.40820366940857855\n",
      "epoche: 484, w1: 6.52984944774096, w2: 1.534101324628777, bias: -3.651174615280482, loss: 0.4080673447111098\n",
      "epoche: 485, w1: 6.537364482474753, w2: 1.5344631111515414, bias: -3.6545165991382307, loss: 0.40793146275911535\n",
      "epoche: 486, w1: 6.544867066637592, w2: 1.534825000046041, bias: -3.6578536520657203, loss: 0.40779602179536417\n",
      "epoche: 487, w1: 6.552357229517078, w2: 1.5351869904105861, bias: -3.6611857852696557, loss: 0.4076610200708289\n",
      "epoche: 488, w1: 6.559835000317428, w2: 1.5355490813324928, bias: -3.6645130099124095, loss: 0.40752645584464187\n",
      "epoche: 489, w1: 6.567300408159678, w2: 1.5359112718883883, bias: -3.6678353371123635, loss: 0.40739232738405295\n",
      "epoche: 490, w1: 6.5747534820818725, w2: 1.5362735611445093, bias: -3.6711527779442483, loss: 0.4072586329643874\n",
      "epoche: 491, w1: 6.582194251039268, w2: 1.5366359481569964, bias: -3.674465343439476, loss: 0.4071253708690027\n",
      "epoche: 492, w1: 6.5896227439045285, w2: 1.5369984319721828, bias: -3.6777730445864716, loss: 0.40699253938924673\n",
      "epoche: 493, w1: 6.597038989467926, w2: 1.5373610116268774, bias: -3.6810758923309974, loss: 0.4068601368244164\n",
      "epoche: 494, w1: 6.6044430164375365, w2: 1.5377236861486439, bias: -3.6843738975764775, loss: 0.40672816148171564\n",
      "epoche: 495, w1: 6.611834853439445, w2: 1.5380864545560742, bias: -3.6876670711843134, loss: 0.40659661167621397\n",
      "epoche: 496, w1: 6.6192145290179445, w2: 1.5384493158590575, bias: -3.6909554239742, loss: 0.4064654857308056\n",
      "epoche: 497, w1: 6.626582071635735, w2: 1.538812269059044, bias: -3.6942389667244355, loss: 0.40633478197616846\n",
      "epoche: 498, w1: 6.633937509674128, w2: 1.5391753131493042, bias: -3.6975177101722294, loss: 0.40620449875072356\n",
      "epoche: 499, w1: 6.641280871433249, w2: 1.5395384471151843, bias: -3.700791665014005, loss: 0.4060746344005942\n",
      "epoche: 500, w1: 6.648612185132239, w2: 1.5399016699343555, bias: -3.704060841905698, loss: 0.40594518727956647\n",
      "epoche: 501, w1: 6.655931478909459, w2: 1.5402649805770603, bias: -3.7073252514630552, loss: 0.40581615574904806\n",
      "epoche: 502, w1: 6.663238780822692, w2: 1.5406283780063534, bias: -3.7105849042619248, loss: 0.4056875381780301\n",
      "epoche: 503, w1: 6.670534118849351, w2: 1.5409918611783389, bias: -3.713839810838546, loss: 0.4055593329430463\n",
      "epoche: 504, w1: 6.6778175208866815, w2: 1.541355429042403, bias: -3.717089981689836, loss: 0.40543153842813406\n",
      "epoche: 505, w1: 6.6850890147519655, w2: 1.5417190805414422, bias: -3.720335427273671, loss: 0.40530415302479555\n",
      "epoche: 506, w1: 6.692348628182729, w2: 1.5420828146120886, bias: -3.7235761580091657, loss: 0.40517717513195844\n",
      "epoche: 507, w1: 6.699596388836947, w2: 1.542446630184929, bias: -3.726812184276949, loss: 0.40505060315593766\n",
      "epoche: 508, w1: 6.706832324293252, w2: 1.5428105261847216, bias: -3.730043516419437, loss: 0.40492443551039653\n",
      "epoche: 509, w1: 6.714056462051136, w2: 1.5431745015306093, bias: -3.7332701647411026, loss: 0.40479867061630886\n",
      "epoche: 510, w1: 6.721268829531163, w2: 1.5435385551363272, bias: -3.7364921395087403, loss: 0.4046733069019206\n",
      "epoche: 511, w1: 6.728469454075171, w2: 1.5439026859104077, bias: -3.7397094509517315, loss: 0.4045483428027125\n",
      "epoche: 512, w1: 6.735658362946483, w2: 1.5442668927563814, bias: -3.7429221092623033, loss: 0.4044237767613619\n",
      "epoche: 513, w1: 6.742835583330113, w2: 1.5446311745729748, bias: -3.7461301245957865, loss: 0.40429960722770586\n",
      "epoche: 514, w1: 6.750001142332976, w2: 1.5449955302543037, bias: -3.7493335070708693, loss: 0.4041758326587037\n",
      "epoche: 515, w1: 6.757155066984095, w2: 1.5453599586900633, bias: -3.7525322667698484, loss: 0.40405245151840036\n",
      "epoche: 516, w1: 6.764297384234808, w2: 1.5457244587657146, bias: -3.755726413738879, loss: 0.40392946227788895\n",
      "epoche: 517, w1: 6.771428120958982, w2: 1.5460890293626686, bias: -3.758915957988218, loss: 0.4038068634152747\n",
      "epoche: 518, w1: 6.7785473039532125, w2: 1.5464536693584647, bias: -3.76210090949247, loss: 0.40368465341563914\n",
      "epoche: 519, w1: 6.785654959937043, w2: 1.5468183776269484, bias: -3.765281278190825, loss: 0.40356283077100263\n",
      "epoche: 520, w1: 6.792751115553166, w2: 1.5471831530384437, bias: -3.768457073987296, loss: 0.40344139398028933\n",
      "epoche: 521, w1: 6.799835797367638, w2: 1.5475479944599233, bias: -3.771628306750955, loss: 0.40332034154929136\n",
      "epoche: 522, w1: 6.806909031870086, w2: 1.5479129007551753, bias: -3.7747949863161647, loss: 0.40319967199063317\n",
      "epoche: 523, w1: 6.813970845473917, w2: 1.5482778707849671, bias: -3.7779571224828072, loss: 0.4030793838237356\n",
      "epoche: 524, w1: 6.821021264516529, w2: 1.548642903407206, bias: -3.7811147250165122, loss: 0.4029594755747824\n",
      "epoche: 525, w1: 6.828060315259519, w2: 1.5490079974770963, bias: -3.7842678036488806, loss: 0.402839945776683\n",
      "epoche: 526, w1: 6.835088023888895, w2: 1.5493731518472942, bias: -3.787416368077707, loss: 0.4027207929690396\n",
      "epoche: 527, w1: 6.842104416515285, w2: 1.5497383653680594, bias: -3.7905604279671987, loss: 0.40260201569811166\n",
      "epoche: 528, w1: 6.849109519174148, w2: 1.5501036368874042, bias: -3.7936999929481936, loss: 0.4024836125167818\n",
      "epoche: 529, w1: 6.856103357825979, w2: 1.5504689652512385, bias: -3.796835072618374, loss: 0.4023655819845216\n",
      "epoche: 530, w1: 6.863085958356525, w2: 1.5508343493035144, bias: -3.79996567654248, loss: 0.4022479226673578\n",
      "epoche: 531, w1: 6.870057346576993, w2: 1.5511997878863653, bias: -3.803091814252518, loss: 0.40213063313783776\n",
      "epoche: 532, w1: 6.87701754822426, w2: 1.5515652798402444, bias: -3.806213495247971, loss: 0.40201371197499725\n",
      "epoche: 533, w1: 6.883966588961082, w2: 1.5519308240040597, bias: -3.8093307289960014, loss: 0.4018971577643253\n",
      "epoche: 534, w1: 6.890904494376304, w2: 1.552296419215306, bias: -3.8124435249316564, loss: 0.4017809690977324\n",
      "epoche: 535, w1: 6.897831289985072, w2: 1.552662064310195, bias: -3.815551892458068, loss: 0.40166514457351654\n",
      "epoche: 536, w1: 6.9047470012290395, w2: 1.5530277581237835, bias: -3.818655840946652, loss: 0.4015496827963311\n",
      "epoche: 537, w1: 6.911651653476581, w2: 1.553393499490097, bias: -3.8217553797373056, loss: 0.4014345823771512\n",
      "epoche: 538, w1: 6.918545272022999, w2: 1.5537592872422532, bias: -3.8248505181386014, loss: 0.4013198419332423\n",
      "epoche: 539, w1: 6.925427882090735, w2: 1.5541251202125814, bias: -3.82794126542798, loss: 0.40120546008812685\n",
      "epoche: 540, w1: 6.932299508829577, w2: 1.5544909972327405, bias: -3.8310276308519415, loss: 0.40109143547155307\n",
      "epoche: 541, w1: 6.939160177316873, w2: 1.5548569171338344, bias: -3.8341096236262335, loss: 0.400977766719462\n",
      "epoche: 542, w1: 6.946009912557738, w2: 1.555222878746525, bias: -3.837187252936037, loss: 0.40086445247395674\n",
      "epoche: 543, w1: 6.952848739485261, w2: 1.5555888809011431, bias: -3.840260527936153, loss: 0.4007514913832703\n",
      "epoche: 544, w1: 6.959676682960717, w2: 1.5559549224277973, bias: -3.843329457751183, loss: 0.4006388821017339\n",
      "epoche: 545, w1: 6.966493767773776, w2: 1.5563210021564797, bias: -3.8463940514757113, loss: 0.40052662328974625\n",
      "epoche: 546, w1: 6.9733000186427105, w2: 1.5566871189171714, bias: -3.849454318174484, loss: 0.40041471361374253\n",
      "epoche: 547, w1: 6.980095460214605, w2: 1.5570532715399432, bias: -3.8525102668825846, loss: 0.4003031517461628\n",
      "epoche: 548, w1: 6.986880117065563, w2: 1.5574194588550574, bias: -3.855561906605611, loss: 0.40019193636542205\n",
      "epoche: 549, w1: 6.993654013700917, w2: 1.5577856796930647, bias: -3.858609246319848, loss: 0.40008106615587885\n",
      "epoche: 550, w1: 7.000417174555437, w2: 1.558151932884901, bias: -3.8616522949724397, loss: 0.3999705398078057\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7.000417174555437, 1.558151932884901, -3.8616522949724397)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradienten_abstieg(X['age'], X['affordibility'], y.to_numpy(), epochs=2500, loss_thr=0.4, lr=0.5) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3710ddfa-9539-4870-b9a0-5f01c11e3d3c",
   "metadata": {},
   "source": [
    "Damit kann jetzt eine Klasse erstellt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "619e18c6-e81b-4e38-b559-4b47a911005c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Einfaches Netz\n",
    "# - Angepasst für den Versuch.\n",
    "class my_nn():\n",
    "    def __init__(self):\n",
    "        self.w1 = 1\n",
    "        self.w2 = 1\n",
    "        self.bias  = 0\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Wie oben: Summe und dann Funktion anwenden.\n",
    "        weight_sum = (self.w1 * X_test['age'] + self.w2 * X_test['affordibility'] + self.bias)  \n",
    "        return sigmoid_funk(weight_sum)\n",
    "\n",
    "    def fit(self, X, y, epochs):\n",
    "        self.w1, self.w2, self.bias = self.gradienten_abstieg( X['age'], X['affordibility'], y, epochs)\n",
    "\n",
    "        \n",
    "    def gradienten_abstieg(self, age, afford, y_true, epochs, loss_thr:float=2.0, lr:float=0.01):\n",
    "        w1   = w2 = 1  # Random, meist mit 1. \n",
    "        bias = 0  # Meist mit 0 \n",
    "        n = len(afford) \n",
    "        for i in range(int(epochs)):   \n",
    "            weight_sum = self.w1 * age + self.w2 * afford + self.bias  # Vektor Operation.\n",
    "            y_pred = sigmoid_funk(weight_sum)  # Aktivierungsfunktion.\n",
    "            loss = logloss(y_pred, y_true)\n",
    "            w1d =  (1/n) * np.dot(np.transpose(age) ,    (y_pred-y_true))           \n",
    "            w2d =  (1/n) * np.dot(np.transpose(afford) , (y_pred-y_true)) \n",
    "            bias_d = np.mean(y_pred-y_true)\n",
    "            self.w1 = self.w1 - lr * w1d  # Formel von Oben.\n",
    "            self.w2 = self.w2 - lr * w2d  # - Hier werden die Gewichte angepasst - Die ganze Magie dahinter. \n",
    "            self.bias = self.bias - lr *bias_d\n",
    "\n",
    "            if i%100==0:\n",
    "                print(f\"epoche: {i}, w1: {self.w1}, w2: {self.w2}, bias: {self.bias}, loss: {loss}\")\n",
    "            \n",
    "        return self.w1, self.w2, self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4041db16-143d-4324-81cb-86198143fb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoche: 0, w1: 0.9995256991514374, w2: 0.9988276331757626, bias: -0.0023446438289389552, loss: 0.71595572538616\n",
      "epoche: 100, w1: 0.9632313469977409, w2: 0.9008775541087021, bias: -0.20843013437288502, loss: 0.6619327284009086\n",
      "epoche: 200, w1: 0.9463485553759833, w2: 0.8370701880535407, bias: -0.3652806910274291, loss: 0.632575560887126\n",
      "epoche: 300, w1: 0.9444504004015485, w2: 0.7999211539363223, bias: -0.4842577485735926, loss: 0.6168202751035144\n",
      "epoche: 400, w1: 0.9534266271505314, w2: 0.7820864281235341, bias: -0.5757101431428063, loss: 0.6079502711195035\n"
     ]
    }
   ],
   "source": [
    "my_mdoel = my_nn()\n",
    "my_mdoel.fit(X, y, epochs=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c33db6-210c-41b6-ac85-637c14a9185b",
   "metadata": {},
   "source": [
    "<h1>Stochastik Gradient, Batch Gradient und Mini-Batch Gradient</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43cc84-f8aa-4a0d-9409-f084b4fd288f",
   "metadata": {},
   "source": [
    "Bei dem oberen Beispiel wurde alle Samples für das Training genutzt. Das war der Batch Gradientenabstieg.\n",
    "Nachteil ist, dass bei einem großen Dataset vorher durch alle Samples iteriert werden muss, bevor die Anpassung der Weights erfolg, das kann lange dauern.\n",
    "\n",
    "\n",
    "Bei dem stochastischen Gradientenabstieg (<b>SGD</b>) wird per Zufall ein Sample ausgewählt und dann Backpropagiert. Bei großen Datasets spart man Zeit, indem man jedes Sample nimmt und eine Anpassung durchführt, und nicht erst durch alle durchgeht. \n",
    "\n",
    "Bei dem Ansatz Mini-Batch Gradientenabstieg werden n-Batches genommen, die aus m-zufälligen Samples bestehen. Bei einem Dataset der Größe 100 und der Batch-Größe 20 gibt es 5 Batches die je aus 20 zufällig ausgewählten Samples bestehen. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c386c7-752f-4fa5-ad52-481504e2c7b0",
   "metadata": {},
   "source": [
    "<i>Abb5</i>: Batch, Mini-Batch und stochastischen Gradientenabstieg.\n",
    "\n",
    "<img src=\"./img/nn_8.PNG\" width=700 hight=500>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "462291cc-bc79-4939-bf80-89bd453c0811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Loss:\n",
    "# - Mit Numpy, von Oben\n",
    "def logloss(y_pred, y_true):\n",
    "    # Weil log(0) nicht definiert ist => Wert nah bei 0 nehmen.\n",
    "    eps = 1e-15\n",
    "    y_pred2 = max(y_pred, eps)   \n",
    "    y_pred2 = min(y_pred2, 1-eps) \n",
    "    y_pred2 = np.array(y_pred2)\n",
    "\n",
    "    return -np.mean(\\\n",
    "        y_true * np.log(y_pred2) + (1-y_true) * np.log(1 - y_pred2 ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fc004ef-e5db-4c18-ac77-a69211523dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD\n",
    "# - Wähle zufälliges Sample und führe Anpassung durch. \n",
    "def stochastik_gradienten_abstieg(X, y_true, epochs, loss_thr:float=2.0, lr:float=0.01):\n",
    "    w1   = w2 = 1   \n",
    "    bias = 0 \n",
    "    n = X.shape[0]  # Anzahl Einträge\n",
    "\n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "    \n",
    "    for i in range(epochs):\n",
    "        random_index = random.randint(0, n-1)  # Ziehe Sample. \n",
    "        \n",
    "        sample_x = X.iloc[random_index]  # Mit iloc auf Zeile zugreifen.\n",
    "        sample_y = y_true[random_index]\n",
    "\n",
    "        # Summe und Funktion\n",
    "        weight_sum = w1 * sample_x['age'] + w2 * sample_x['affordibility'] + bias\n",
    "        y_pred = sigmoid_funk(weight_sum)  # Aktivierungsfunktion. \n",
    "\n",
    "        loss = logloss(y_pred, sample_y)\n",
    "\n",
    "        w1d =  (1/n) * np.dot(np.transpose(sample_x['age']) ,           (y_pred-sample_y))           \n",
    "        w2d =  (1/n) * np.dot(np.transpose(sample_x['affordibility']) , (y_pred-sample_y)) \n",
    "        bias_d = np.mean(y_pred-y_true)\n",
    "\n",
    "        w1 = w1 - lr * w1d \n",
    "        w2 = w2 - lr * w2d  \n",
    "        bias = bias - lr * bias_d\n",
    "        \n",
    "        if i % 100 ==0:\n",
    "            cost_list.append(loss)\n",
    "            epoch_list.append(i)\n",
    "    return w1, w2, bias, loss, cost_list, epoch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "66b83803-1943-40e7-b2fc-08ae58c8185f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.7268264148118373, 1.4481113140464417, -1.9367194020479213)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2, bias, loss, cost_list, epoch_list = stochastik_gradienten_abstieg(X, y, 2500, loss_thr=0.4, lr=0.5)   \n",
    "w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ebaf7869-124d-4c1a-9adb-18d37971409f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2be6a72ee20>]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, cost_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6220800e-1510-46bb-ae95-df1f151f4c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "139b9b77-9c98-4c57-93cb-0fe9ef7968bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log-Loss:\n",
    "# - Mit Numpy\n",
    "def logloss(y_pred, y_true):\n",
    "    # Weil log(0) nicht definiert ist => Wert nah bei 0 nehmen.\n",
    "    eps = 1e-15\n",
    "    y_pred = [max(i, eps)    for i in y_pred ]\n",
    "    y_pred = [min(i, 1-eps)  for i in y_pred ]\n",
    "    y_pred = np.array(y_pred)\n",
    "\n",
    "    return -np.mean(\\\n",
    "        y_true * np.log(y_pred) + (1-y_true) * np.log(1 - y_pred ) )\n",
    "    \n",
    "# Mini-Batch Gradientenasbtieg. \n",
    "def mini_batch_gradienten_abstieg(X, y_true, epochs, batch_size:int=5, loss_thr:float=2.0, lr:float=0.01):\n",
    "    w1   = w2 = 1   \n",
    "    bias = 0 \n",
    "    n = X.shape[0]  # Anzahl Einträge\n",
    "    \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    # Wenn Batchgröße ist als n, dann nehme ganzes Dataset.\n",
    "    if batch_size > n: \n",
    "        batch_size = n\n",
    "        \n",
    "    cost_list = []\n",
    "    epoch_list = []\n",
    "\n",
    "    # Anzahl der Batches.\n",
    "    num_batches = int(n/batch_size)\n",
    "    \n",
    "    for i in range(epochs):  \n",
    "        \n",
    "        random_indices = np.random.permutation(n)  # Zufällige Ziehungenm. \n",
    "        X_samples = X.iloc[random_indices]      # X und y Ziehungen müssen mit dem Index passen. \n",
    "        y_samples = y_true[random_indices]\n",
    "        \n",
    "        for j in range(0, n ,batch_size):\n",
    "            \n",
    "            X_s = X_samples.iloc[j:j+batch_size]  # Batch mit Samples.\n",
    "            y_s = y_samples[j:j+batch_size]  # Batch mit Samples.\n",
    "            # Summe und Aktivierungsfunktion.\n",
    "            weight_sum = w1 * X_s['age'] + w2 * X_s['affordibility'] + bias\n",
    "            y_pred = sigmoid_funk(weight_sum)\n",
    "\n",
    "            loss = logloss(y_pred, y_s)\n",
    "                 \n",
    "            w1d =  (1/n) * np.dot(np.transpose(X_s['age']) ,           (y_pred-y_s))           \n",
    "            w2d =  (1/n) * np.dot(np.transpose(X_s['affordibility']) , (y_pred-y_s)) \n",
    "            bias_d = np.mean(y_pred-y_s)\n",
    "\n",
    "            w1 = w1 - lr * w1d \n",
    "            w2 = w2 - lr * w2d  \n",
    "            bias = bias - lr * bias_d\n",
    "                \n",
    "        if i%100==0:\n",
    "            cost_list.append(loss)\n",
    "            epoch_list.append(i)\n",
    "            print(f'loss: {loss}')\n",
    "        \n",
    "    return w1, w2, bias, loss, cost_list, epoch_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "78b855a7-5319-4c05-b327-358269d7e15e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.5976384799472111\n",
      "loss: 0.5183918244159663\n",
      "loss: 0.3636452023374849\n",
      "loss: 0.34279837859761964\n",
      "loss: 0.5041858669270558\n",
      "loss: 0.23461356552691118\n",
      "loss: 0.41957635194558673\n",
      "loss: 0.37672537877297446\n",
      "loss: 0.25204866605488685\n",
      "loss: 0.28402623454812936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8.065675382863366, 1.7365325969241994, -4.49145830736558)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w1, w2, bias, loss, cost_list, epoch_list = mini_batch_gradienten_abstieg(X, y, 1000, batch_size=2, loss_thr=0.4, lr=0.3)   \n",
    "w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "72c12458-9979-4d46-b070-8759b5c63d42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x2be6edf4fd0>]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy80BEi2AAAACXBIWXMAAA9hAAAPYQGoP6dpAABfQElEQVR4nO3deXhU9fU/8PedmcxM9n1fCBBICNkQJAZQQSIBkcUVrYqmLVaKrTauVIW6ora1tpaftLQoaqtYv5RNBDUSFAyELRD2NSQkmawkk32Smfv7YzIDKQlkkpncWd6v55nn0cydmzOOJIfPOZ/zEURRFEFERERkx2RSB0BERER0LUxYiIiIyO4xYSEiIiK7x4SFiIiI7B4TFiIiIrJ7TFiIiIjI7jFhISIiIrvHhIWIiIjsnkLqAKzBYDCgvLwc3t7eEARB6nCIiIioD0RRRGNjIyIiIiCTXX0NxSkSlvLyckRHR0sdBhEREfVDaWkpoqKirnqNUyQs3t7eAIxv2MfHR+JoiIiIqC+0Wi2io6PNv8evxikSFlMZyMfHhwkLERGRg+lLOwebbomIiMjuMWEhIiIiu8eEhYiIiOweExYiIiKye0xYiIiIyO4xYSEiIiK7x4SFiIiI7F6/Epbly5cjNjYWarUa6enpKCgouOr19fX1WLRoEcLDw6FSqTBy5Ehs3rx5QPckIiIi12FxwrJmzRrk5ORg6dKl2L9/P1JTU5GVlYWqqqoer9fpdLj11ltRXFyML774AidOnMDKlSsRGRnZ73sSERGRaxFEURQteUF6ejquv/56/PWvfwVgPHgwOjoav/rVr/D8889fcf2KFSvw+9//HsePH4ebm5tV7vm/tFotfH190dDQwEm3REREDsKS398WrbDodDrs27cPmZmZl24gkyEzMxP5+fk9vmbDhg3IyMjAokWLEBoaiqSkJLzxxhvQ6/X9vmd7ezu0Wm23BxERETkvixKWmpoa6PV6hIaGdvt6aGgoNBpNj685e/YsvvjiC+j1emzevBkvvfQS/vjHP+K1117r9z2XLVsGX19f84MnNRMRETk3m+8SMhgMCAkJwd///neMHTsW8+bNwwsvvIAVK1b0+56LFy9GQ0OD+VFaWmrFiC8xGESs2nEOS9cftsn9iYiIqG8sOq05KCgIcrkclZWV3b5eWVmJsLCwHl8THh4ONzc3yOVy89dGjRoFjUYDnU7Xr3uqVCqoVCpLQu+XoxVavPrlUYgicHN8MG5JCL32i4iIiMjqLFphUSqVGDt2LHJzc81fMxgMyM3NRUZGRo+vmThxIk6fPg2DwWD+2smTJxEeHg6lUtmvew6WpEhf/GziUADAc/9XhIvNOknjISIiclUWl4RycnKwcuVKrF69GseOHcPChQvR3NyM7OxsAMD8+fOxePFi8/ULFy5EXV0dnnjiCZw8eRJffvkl3njjDSxatKjP95TS01nxiAvxQnVjO15kaYiIiEgSFpWEAGDevHmorq7GkiVLoNFokJaWhi1btpibZktKSiCTXcqDoqOjsXXrVvzmN79BSkoKIiMj8cQTT+C5557r8z2lpHaT4517U3HH//sRXx6qwPTR5ZiVGiF1WERERC7F4jks9mgw5rD86ZuT+HPuKfh5uOHrJ29CiI/aJt+HiIjIVdhsDosre/yWOCRF+qC+pQPP/d8hOEGeR0RE5DCYsPSRm1yGd+5Ng1Ihw7YT1VizxzZbqYmIiOhKTFgsMDLUG09PGwkAeHXTUZTWtUgcERERkWtgwmKhn00ahvGxAWjW6fH0fw7CYGBpiIiIyNaYsFhILhPwh3tS4aGUY/e5OqzaeU7qkIiIiJweE5Z+iAn0wAszRwEA3t56AqerGiWOiIiIyLkxYemnn4yPwc0jg6HrNCDn84Po1Buu/SIiIiLqFyYs/SQIAt66KwU+agUOXWjA/8s7I3VIRERETosJywCE+arxypwkAMBfck/hcFmDxBERERE5JyYsAzQnLQIzksLQaRCR83kh2jr0UodERETkdJiwDJAgCHhtbhKCvJQ4WdmEP31zUuqQiIiInA4TFisI9FJh2Z0pAIC//3AWe4rrJI6IiIjIuTBhsZJbE0Nx99goiCLw1OcH0dzeKXVIREREToMJixUtmZWISD93lNS14I3Nx6QOh4iIyGkwYbEiH7Ub3r7bWBr61+4SbD9ZLXFEREREzoEJi5VNjAvCwxlDAADPfXEIDS0dEkdERETk+Jiw2MDzM0ZhaJAnNNo2/G7jEanDISIicnhMWGzAXSnHH+9NhUwA/nugDFsOV0gdEhERkUNjwmIj18X447GbhwMAfvvfw6hubJc4IiIiIsfFhMWGnsgcgYQwb9Q16/Db/xZBFEWpQyIiInJITFhsSKWQ40/z0uAmF/DN0Ur83/4yqUMiIiJySExYbGxUuA+ezBwJAHh5wxGU1bdKHBEREZHjYcIyCH5x0zCMifFDY3snnvviEAwGloaIiIgswYRlECjkMvzxnlSo3WTYcboGn+w+L3VIREREDoUJyyAZFuyF56cnAADe2HwM52qaJY6IiIjIcTBhGUTzM2IxYXgg2joMeOrzQuhZGiIiIuoTJiyDSCYT8Pt7UuGtUmB/ST3+9v0ZqUMiIiJyCExYBlmknzuWzEoEAPzpm5M4VqGVOCIiIiL7x4RFAnePjULmqFB06EXkfH4Quk6D1CERERHZNSYsEhAEAcvuTIa/hxuOVWjx59yTUodERERk15iwSCTYW4XX70gGALyfdwYHSi5KHBEREZH9YsIioduSwzEnLQIGEXjq84No1emlDomIiMguMWGR2CuzkxDqo8LZmma8teW41OEQERHZJSYsEvP1cMNbd6UAAD78sRg/nq6ROCIiIiL7w4TFDkyOD8FP0mMAAM98cQjatg6JIyIiIrIv/UpYli9fjtjYWKjVaqSnp6OgoKDXaz/88EMIgtDtoVaru13zyCOPXHHN9OnT+xOaw3rhtlGICfBAWX0rXt14VOpwiIiI7IrFCcuaNWuQk5ODpUuXYv/+/UhNTUVWVhaqqqp6fY2Pjw8qKirMj/Pnrzz8b/r06d2u+fTTTy0NzaF5qhT4wz2pEATgP/su4NujlVKHREREZDcsTljeeecdLFiwANnZ2UhMTMSKFSvg4eGBVatW9foaQRAQFhZmfoSGhl5xjUql6naNv7+/paE5vPFDA/DzSUMBAM+vLUJds07iiIiIiOyDRQmLTqfDvn37kJmZeekGMhkyMzORn5/f6+uampowZMgQREdHY86cOThy5MgV1+Tl5SEkJATx8fFYuHAhamtrLQnNaTw1LR4jQrxQ09SOF9cVQRR5QCIREZFFCUtNTQ30ev0VKyShoaHQaDQ9viY+Ph6rVq3C+vXr8cknn8BgMGDChAm4cOGC+Zrp06fjo48+Qm5uLt566y1s374dM2bMgF7f81yS9vZ2aLXabg9noXaT451706CQCdhcpMGGg+VSh0RERCQ5ha2/QUZGBjIyMsz/PmHCBIwaNQp/+9vf8OqrrwIA7rvvPvPzycnJSElJwfDhw5GXl4epU6decc9ly5bh5ZdftnXokkmO8sXjt8Th3W9PYcn6I7hhWCBCfdTXfiEREZGTsmiFJSgoCHK5HJWV3RtCKysrERYW1qd7uLm5YcyYMTh9+nSv1wwbNgxBQUG9XrN48WI0NDSYH6WlpX1/Ew5i0ZQ4JEf6oqG1A89+cYilISIicmkWJSxKpRJjx45Fbm6u+WsGgwG5ubndVlGuRq/Xo6ioCOHh4b1ec+HCBdTW1vZ6jUqlgo+PT7eHs3GTy/DOvalQKmTYfrIanxY4X1JGRETUVxbvEsrJycHKlSuxevVqHDt2DAsXLkRzczOys7MBAPPnz8fixYvN17/yyiv4+uuvcfbsWezfvx8PPvggzp8/j5///OcAjA25zzzzDHbt2oXi4mLk5uZizpw5iIuLQ1ZWlpXepmMaEeqNZ7PiAQCvfXkUJbUtEkdEREQkDYt7WObNm4fq6mosWbIEGo0GaWlp2LJli7kRt6SkBDLZpTzo4sWLWLBgATQaDfz9/TF27Fj8+OOPSExMBADI5XIcOnQIq1evRn19PSIiIjBt2jS8+uqrUKlUVnqbjit74lB8faQSBcV1ePo/B/HpozdALhOkDouIiGhQCaITNEdotVr4+vqioaHBKctDJbUtmP7n79Gi0+OF20ZhwU3DpA6JiIhowCz5/c2zhBxATKAHXpxpXJH6/dcncKqyUeKIiIiIBhcTFgdx//hoTI4Phq7TgJzPD6JDb5A6JCIiokHDhMVBCIKAt+5Kga+7G4rKGrB8W+/bwomIiJwNExYHEuqjxitzRgMA/vrdaRRdaJA4IiIiosHBhMXBzE6NwMzkcHQaROR8Xoi2jp6PLyAiInImTFgcjCAIeHVuEoK8VDhV1YQ/fn1C6pCIiIhsjgmLAwrwVOLNO5MBAP/YcQ67z7rmydZEROQ6mLA4qMzEUNwzNgqiCDz9xUE0tXdKHRIREZHNMGFxYEtmJSLSzx2lda14Y/MxqcMhIiKyGSYsDsxb7Ybf35MCAPj37hLknaiSOCIiIiLbYMLi4CYMD8IjE2IBAM/93yE0tHRIGxAREZENMGFxAs9NT8CwIE9UatuxZMNhqcMhIiKyOiYsTsBdKccf7k2FTADWF5Zjc1GF1CERERFZFRMWJ3FdjD8WTh4OAHjhv0WoamyTOCIiIiLrYcLiRJ6YOhKjwn1wsaUDv11bBFEUpQ6JiIjIKpiwOBGlQoZ37k2Fm1zAt8eq8J99F6QOiYiIyCqYsDiZUeE++M2tIwEAr2w8igsXWySOiIiIaOCYsDihX9w0HNfF+KGpvRPPfnEIBgNLQ0RE5NiYsDghuUzAH+9Ng9pNhh/P1OKj/GKpQyIiIhoQJixOamiQJxbPGAUAeHPLcZytbpI4IiIiov5jwuLEHrphCCbGBaKtw4Cczw+iU2+QOiQiIqJ+YcLixGQyAb+/OxXeKgUKS+vxt+/PSh0SERFRvzBhcXIRfu5YOns0AODdb0+ivL5V4oiIiIgsx4TFBdx1XSTGDvFHh17ExoPlUodDRERkMSYsLkAQBNx5XSQA41lDREREjoYJi4u4LSkcCpmAoxVanK5qlDocIiIiizBhcRH+nkrcNDIYALCBqyxERORgmLC4kNmpEQCADQfLeTAiERE5FCYsLuTWxFCo3WQorm3BoQsNUodDRETUZ0xYXIinSoHMUaEAjKssREREjoIJi4uZk2bcLbTxYDn0PBSRiIgcBBMWF3PzyGD4uruhqrEdu8/VSh0OERFRnzBhcTFKhQwzksIAcLcQERE5DiYsLmh2mnG30FeHNWjv1EscDRER0bUxYXFB6UMDEeKtQkNrB74/WSN1OERERNfEhMUFyWUCZnXNZFlfWCZxNOTIPi0oQfyLX2H3WfZDEZFt9SthWb58OWJjY6FWq5Geno6CgoJer/3www8hCEK3h1qt7naNKIpYsmQJwsPD4e7ujszMTJw6dao/oVEfmYbIfXusEs3tnRJHQ45IFEX8bfsZtHcasPEQ+6GIyLYsTljWrFmDnJwcLF26FPv370dqaiqysrJQVVXV62t8fHxQUVFhfpw/f77b82+//Tb+8pe/YMWKFdi9ezc8PT2RlZWFtrY2y98R9UlKlC9iAz3Q1mHAN0crpQ6HHNCRci2Ka1sAAEUcREhENmZxwvLOO+9gwYIFyM7ORmJiIlasWAEPDw+sWrWq19cIgoCwsDDzIzQ01PycKIp499138eKLL2LOnDlISUnBRx99hPLycqxbt65fb4quTRCEbqP6iSz1ZVGF+Z+PaRqh6zRIGA0ROTuLEhadTod9+/YhMzPz0g1kMmRmZiI/P7/X1zU1NWHIkCGIjo7GnDlzcOTIEfNz586dg0aj6XZPX19fpKen93rP9vZ2aLXabg+ynGm30Pcnq3GxWSdxNORIRFHEl4cuJSy6TgNOVvIUcCKyHYsSlpqaGuj1+m4rJAAQGhoKjUbT42vi4+OxatUqrF+/Hp988gkMBgMmTJiACxcuAID5dZbcc9myZfD19TU/oqOjLXkb1CUuxBujI3zQaRCx+XDFtV9A1OVwmRYldS1Qu8kwJsav62ssCxGR7dh8l1BGRgbmz5+PtLQ03HzzzVi7di2Cg4Pxt7/9rd/3XLx4MRoaGsyP0tJSK0bsWmabdwuxLER9t6nI+P/L1IRQjB8aAAAoYsJCRDZkUcISFBQEuVyOysruTZqVlZUICwvr0z3c3NwwZswYnD59GgDMr7PkniqVCj4+Pt0e1D+m7c17iutQXt8qcTTkCC4vB81MCUdKpB8AJixEZFsWJSxKpRJjx45Fbm6u+WsGgwG5ubnIyMjo0z30ej2KiooQHh4OABg6dCjCwsK63VOr1WL37t19vif1X4SfO8bHBkAUgU3cmkp9UFTWgAsXW+HuJseU+BAkR/oCAI5XsPGWiGzH4pJQTk4OVq5cidWrV+PYsWNYuHAhmpubkZ2dDQCYP38+Fi9ebL7+lVdewddff42zZ89i//79ePDBB3H+/Hn8/Oc/B2DcrfLkk0/itddew4YNG1BUVIT58+cjIiICc+fOtc67pKsyNd+yLER9YVpduWVUCNyVckQHuMPX3Q06PRtvich2FJa+YN68eaiursaSJUug0WiQlpaGLVu2mJtmS0pKIJNdyoMuXryIBQsWQKPRwN/fH2PHjsWPP/6IxMRE8zXPPvssmpub8eijj6K+vh6TJk3Cli1brhgwR7ZxW3I4frfhCI6Ua3G6qglxIV5Sh0R2ShRFbOpKWG5PNq6SCoKA5Ehf7Dhdg6KyBiR1rbgQEVmTIIqiKHUQA6XVauHr64uGhgb2s/RT9gcF2HaiGr+eOgI5t46UOhyyU4Wl9Zi7fCc8lHLse/FWuCvlAIA3vzqOFdvP4CfpMXjjjmSJoyQiR2HJ72+eJUQALpWFNh4shxPksGQjX3b1OU0dFWpOVgDj5GSAE2+JyHaYsBAA4NbEMKjdZDhX08zdHtSjbruDuspBJubGW40W7Z36QY+NiJwfExYCAHipFMgcZexD2sDmW+rBgdJ6lDe0wVMpx+T44G7PRfkbG2879CJOapokipCInBkTFjIzDZHbeKgcegPLQtTd5q7VlczEUKjd5N2eEwThUlmIK3REZANMWMjs5vhg+KgVqNS2o+BcndThkB0xGERsLuq5HGRi2h3EhIWIbIEJC5mpFHLMSDL+MtpwsEziaMiemMpBXioFbhoZ3OM1KeaEpX4QIyMiV8GEhbqZ07VbaHORhlNLyczUbJs5KuSKcpCJaYXlhKaRjbdEZHVMWKib9GGBCPFWoaG1A9+frJY6HLID3cpBKRG9Xhfl7w4/D2Pj7QkNJ94SkXUxYaFu5DIBt3f9Ulp/kLuFCNhfchEabRu8VQrcOCKo1+tME28B9rEQkfUxYaErmIbIfXu0Es3tnRJHQ1IzjeK/tYfdQf/LlLAcZsJCRFbGhIWukBrliyGBHmjt0OPbY5VSh0MSMhhEfHXYVA7qeXfQ5Uxbmw9x4i0RWRkTFrqCIAiY0zWThUPkXNu+kouo1LbDW63ApKuUg0xMjbcnKxvR1sHGWyKyHiYs1CNTWWj7yWpcbNZJHA1J5cvLykEqxdXLQQAQ6ecOfzbeEpENMGGhHsWFeCMx3AedBhFfHdZIHQ5JQH/Z7qDb+1AOAroab6P8ALDxloisiwkL9cq0yrK+kEPkXNHe4jpUNXaVg+J6HhbXk+RI4xHxPLmZiKyJCQv1alZXH0tBcR0qGloljoYG25ddqytZo8OgVPT9R0VypB8ArrAQkXUxYaFeRfq54/pYf4gisOlghdTh0CAyloOMpcC+7A66XHIUG2+JyPqYsNBVzU6LBABs4BA5l7KnuA41Te3wdXfDxOHX3h10uQhfNQI8leg0iDjOxlsishImLHRVtyWFQS4TUFTWgDPVTVKHQ4PEtDsoa3SoReUggBNvicg2mLDQVQV6qczj2DmTxTXoLxsWd1uyZeUgE3PCcqHeWmERkYtjwkLXZDrBeePBcoiiKHE0ZGu7z9WipklnLAfFWVYOMjH1sRSVaa0ZGhG5MCYsdE23JoZBpZDhbE0zDvMXkNMzlYOmjw6Dm7x/PyJMKyyn2HhLRFbChIWuyUulQGZiKABgw0HOZHFmnXoDthzu3+6gy4X7qhHY1Xh7rIJJLhENHBMW6pPZqaayUAUMBpaFnNXuc3WobdbB38MNGcMD+30f48RbntxMRNbDhIX6ZHJ8MLzVCmi0bSgorpM6HLKRTaZyUFL/y0EmprIQT24mImtgwkJ9olLIMSMpDACwnruFnFKn3oCtR7rKQckRA74ftzYTkTUxYaE+m9M1RO6rwxXQdRokjoasbdfZOtQ16xDgqcQNwwIGfD9TSehUVRMbb4lowJiwUJ/dMCwQwd4q1Ld04IdT1VKHQ1b2ZZFx5SxrdBgUAywHAUCYjxpBXkroDSKOsvGWiAaICQv1mVwm4PaunSMc1e9cOi7bHXT7AHYHXe7yibdsvCWigWLCQhYxlYW+PlKJFl2nxNGQteSfqcXFlg4EeiqRPnTg5SATNt4SkbUwYSGLpEb5YkigB1o79PjmaKXU4ZCVfHnZ7iBrlINMkqP8AHCFhYgGjgkLWUQQhMtmsrAs5Aw69AZsPTrwYXE9MU+8rWpCq46Nt0TUf0xYyGKmhGX7yWrUt+gkjoYG6scztahv6UCQlxLpQ/s/LK4noT4qBHmp2HhLRAPGhIUsNiLUG6PCfdChF/FVV6MmOa4vDxlXymYkhUMuE6x6b0EQkMKJt0RkBUxYqF9MqyzrC3m2kCPTdRqw9YixF+m2ZOuWg0yS2HhLRFbQr4Rl+fLliI2NhVqtRnp6OgoKCvr0us8++wyCIGDu3Lndvv7II49AEIRuj+nTp/cnNBoks1KNv9x2n6uDpqFN4miov3aeqUFDaweCvFQYb8XdQZdL4dZmIrICixOWNWvWICcnB0uXLsX+/fuRmpqKrKwsVFVVXfV1xcXFePrpp3HjjTf2+Pz06dNRUVFhfnz66aeWhkaDKMrfA9fH+kMUgU2H2HzrqEy7g25LDrN6Ocjk0sTbRjbeElG/WZywvPPOO1iwYAGys7ORmJiIFStWwMPDA6tWrer1NXq9Hg888ABefvllDBs2rMdrVCoVwsLCzA9/f39LQ6NBZioLcYicYzKWg0xnB9mmHAQAoT5qBHurYBCBoxVcZSGi/rEoYdHpdNi3bx8yMzMv3UAmQ2ZmJvLz83t93SuvvIKQkBD87Gc/6/WavLw8hISEID4+HgsXLkRtbW2v17a3t0Or1XZ70OC7LdnYpHnoQgPOVjdJHQ5ZaMfpajS2dSLEW4VxsbYpB5mYykJF7GMhon6yKGGpqamBXq9HaGhot6+HhoZCo+l5t8iOHTvwz3/+EytXruz1vtOnT8dHH32E3NxcvPXWW9i+fTtmzJgBvb7n5eNly5bB19fX/IiOjrbkbZCVBHqpMCkuCABXWRzRl4eMf2ZNiactmRtv2cdCRP1k011CjY2NeOihh7By5UoEBQX1et19992H2bNnIzk5GXPnzsWmTZuwZ88e5OXl9Xj94sWL0dDQYH6Ulpba6B3QtcxJu1QWEkVR4mior9o79fjaRsPiesKtzUQ0UApLLg4KCoJcLkdlZfeR7JWVlQgLC7vi+jNnzqC4uBizZs0yf81gMBi/sUKBEydOYPjw4Ve8btiwYQgKCsLp06cxderUK55XqVRQqVSWhE42Mm10GFSKIpytbsaRcq35b9Jk33acqkFjWydCfVQYG2P7fjHTxNvTVU1o0XXCQ2nRjx4iIstWWJRKJcaOHYvc3Fzz1wwGA3Jzc5GRkXHF9QkJCSgqKkJhYaH5MXv2bEyZMgWFhYW9lnIuXLiA2tpahIfb/m9+NDBeKgUyRxlLhCwLOQ7T7qAZSeGQ2bgcBAAhPmqE+nQ13paz54yILGdxSSgnJwcrV67E6tWrcezYMSxcuBDNzc3Izs4GAMyfPx+LFy8GAKjVaiQlJXV7+Pn5wdvbG0lJSVAqlWhqasIzzzyDXbt2obi4GLm5uZgzZw7i4uKQlZVl3XdLNjHrsrOFDAaWhexd22UHV94+COUgE9MqSxHLQkTUDxavy86bNw/V1dVYsmQJNBoN0tLSsGXLFnMjbklJCWSyvudBcrkchw4dwurVq1FfX4+IiAhMmzYNr776Kss+DmJyfDC81QpUNLRhT3Ed0odZ9zwasq4fTtWgsb0TYT5qXDcI5SCTpEhffHusijuFiKhf+lVIfvzxx/H444/3+FxvjbImH374Ybd/d3d3x9atW/sTBtkJtZscM5LC8PneC1h/sJwJi50znR10W/LglINMTI23XGEhov7gWUJkFbNTIwEAm4sqoOs0SBwN9aatQ49vjxmnUg/G7qDLmRqyT1c3obm9c1C/NxE5PiYsZBUZwwMR5KVCfUsHdpyuljoc6sX3J6vR1N6JCF81xkT7Der3DvFWI8xHDVEEjlaw8ZaILMOEhaxCLhPMDZwbCrlbyF59WdS1O2iQy0EmSZx4S0T9xISFrMY0RO7ro5Vo0XHJ3960dejxbdfuoMEuB5lwpxAR9RcTFrKatGg/xAR4oEV3qU+C7EfeiWo06/SI9HMf9HKQCRtviai/mLCQ1QiCcOkEZ5aF7I6pHHRbchgEYfDLQcClktCZ6iY0sfGWiCzAhIWsanZXWWj7ySrUt+gkjoZM2jr0yD1mKgdFSBZHsLcK4b5djbeceEtEFmDCQlY1MtQbCWHe6NCL2HK45xO8afDlnahCS1c5KDVK2vOektjHQkT9wISFrG5OmnEmy3qWhezGpq6zg25PCZesHGRibry9UC9pHETkWJiwkNXNSjXuQNl1rhaV2jaJo6FWnR65XU3QtyVLf6BoMhtviagfmLCQ1UX5e2DcEH+IovFARJLWthNVaO3QI8rf3bxLR0qmFZazNc1svCWiPmPCQjZhar5lwiK9L7vKQTPtoBwEAEFeKkR0Nd4e4SoLEfURExayiduSwyGXCTh4oQHnapqlDsdlteg6kXvcuDvo9mTpdgf9LzbeEpGlmLCQTQR5qTAxLggAV1mk9N3xKrR1GBAT4IGkSB+pwzHjxFsishQTFrKZOV1D5NYVlkEURYmjcU32Vg4yYeMtEVmKCQvZzLTRoVApZDhb3YwjHBI26JrbO7HthHF30Ew72B10OXPjbXUzGts6JI6GiBwBExayGW+1G6aOCgHAspAUTOWgIYEeGB1hP+UgAAj0UiHSzx0AmMwSUZ8wYSGbmp1qHCK34WA5DAaWhQaTuRyUbF/lIBNTT81hloWIqA+YsJBNTY4PhrdKgYqGNuw9f1HqcFxG0+XloBT7KgeZmMpChy4wYSGia2PCQjaldpNjelIYAGB9YZnE0biO3GOVaO80YGiQJxLD7ascZJIc5QeAKyxE1DdMWMjmTEPkNhdVoENvkDga12Dv5SCg+8RbLRtvrULT0IaFn+zDpkPsGSPnw4SFbC5jWCCCvFS42NKBHadqpA7H6TW2dSDvZDUA+y0HAUCAp/JS420ZG2+tYXV+Mb46rMHj/z6AVzYe5V8QyKkwYSGbU8hluL3rF+cG7hayue+OV0HXacCwYE8khHlLHc5VXRogVy9tIE5i2/Eq8z+v2nkOD/5jN6ob2yWMiMh6mLDQoDCVhbYe0aBVp5c4Gue2qascdLsdl4NMLg2Q4wrLQJXVt+K4phEyAXj77hR4qRTYfa4Os97bgcLSeqnDIxowJiw0KMZE+yE6wB0tOr35bBuyvsa2Dmw/YSwH3WbH5SAT0woLG28HzrS6cl2MP+4dF411iyZieLAnNNo23LsiH58VlEgcIdHAMGGhQSEIAmZ3jepfX8iykK18e6wSOr0Bw4M9ER9q3+Ug4FLCco6NtwNmSlimJBiHNcaFeGHdoonIGh0Knd6A59cWYfHaQ2jv5AonOSYmLDRo5qQZh8jlnahCQwt/OdnCpbODIuy+HAQA/p5KRPkbG2+5ytJ/bR167DxjbGi/pSthAYzTplc8OBbPZMVDEIBPC0px7992oaKhVapQifqNCQsNmpGh3kgI80aHXsSWIxVSh+N0Glo78P1J4y+t2x2gHGRibrzlALl+yz9bi7YOA8J91Vc0WguCgEVT4vBh9nj4urvhYGk9Zr23A7vO1koULVH/MGGhQWVqvmVZyPq+PWosB40I8cJIBygHmSRF8uTmgcq7rBzU28razSODsfHxSRgV7oOaJh0e+MdurNpxjiepk8NgwkKDalaKMWHJP1uLKm2bxNE4l81FpnKQ46yuAEBKFBtvB0IURXzXdQzDLfEhV702JtADaxdOwNy0COgNIl7ZdBS/WVPInXvkEJiw0KCKDvDA2CH+EEVg4yGWhaylobUD35/qGhaX7FgJS1KEMWEprm1BQyt7myx1proJpXWtUCpkmBAXeM3r3ZVy/GleGpbOSoRcJmBdYTnufP9HlNS2DEK0RP3HhIUGnWm3EIfIWc83RyvRoRcxMtQLIxyoHAQYG2+jA0wTb7nKYqnvuspBNwwLhIdS0afXCIKA7IlD8e+fpyPIS4ljFVrM+usO5J2ouvaLiSTChIUG3W3J4ZDLBBwsrUdxTbPU4TiFL7vOjpmZHCFxJP1jPrmZCYvFTAnLLfHBFr82fVggNv5qEtKi/dDQ2oHsD/dg+bbT7Gshu8SEhQZdsLcKE4Ybl643cpVlwBpaOvBD1xlNM1PCJI6mf9h42z/atg7sLb4IALglIbRf9wj3dceaX9yA+8fHQBSB3289gcc+2YdGzsUhO8OEhSRhmsmyrrCMf5sboK1HNeg0iEgI80ZciGOVg0xSIv0AsPHWUj+crEGnQcTwYE/EBHr0+z4qhRzL7kzGm3cmQymXYeuRSsxdvhOnq5qsGC3RwPQrYVm+fDliY2OhVquRnp6OgoKCPr3us88+gyAImDt3brevi6KIJUuWIDw8HO7u7sjMzMSpU6f6Exo5iKzRoVAqZDhT3YyjFTxHZiDMw+IcrNn2ckmRPgCA87UtHCpoAXM5KOHqu4P66r7xMVjzixsQ5qPGmepmzF2+E1uPaKxyb6KBsjhhWbNmDXJycrB06VLs378fqampyMrKQlXV1Zu1iouL8fTTT+PGG2+84rm3334bf/nLX7BixQrs3r0bnp6eyMrKQlsbt706K2+1G6Z2/ZBl823/1bfosPO0sRzkCGcH9cbPQ4mYAOMKweFyrrL0hcEgYvvJ7uP4rWFMjD82/moS0ocGoKm9E7/4eB9+v/U49AauhJK0LE5Y3nnnHSxYsADZ2dlITEzEihUr4OHhgVWrVvX6Gr1ejwceeAAvv/wyhg0b1u05URTx7rvv4sUXX8ScOXOQkpKCjz76COXl5Vi3bp3Fb4gcx5yuIXIbC8th4A/Dfvn6SCU6DSJGhftgeLCX1OEMiLnxlhNv++RQWQNqmnTwVilwfWyAVe8d7K3CJz9Px08nDgUALN92Btkf7kF9i86q34fIEhYlLDqdDvv27UNmZualG8hkyMzMRH5+fq+ve+WVVxASEoKf/exnVzx37tw5aDSabvf09fVFenp6r/dsb2+HVqvt9iDHMzk+BN4qBcob2rCv5KLU4TikTaZhccmO2Wx7uSSe3GwRUznoxpFBcJNbvx3RTS7DklmJ+PN9aVC7yfD9yWrM+usOHC3nz1uShkX/l9fU1ECv1yM0tHs3emhoKDSanuucO3bswD//+U+sXLmyx+dNr7PknsuWLYOvr6/5ER0dbcnbIDuhdpMjK8n4i3Z9YZnE0Tiei82XlYMcuH/FxDTxljuF+sZ8OvM1ptsO1Jy0SKxdOBHRAe4orWvFne/v5J9XkoRNdwk1NjbioYcewsqVKxEUFGS1+y5evBgNDQ3mR2lpqdXuTYPLNERuc5EGHXqDxNE4lq1HNNAbRCSG+2CYg5eDgEsTb0vqWlh6uIYqbZs5sZts44QFABIjfLDx8Um4aWQw2joMeOKzQry88Qj/zNKgsihhCQoKglwuR2VlZbevV1ZWIizsyiXpM2fOoLi4GLNmzYJCoYBCocBHH32EDRs2QKFQ4MyZM+bX9fWeAKBSqeDj49PtQY5pwvBABHkpUdesw46u1QLqmy8d9Oyg3vh6uGFI19bcw2UsO1xN3knjMQypUb4I9lYNyvf081Dig0eux+NT4gAAH+wsxoP/2I3qxvZB+f5EFiUsSqUSY8eORW5urvlrBoMBubm5yMjIuOL6hIQEFBUVobCw0PyYPXs2pkyZgsLCQkRHR2Po0KEICwvrdk+tVovdu3f3eE9yLgq5zLwddyNPcO6zumYdfjxTC8CxtzP/ryTzxNt6aQOxc9uOW393UF/IZQKezorH3x4aCy+VArvP1WHWeztwgD1oNAgsLgnl5ORg5cqVWL16NY4dO4aFCxeiubkZ2dnZAID58+dj8eLFAAC1Wo2kpKRuDz8/P3h7eyMpKQlKpRKCIODJJ5/Ea6+9hg0bNqCoqAjz589HRETEFfNayDnN7hoit/WIhqfG9pGpHJQU6YPYIE+pw7GaFDbeXpOu02CebGzr/pXeZI0Ow7pFEzE82BMabRvm/W0XPi0okSQWch19OynrMvPmzUN1dTWWLFkCjUaDtLQ0bNmyxdw0W1JSApnMsjzo2WefRXNzMx599FHU19dj0qRJ2LJlC9RqtaXhkQO6LsYPUf7uuHCxFd8dr3KaEoctXRoW55hnB/UmmSP6r2lvcR2a2jsR5KUy//eSQlyIF9Y/PglPf34QW45osHhtEQ5dqMfvZo+GSiGXLC5yXoLoBHPRtVotfH190dDQwH4WB/X2luP4f3lnMC0xFH+fP07qcOxabVM7rn/9WxhE4PtnpgxoJLu9aWjtQOrLXwMADrx0K/w9lRJHZH9e23QU/9hxDnePjcIf7kmVOhyIooj/l3cGf/j6BEQRSI32w4oHr0O4r7vUoZEDsOT3N88SIrtgOlso70Q1Glo5mv1qthzRwCAaVyOcKVkBAF93N8QGcuLt1Xx3wrrj+AdKEAQsmhKHD7PHw9fdDQdL6zHrvR3YdbZW6tDIyTBhIbsQH+aN+FBv6PQGbD3Ms0uuxlwOctLSWRIn3vbqfG0zzlY3QyETMGmE9UZFWMPNI4Ox6VeTMCrcBzVNOjzwj934545zPNyUrIYJC9mN2V2j+tcf5FCq3lQ3tpv/5upMu4MuZxogx8bbK5mm214fGwAftZvE0VwpOsADaxdOwNy0COgNIl7ddBRPrilkMz1ZBRMWshumIXL5Z2pRpeXBlz0xlYNSo3wRHeBc5SCTJDbe9srapzPbgrtSjj/NS8PSWYmQywSsLyzHne//iJLaFqlDIwfHhIXsRnSAB66L8YNBBDZ1lT2ouy8PGWfVOGs5CLiUsFy42IqLzZx4a9Lc3ondZ+sADP78FUsJgoDsiUPx75+nI8hLiWMVWsz66w7kdfXfEPUHExayK6ZVlg0HOUTuf1U1tqHgnPEXljOcHdQbH7UbhnbNluEqyyU7T9dApzcgJsADw4MdY/ZO+rBAbPzVJKRF+6GhtQPZH+7B8m2neTo79QsTFrIrM1MiIBOAwtJ6nK9tljocu7L1sLEclBbthyh/5ywHmbAsdKVtl+0OEgRB4mj6LtzXHWt+cQPuHx8DUQR+v/UEHvtkHxrbuBuQLMOEhexKsLcKE+OMux82cpWlm03mYXHOu7piYpp4W8SdQgCMs062HTeeH2Tv5aCeqBRyLLszGW/emQylXIavj1Zi7vKdOF3VJHVo5ECYsJDdMZWF1heWc0tklyptGwqKjeWgGck9HwrqTLjC0t2xikZotG1wd5MjfWiA1OH0233jY/D5YxkI91XjTHUz5i7fiS0cY0B9xISF7E5WUhiUChlOVTXhuKZR6nDswleHNRBFYEyM85eDAGB0pHHiZVl9K+rYeGsuB02MC4TazbHH3qdF+2HjryYhfWgAmto78dgn+/D7rcehZ18LXQMTFrI7Pmo33NJ1qNt6nuAM4PKzg5y/HAQY/x8YxsZbs+8kOp3ZVoK8VPjk5+n46cShAIDl284g+8M9qG9hckq9Y8JCdmlO1xC5jQfLXX5HQaW2DXvOO//uoP9lLgtdqJc2EIldbNbhQMlFANKdzmwLbnIZlsxKxJ/vS4PaTYbvT1Zj1l934Gi5VurQyE4xYSG7NCUhBF4qBcrqW7G/64e1q/qqqAKiCIwd4o8IP9c5UM408dbVV1i2n6yGQQQSwryd8vOfkxaJtQsnIjrAHaV1rbjz/Z1Yd4DTrulKTFjILqnd5MgabWwudfWy0JdFrlUOMkniTiEAjjHddqASI3yw8fFJuHlkMNo6DHhyTSFe3ngEHXqD1KGRHWHCQnbLdLbQ5qIKl/3BpWlow55i4wqTK+wOutzoCGPjbXlDG2qb2iWORhqdegO2nzRuZ3bmhAUA/DyUWPXI9Xh8ShwA4IOdxfjt2iKJoyJ7woSF7NbE4YEI9FSitlmHnadrpA5HEpu7VlfGDfFHuK/zlQOuxlvthmHBrt14e6C0Hg2tHfDzcMOYGH+pw7E5uUzA01nxeP+B6wAAaw+Uoay+VeKoyF4wYSG7pZDLcHvXmTmuOqrfXA5y4rODribZxctCpnLQzSODIZc5znTbgZqRHI4JwwOhN4j4KL9Y6nDITjBhIbtmKgttPaxBW4drHVFfXt+KfecvQhCAGUkunrC46ArLNhfoX+lNdteW588KStGi65Q4GrIHTFjIrl0X448of3c06/Tmv226ClM56PohAQjzVUscjTRcOWEpq2/FcU0jZIJxhcXV3JIQgpgADzS0duC/3DVEYMJCdk4QBMwyj+p3rR9am128HAQAoyN9IQhARUMbalys8da0unJdjD/8PJQSRzP45DIBD0+IBQB8uLOYx3QQExayf6YhcttOVKOh1TVOeDXOn6nvKge51u6gy3mpFC478Xabk0237Y97x0XBS6XAqaom7HDRxnu6hAkL2b2EMB+MDPWCrtOArUdc46C0r0zloNgAhPi4ZjnIxBUbb9s69Nh5xvgL2pmm21rKW+2Gu8dGAQBW7TgncTQkNSYs5BDmpEUCADa4yBC5TV1nB93uwuUgk+QoPwCutcKy62wt2joMCPdVY1S4t9ThSOqRCbEQBOMK69nqJqnDIQkxYSGHMCvFWBb68UwNqhrbJI7GtkrrWlBYaiwHTXfhcpCJK66wmMpBk+NDIAius525J7FBnubDUFf/WCxtMCQpJizkEGICPTAmxg8G8dLJxc7qq8PG95c+NAAh3q5dDgKME28FAdBo21Dd6PyNt6Io4rsTrruduSemLc5f7LsAbZtr9LHRlZiwkMOY07VbyNmHyJkSspldq0quzlOlwPBgLwDAYRcoC52pbkJpXSuUChkmxgVKHY5dmBgXiJGhXmjW6fH5nlKpwyGJMGEhhzEzJQIyAThQUo+l6w/jSLnz/fIqrWvBwQsNkAnA9NEsB5mYykKHXKAsZJo3dMOwQHgoFRJHYx8EQcAjE4yrLKvzi6E3cIuzK2LCQg4j2Ftl3jGwOv88Zv5lB25/7wd8lF+MhhbnWCY2zV65YVgggr1VEkdjP1xpgJz5dOZ41xsWdzV3jImEn4cbSutakXusUupwSAJMWMihLLszBat/Oh4zU8KhlMtwuEyLJeuP4Po3vsWvPz2AnadrYHDgv32Zzg66LZm7gy6XHGVKWOqlDcTGtG0d2Nt1OvctCaESR2Nf3JVy3D8+BgCwaie3OLsirjeSQ5HLBNw8Mhg3jwzGxWYd/nugDJ/vLcVxTSM2HCzHhoPliPJ3xz1jo3H3uChE+jnOCccltS04ZCoHcXdQN4nhxsbbSm07qhrbnLYZ+YeTNeg0iBge7ImYQA+pw7E7D90wBH///ix2na3DsQotRoX7SB0SDSKusJDD8vdU4qeThuKrJ27Ehscn4sEbYuCtVuDCxVb86duTmPTWd3jon7ux6VA52jvt/+BE0+pKxvBABHmxHHQ5T5UCcS7QePudCx922BcRfu7mZP4DrrK4HCYs5PAEQUBKlB9em5uMgt9m4t15acgYFghRBH44VYPH/30A6W/k4ncbjuBYhVbqcHv1ZZFx99PMZO4O6omzN94aDCK2n+Q4/mv56cRYAMC6wnLUutj5Uq6OCQs5FXelHHPHROLTR2/A9mcm41e3xCHMR436lg58+GMxZvz5B8x6bwc+3nXers4lKq5pxuEyLeQyAVmj2bvQE1Mfi7OusBwqa0BNkw5eKgXGDQmQOhy7dV2MP1KifKHrNODTghKpw6FBxISFnNaQQE88NS0eO5+/BR9kX4/bksPgJhdQVNaAl9YdxvjXv8WTnx3Aj2ekb9Q1lYMmDA9EIMtBPXL2FRZTOejGEUFQKvijuTeCICC7a5Xl413n0aE3SBsQDRo23ZLTk8sETIkPwZT4ENQ2tWNdYTk+31OKE5WNWFdYjnWF5YgJ8MA9Y6Nw19goREjQqGvazjyTu4N6lRjhA5kAVDW2o1LbhlAnOxQy7wTLQX01MzkCb2w+jkptOzYXVZjPGiPnxjSeXEqglwo/mzQUW568EesXTcRP0mPgrVKgpK4Ff/zG2Kj78KoCbC6qGLRG3XM1zThSbioHcXdQbzyUCsSFGBtvne1coarGNvPK0WTOX7kmpUKGh24YAgBYtbNY2mBo0PQrYVm+fDliY2OhVquRnp6OgoKCXq9du3Ytxo0bBz8/P3h6eiItLQ0ff/xxt2seeeQRCILQ7TF9+vT+hEbUJ4IgIDXaD2/ckYyCFzLxzr2pSB8aAIMIbD9ZjV/+az9ueCMXr2w8iuMa2zbqbr6sHOTvqbTp93J0SU46QC7vRDUAICXK12m3bFvbT9JjoJTLcLC0HvtLLkodDg0CixOWNWvWICcnB0uXLsX+/fuRmpqKrKwsVFVV9Xh9QEAAXnjhBeTn5+PQoUPIzs5GdnY2tm7d2u266dOno6Kiwvz49NNP+/eOiCzkrpTjzuuisOYXGch7ejIWTRmOUB8VLrZ0YNXOc5j+7g+Y89cd+GTXeZscvLap6+yg21NYDrqWlEjnbLw1nc48JZ7loL4K8lJhdppxR90HXGVxCRYnLO+88w4WLFiA7OxsJCYmYsWKFfDw8MCqVat6vH7y5Mm44447MGrUKAwfPhxPPPEEUlJSsGPHjm7XqVQqhIWFmR/+/v79e0dEAxAb5IlnshKw87lb8MEj12P66DAoZAIOXmjAi12NujlrCpF/phaiOPBG3TPVTThWoYVCJmBaIstB12LaKXTIiRIWXacBP5yqAcD5K5YyNd9+VVQBTUObtMGQzVmUsOh0Ouzbtw+ZmZmXbiCTITMzE/n5+dd8vSiKyM3NxYkTJ3DTTTd1ey4vLw8hISGIj4/HwoULUVtb2+t92tvbodVquz2IrEkhl2FKQghWPDQWu347FS/OHIURIV5o6zBg7YEy3L9yFyb/IQ/Lt50e0A/KzV2rKxPjglgO6oPEcF/IBKC6q/HWGewtrkNTeyeCvFTmnVDUN6MjfDF+aAA6DSI+3lUsdThkYxYlLDU1NdDr9QgN7T4nIjQ0FBqNptfXNTQ0wMvLC0qlEjNnzsR7772HW2+91fz89OnT8dFHHyE3NxdvvfUWtm/fjhkzZkCv77npcdmyZfD19TU/oqOjLXkbRBYJ8lLh5zcOw9e/uQn//eUE3D8+Gl4qBc7XtuD3W09gwpu5yP6gAF8VVUDXadkWS9N25pksB/WJu1KOESHeAJxne7NpO/Pk+GDIZILE0Tge0yC5f+8uQVuH/U+0pv4blG3N3t7eKCwsRFNTE3Jzc5GTk4Nhw4Zh8uTJAID77rvPfG1ycjJSUlIwfPhw5OXlYerUqVfcb/HixcjJyTH/u1arZdJCNicIAsbE+GNMjD9euj0Rm4s0+HxPKQqK67DtRDW2nahGgKcSd4yJxLzrozEy1Puq9ztd1YTjmka4yQVksRzUZ0mRvjhR2Yiisgbcmuj4Q/a+O8Fx/ANxa2IYovzdceFiK9YdKMN9XQckkvOxaIUlKCgIcrkclZXdj/aurKxEWFjvP3BlMhni4uKQlpaGp556CnfffTeWLVvW6/XDhg1DUFAQTp8+3ePzKpUKPj4+3R5Eg8lDqcDdY6Pw+WMZ+O6pm7Fw8nCEeKtQ16zDP3ecw7Q/fY85y3fi37tL0NhLo65pd9CkuCD4ergNZvgOLcWJJt6er23G2epmKGQCJo0IkjochySXCXg4IxaAsfnWGr1lZJ8sSliUSiXGjh2L3Nxc89cMBgNyc3ORkZHR5/sYDAa0t/d+BsSFCxdQW1uL8HAuk5P9GxbsheemJ+DH52/BPx8eh2mJocZG3dJ6/Pa/Rbj+9W+R83khdp/t3qj7ZVf/ym0cFmeRpMsm3jr6LydTOej62AD4qJm09te910fDQynHicpG5J/pvf+RHJvFJaGcnBw8/PDDGDduHMaPH493330Xzc3NyM7OBgDMnz8fkZGR5hWUZcuWYdy4cRg+fDja29uxefNmfPzxx3j//fcBAE1NTXj55Zdx1113ISwsDGfOnMGzzz6LuLg4ZGVlWfGtEtmWQi7D1FGhmDoqFNWN7fjvgQtYs6cUZ6qbsXZ/GdbuL0NsoAfuGReNtGg/nKg0loO4O8gyieE+kMsE1DS1o1LbjjBfx51bYkpYpiRwWNxA+Lq74a7rovDxrvNYtbMYE+K4WuWMLE5Y5s2bh+rqaixZsgQajQZpaWnYsmWLuRG3pKQEMtmlhZvm5mb88pe/xIULF+Du7o6EhAR88sknmDdvHgBALpfj0KFDWL16Nerr6xEREYFp06bh1VdfhUrFM1XIMQV7q/DoTcOx4MZh2F9Sj8/3lGLToXIUdzXqmtw4IpjlIAsZG2+9cFzTiEMX6hHm65gJX3N7J3afrQPA/hVreGRiLD7edR65xytxvrYZQwI9pQ6JrEwQHX1NFcamW19fXzQ0NLCfhexWc3snviyqwH/2lmJPsXEy53v3j8Gs1AiJI3M8T//nIL7YdwG/viUOOdPipQ6nX74+osGjH+9DdIA7vn9mCgSBO4QG6uFVBdh+sho/nTgUS2YlSh0O9YElv795lhDRIPFUKXDvuGj857EJyH3qZnz8s/GcbttPpsZbRx7Rv61rHP8t8SFMVqzkp5OGAgA+31vaa7M7OS4mLEQSGB7shRtHBPMXVT9dfqaQIy4Si6LI05lt4KYRQRge7Imm9k58se+C1OGQlTFhISKHc6nxVgeNA068PVbRiIqGNri7yXHDsECpw3EagiDgkYnGVZbVPxbDYHC8ZJZ6x4SFiByO2s3YeAs45sTbbV2rKxPjAqF2k0scjXO567pI+KgVKK5tMf93JufAhIWIHFKyA5/cfGk7M8tB1uahVJin3fIUZ+fChIWIHJKjNt5ebNbhQIlxl9iUeCYstjA/YwhkArDjdA1OVjZKHQ5ZCRMWInJI5sZbB5t4u/1kNQwikBDmjQg/d6nDcUpR/h7mgYxcZXEeTFiIyCGNCveBQiagtlmHigbHabw1lYM4LM62TFuc1+6/gIvNOomjIWtgwkJEDkntJseIrhOxHaXxtlNvwPaTXfNXmLDY1PWx/hgd4YP2TgM+3VMidThkBUxYiMhhJUcaJ2M6SuPtgdJ6NLR2wNfdDWnRflKH49QEQUB21xbnj/PPo0NvkDgiGigmLETksJKj/AA4TuOtqRx088hgKOT88Wtrs1LDEeSlREVDG7Ye0UgdDg0Q/8QQkcNKdrCJt9vYvzKoVAo5fpI+BACbb50BExYiclgJYd5QyATUNetQbueNt+X1rTiuaYRMMK6w0OB48IYYuMkF7Dt/EYcu1EsdDg0AExYiclhqNzlGdjXeFtn5LyPT1NUxMf7w91RKHI3rCPFW4/YU44noXGVxbExYiMihXV4WsmcsB0nnp13Nt5sOlaPKAc+eIiMmLETk0JK7Jt7a89bmtg49dp6uBcDptlJIjvLFuCH+6NCL+GTXeanDoX5iwkJEDu3yM4XstfF219latHboEe6rxqhwb6nDcUmmLc7/2l2Ctg69xNFQfzBhISKHlhDuDTe5gIstHSirb5U6nB6ZykGT40MgCILE0bimrNGhiPBVo7ZZh40Hy6UOh/qBCQsROTSV4vLGW/srC4miiO9OsH9Fagq5DA9lxAIwNt/a62oc9Y4JCxE5PHtuvD1T3YTSulYoFTJMjAuUOhyXdv/4aKjdZDhaoUXBuTqpwyELMWEhIodnary1x4TFNN32hmGB8FAqJI7Gtfl5KHHndVEAuMXZETFhISKHZ88Tb00Jy5R4DouzB9kTYgEAXx/VoLSuRdpgyCJMWIjI4cWHGRtv61s6cOGi/TTeats6sLf4IgD2r9iLEaHeuHFEEAwi8FF+sdThkAWYsBCRw1Mp5IgP62q8taOy0A8na9BpEDEs2BNDAj2lDoe6ZE+MBQB8tqcUze2d0gZDfcaEhYicgj023prKQbdwWJxdmTwyBEODPNHY1om1+y9IHQ71ERMWInIKyZF+AOxna7PBIGL7SW5ntkcymYCHM7pOcf6xGAaDffU9Uc+YsBCRU7C3xtuisgbUNOngpVJgXGyA1OHQ/7h7XDS8VQqcrW7G96eqpQ6H+oAJCxE5hZFhXlDKZWhotY/GW1M56MYRQVAq+KPW3nipFLj3+mgAwCpucXYI/FNERE7h8sZbezgIcVvXdNspLAfZrYczYiEIwPcnq3G6qknqcOgamLAQkdNIspPG26rGNnPSNJnzV+xWTKAHMkeFAgA+/PGcxNHQtTBhISKnkWKeeFsvaRx5J4w9ESlRvgjxVksaC12daYvz/+0rQ0NLh7TB0FUxYSEip2FqvD1cppW08Xabeboty0H2LmNYIBLCvNHaoceavSVSh0NXwYSFiJzGyFBvc+NtaZ00jbe6TgN+OFUDgNuZHYEgCOZVltU/nken3iBtQNQrJixE5DSUChkSwrsabyUqC+0trkNTeyeCvJTmFR+yb3PSIuHv4Yay+lZ8e6xS6nCoF0xYiMipSN14a9rOfPPIEMhkgiQxkGXUbnI8kG4cJLdqR7G0wVCv+pWwLF++HLGxsVCr1UhPT0dBQUGv165duxbjxo2Dn58fPD09kZaWho8//rjbNaIoYsmSJQgPD4e7uzsyMzNx6tSp/oRGRC4uxZSwSLS1+bsTnG7riB7KGAKFTEBBcR0O29HxDnSJxQnLmjVrkJOTg6VLl2L//v1ITU1FVlYWqqqqerw+ICAAL7zwAvLz83Ho0CFkZ2cjOzsbW7duNV/z9ttv4y9/+QtWrFiB3bt3w9PTE1lZWWhra+v/OyMil5Rkbrwd/Im352ubcba6GQqZgBtHBg3q96aBCfVR47bkcADABxwkZ5csTljeeecdLFiwANnZ2UhMTMSKFSvg4eGBVatW9Xj95MmTcccdd2DUqFEYPnw4nnjiCaSkpGDHjh0AjKsr7777Ll588UXMmTMHKSkp+Oijj1BeXo5169YN6M0RkesZGeoNpUIGbVsnSupaBvV7m8pB42L94aN2G9TvTQNnar7deLAc1Y3t0gZDV7AoYdHpdNi3bx8yMzMv3UAmQ2ZmJvLz86/5elEUkZubixMnTuCmm24CAJw7dw4ajabbPX19fZGent7rPdvb26HVars9iIgAY+PtKIkm3m7rmr/CcpBjGhPjj7RoP+j0Bvx7N7c42xuLEpaamhro9XqEhoZ2+3poaCg0Gk2vr2toaICXlxeUSiVmzpyJ9957D7feeisAmF9nyT2XLVsGX19f8yM6OtqSt0FETi456lJZaLC06Dqx62wtACYsjsy0yvLJ7vNo79RLGwx1Myi7hLy9vVFYWIg9e/bg9ddfR05ODvLy8vp9v8WLF6OhocH8KC0ttV6wROTwTNuJB3OFZefpWug6DYgOcMfwYK9B+75kXbclhyPUR4XqxnZ8eahC6nDoMhYlLEFBQZDL5ais7L5PvbKyEmFhYb1/E5kMcXFxSEtLw1NPPYW7774by5YtAwDz6yy5p0qlgo+PT7cHEZGJufG2vAEGw+A03pr6V26JD4EgcDuzo3KTyzA/IxaAsflWyonJ1J1FCYtSqcTYsWORm5tr/prBYEBubi4yMjL6fB+DwYD2dmND09ChQxEWFtbtnlqtFrt377bonkREJqbG28a2TpwfhMZbURSRx9OZncb942OgUshQVNaAfecvSh0OdbG4JJSTk4OVK1di9erVOHbsGBYuXIjm5mZkZ2cDAObPn4/Fixebr1+2bBm++eYbnD17FseOHcMf//hHfPzxx3jwwQcBGMciP/nkk3jttdewYcMGFBUVYf78+YiIiMDcuXOt8y6JyKW4yWUYFW5ceR2MAXLHKhpR0dAGtZsMNwwLtPn3I9sK8FRiblokAG5xticKS18wb948VFdXY8mSJdBoNEhLS8OWLVvMTbMlJSWQyS7lQc3NzfjlL3+JCxcuwN3dHQkJCfjkk08wb9488zXPPvssmpub8eijj6K+vh6TJk3Cli1boFbzlFMi6p+USF8cLK3H4bIGzE6NsOn32ta1ujJxeBDUbnKbfi8aHNmTYrFmbym2HNGgvL4VEX7uUofk8gTRCQp0Wq0Wvr6+aGhoYD8LEQEAPt9Timf/7xBuGBaAzx61bXn5rvd/xL7zF/Ha3CQ8eMMQm34vGjz3/30X8s/W4rGbh+P5GQlSh+OULPn9zbOEiMgpmRpvj5Rpbdp4e7FZhwMlxj4H9q84F9MW508LStCq4xZnqTFhISKnNCLUCyqFDI3tnSiubbbZ99l+shoGEUgI80YkywZOZeqoUMQEeKChtQNrD1yQOhyXx4SFiJzSYDXemrYzc3XF+chlAh6eEAsA+JBbnCXHhIWInFaKjSfeduoN2H6S4/id2T3jouCplONUVRN2nK6ROhyXxoSFiJxWko0n3h4orUdDawd83d0wJtrPJt+DpOWjdsM944zHv3CLs7SYsBCR0zKN6D9SbpvG221d5aCbRwZDIeePU2f18IRYCIKx/Heuxnb9UHR1/BNGRE5rRIix8bapvRPnbNB4ax7Hz3KQUxsa5Ikp8cbPePWPxdIGI5F95y9iy+HeDzkeDExYiMhpKeQyJEYYG2+t3cdSXt+K45pGyATjCgs5N9MW5//sLYW2rUPaYAZRVWMbcj4vxF3v/4jFaw+hvkUnWSxMWIjIqaV0lYWKrNzHYppuOybGH/6eSqvem+zPpLggjAjxQrNOj8/3lEodjs116A34xw9nccsftmPt/jIAwK2JoZByoxQTFiJyaubGWyuvsGxjOcilCIKA7IlDAQCr84uhH6RTwKWw41QNZvz5B7z25TE0tXciNcoX6xZNxNt3p0qanFt8lhARkSNJjjJNvG2AwSBCJhMGfM+2Dj12nq4FAEyOZznIVdwxJhJvbz2O0rpW5B6rxLTRYVKHZFUXLrbgtU3HsOWIsVcl0FOJ56Yn4O6xUVb5czNQXGEhIqcWF+wFtZsMzTo9zlpph8eus7Vo7dAjzEeNxHCeX+Yq3JVy3Hd9DADn2uLc1qHHn789hal/3I4tRzSQywQ8MiEW3z09GfdeH20XyQrAhIWInJxCLjMnFdZqvN1mnm4bDEGwjx/mNDjmZwyBXCYg/2wtjlVopQ5nQERRxNYjGmS+sx1/+vYk2jsNuGFYAL789ST8bvZo+Lq7SR1iN0xYiMjppUT5AbDOiH5RFPFdV8OtaasruY4IP3dM7yoFfejAqyxnqpswf1UBfvHxPly42IpwXzX++pMx+HTBDUgIs89VQyYsROT0kqy4U+hMdRNK61qhlMswMS5owPcjx2Pa4vzfwjLUNrVLG4yFmto7sWzzMUx/93v8cKoGSrkMi6YMR+5TN+P2lAi7XjFk0y0ROb1LE28boDeIkA+gJm8aFpc+LACeKv4IdUVjh/gjJcoXhy404NOCEjx+ywipQ7omURSxrrAMyzYfR1WjMcmamhCCl25PRGyQp8TR9Q1XWIjI6Q0P9oS7mxzNOj3O1TQN6F6cbkvGLc6xAICPd51Hh94gbUDXcKS8AfesyMdv1hxEVWM7YgM9sOqRcfjnI9c7TLICMGEhIhdw+cTbgfSxaNs6sLf4IgAmLK5uZnIEgr1VqNS2Y3NRhdTh9Ki+RYcX1xVh1ns7sPf8Rbi7yfFMVjy2/uYm3JIQKnV4FmPCQkQuIdncx9L/nR07TtWg0yBiWLAnhgQ6zt9MyfqUChkeTB8CwP62OOsNIj7ZdR6T/5CHT3aVwCACt6eEI/epm7FoShxUCrnUIfYLC7BE5BLMCUtZfb/vYS4HcXcQAfhJegyWbzuNwtJ6HCi5iDEx/lKHhH3n67Bk/REcKTcm5vGh3vjd7NHIGB4ocWQDx4SFiFyCeeJtubZfjbcGg4i8E+xfoUuCvVWYlRqB/9t/AR/sLJY0YanStuHNr45j7QHjuT/eagWeunUkHrxhCBRy5yimOMe7ICK6huHBXnB3k6NFp8fZassbb4vKGlDTpIOXSoFxsQE2iJAckan5dnNRBTQNbYP+/XWdBqz8/ixu+eN2rD1QBkEA5o2LxranJ+ORiUOdJlkBmLAQkYuQywSMHkDjrakcNCkuCEoFf3SSUVKkL8YPDUCnQcTHu4oH9Xv/cKoaM/78PV7f3HVIYbQf1v1yIt66OwVBXqpBjWUw8E8dEbkMU1moPwnLNpaDqBc/7Vpl+ffuErR16G3+/UrrWvDYx/vw0D8LcKa6GYGeSrx9dwr+u3ACUqP9bP79pcIeFiJyGcn9nHhb1diGQ12vmZzA05mpu1sTwxDp546y+lasLyzDvK4DEq2trUOPFdvP4P28M2jvNEAuEzA/YwiezBxpd+f+2AJXWIjIZVyaeGtsvO2rvBPV5teHeKttEhs5LrlMwMMTLm1xFsW+/7/VF6IoYsth4yGF7357ynxI4eZf34ils+zvkEJbYcJCRC5jWLAXPJRytHboccaCxttLpzOzHEQ9mzcuBu5uchzXNCL/bK3V7nu6ynhI4WOfXHlIYXyYt9W+jyNgwkJELqNb420fy0K6TgN+OFUDgP0r1DtfDzfcNTYSALBqR/GA79fY1oE3/ueQwsenxDnEIYW2woSFiFxKcqQfgL433u4trkNTeyeCvJRI6SopEfXkkQlDAQC5xytxvra5X/cQRRH/PXABt/xxO/7+/Vl0GkRMTQjB17+5CU9nxcND6bqtp677zonIJSVHWba12bSd+eaRIZAN4JRncn5xIV64eWQwtp+sxuofz2PJrESLXn+4rAG/23AEe88bz6uKDfTA0lmjWYrswoSFiFyKqfH2aLkWnXrDNQdrfcftzGSB7Imx2H6yGv/ZW4qcaSPhpbr2r9mLzTr84esT+LTAeO6Pu5scv5oah59NGuqw5/7YAhMWInIpQ4O84KmUo1mnx5nq5qs2Lp6vbcbZ6mYoZAJuHBk0iFGSo7ppRDCGBXvibHUzvthbikcmDu31Wr1BxKcFJfjD1ydQ39IBAJiVGoHf3paAcF/3wQrZYbCHhYhcirHxtm8D5Ey7g8bF+sNH7RpbR2lgZDIB2RNiAQCr88/D0Mv2+b3FdZj91x14cd1h1Ld0ICHMG58uuAHv3T+GyUovmLAQkcsxT7y9UH/V677rmr/CchBZ4s7rouCtVuBcTTPyTlZ1e65K24bfrCnE3SvycaRcCx+1Ar+blYhNv5rkFCcq2xJLQkTkcswTb6+ywtKi68SurnkaU+KZsFDfeaoUuO/6aKz84RxW7SjGLQmh0HUa8OGP5/Dnb0+hWac3H1L4TFY8Ap3w3B9b6NcKy/LlyxEbGwu1Wo309HQUFBT0eu3KlStx4403wt/fH/7+/sjMzLzi+kceeQSCIHR7TJ8+vT+hERFdU5Kp8bbC2Hjbk52na6HrNCDK3x1xIV6DGR45gfkZsZAJwI7TNfh413lM//P3eGPzcTTr9OZDCt+8K4XJigUsTljWrFmDnJwcLF26FPv370dqaiqysrJQVVXV4/V5eXm4//77sW3bNuTn5yM6OhrTpk1DWVlZt+umT5+OiooK8+PTTz/t3zsiIrqGYUGe8FTK0dZhwOleJt6atjPfkhDikkO6aGCiAzwwLTEMAPDSusM4W92MIC/XOKTQVixOWN555x0sWLAA2dnZSExMxIoVK+Dh4YFVq1b1eP2//vUv/PKXv0RaWhoSEhLwj3/8AwaDAbm5ud2uU6lUCAsLMz/8/f37946IiK5BJhMw+ioHIYqiiLwTHMdPA/PzG4dCEIyN3j+dOBS5T03GveOiOc+nnyxKWHQ6Hfbt24fMzMxLN5DJkJmZifz8/D7do6WlBR0dHQgICOj29by8PISEhCA+Ph4LFy5EbW3vZzG0t7dDq9V2exARWSLlKn0sxyoaUdHQBrWbDBnD2AhJ/TMuNgBrF05Abs7NWDIr0WUOKbQVixKWmpoa6PV6hIaGdvt6aGgoNBpNn+7x3HPPISIiolvSM336dHz00UfIzc3FW2+9he3bt2PGjBnQ6/U93mPZsmXw9fU1P6Kjoy15G0REl3YK9ZCwbOtaXZk4PAhqNw7uov4bE+OP2CBPqcNwCoO6S+jNN9/EZ599hry8PKjVl45ov++++8z/nJycjJSUFAwfPhx5eXmYOnXqFfdZvHgxcnJyzP+u1WqZtBCRRa428fY7ns5MZHcsWmEJCgqCXC5HZWVlt69XVlYiLCzsqq/9wx/+gDfffBNff/01UlJSrnrtsGHDEBQUhNOnT/f4vEqlgo+PT7cHEZElYgM94aVSoL3TgFNVlxpvLzbrcKDEeJYLExYi+2FRwqJUKjF27NhuDbOmBtqMjIxeX/f222/j1VdfxZYtWzBu3Lhrfp8LFy6gtrYW4eHhloRHRNRnMpmA0RFXHoS4/WQ1DCKQEOaNSD9OHCWyFxbvEsrJycHKlSuxevVqHDt2DAsXLkRzczOys7MBAPPnz8fixYvN17/11lt46aWXsGrVKsTGxkKj0UCj0aCpyfg3mqamJjzzzDPYtWsXiouLkZubizlz5iAuLg5ZWVlWeptERFdKibpypxDLQUT2yeIelnnz5qG6uhpLliyBRqNBWloatmzZYm7ELSkpgUx2KQ96//33odPpcPfdd3e7z9KlS/G73/0Ocrkchw4dwurVq1FfX4+IiAhMmzYNr776KlQqDtQhIttJ+p+dQnqDiO0nOY6fyB4Joij2fDKTA9FqtfD19UVDQwP7WYioz87VNGPKH/KgUshw+OUsHCytx90r8uHr7oZ9L2Z2a8QlIuuz5Pc3/zQSkcsaEuABb1PjbWWTuRx008hgJitEdoZ/IonIZRkn3hr/Vne4rOGycfzBUoZFRD1gwkJELi0lyg8A8PVRDY5rGiEIwM0j2b9CZG+YsBCRSzM13n57zLi6MibaDwGeSilDIqIeMGEhIpdmOlPIhLuDiOwTExYicmlDAj3grb404YHzV4jsExMWInJpgiAgKcK4yhLmo0ZiOEcjENkjJixE5PLGxfoDADITQyAIgsTREFFPBvW0ZiIie/TYzcMR7K3C3DGRUodCRL1gwkJELs9TpcD8jFipwyCiq2BJiIiIiOweExYiIiKye0xYiIiIyO4xYSEiIiK7x4SFiIiI7B4TFiIiIrJ7TFiIiIjI7jFhISIiIrvHhIWIiIjsHhMWIiIisntMWIiIiMjuMWEhIiIiu8eEhYiIiOyeU5zWLIoiAECr1UocCREREfWV6fe26ff41ThFwtLY2AgAiI6OljgSIiIislRjYyN8fX2veo0g9iWtsXMGgwHl5eXw9vaGIAhWvbdWq0V0dDRKS0vh4+Nj1XuT5fh52Bd+HvaHn4l94edxdaIoorGxEREREZDJrt6l4hQrLDKZDFFRUTb9Hj4+PvyfzY7w87Av/DzsDz8T+8LPo3fXWlkxYdMtERER2T0mLERERGT3mLBcg0qlwtKlS6FSqaQOhcDPw97w87A//EzsCz8P63GKplsiIiJyblxhISIiIrvHhIWIiIjsHhMWIiIisntMWIiIiMjuMWG5huXLlyM2NhZqtRrp6ekoKCiQOiSns2zZMlx//fXw9vZGSEgI5s6dixMnTnS7pq2tDYsWLUJgYCC8vLxw1113obKysts1JSUlmDlzJjw8PBASEoJnnnkGnZ2dg/lWnNKbb74JQRDw5JNPmr/Gz2NwlZWV4cEHH0RgYCDc3d2RnJyMvXv3mp8XRRFLlixBeHg43N3dkZmZiVOnTnW7R11dHR544AH4+PjAz88PP/vZz9DU1DTYb8Up6PV6vPTSSxg6dCjc3d0xfPhwvPrqq93Ow+FnYgMi9eqzzz4TlUqluGrVKvHIkSPiggULRD8/P7GyslLq0JxKVlaW+MEHH4iHDx8WCwsLxdtuu02MiYkRm5qazNc89thjYnR0tJibmyvu3btXvOGGG8QJEyaYn+/s7BSTkpLEzMxM8cCBA+LmzZvFoKAgcfHixVK8JadRUFAgxsbGiikpKeITTzxh/jo/j8FTV1cnDhkyRHzkkUfE3bt3i2fPnhW3bt0qnj592nzNm2++Kfr6+orr1q0TDx48KM6ePVscOnSo2Nraar5m+vTpYmpqqrhr1y7xhx9+EOPi4sT7779firfk8F5//XUxMDBQ3LRpk3ju3DnxP//5j+jl5SX++c9/Nl/Dz8T6mLBcxfjx48VFixaZ/12v14sRERHismXLJIzK+VVVVYkAxO3bt4uiKIr19fWim5ub+J///Md8zbFjx0QAYn5+viiKorh582ZRJpOJGo3GfM37778v+vj4iO3t7YP7BpxEY2OjOGLECPGbb74Rb775ZnPCws9jcD333HPipEmTen3eYDCIYWFh4u9//3vz1+rr60WVSiV++umnoiiK4tGjR0UA4p49e8zXfPXVV6IgCGJZWZntgndSM2fOFH/60592+9qdd94pPvDAA6Io8jOxFZaEeqHT6bBv3z5kZmaavyaTyZCZmYn8/HwJI3N+DQ0NAICAgAAAwL59+9DR0dHts0hISEBMTIz5s8jPz0dycjJCQ0PN12RlZUGr1eLIkSODGL3zWLRoEWbOnNntvzvAz2OwbdiwAePGjcM999yDkJAQjBkzBitXrjQ/f+7cOWg0mm6fh6+vL9LT07t9Hn5+fhg3bpz5mszMTMhkMuzevXvw3oyTmDBhAnJzc3Hy5EkAwMGDB7Fjxw7MmDEDAD8TW3GKww9toaamBnq9vtsPXAAIDQ3F8ePHJYrK+RkMBjz55JOYOHEikpKSAAAajQZKpRJ+fn7drg0NDYVGozFf09NnZXqOLPPZZ59h//792LNnzxXP8fMYXGfPnsX777+PnJwc/Pa3v8WePXvw61//GkqlEg8//LD5v2dP/70v/zxCQkK6Pa9QKBAQEMDPox+ef/55aLVaJCQkQC6XQ6/X4/XXX8cDDzwAAPxMbIQJC9mVRYsW4fDhw9ixY4fUobis0tJSPPHEE/jmm2+gVqulDsflGQwGjBs3Dm+88QYAYMyYMTh8+DBWrFiBhx9+WOLoXNPnn3+Of/3rX/j3v/+N0aNHo7CwEE8++SQiIiL4mdgQS0K9CAoKglwuv2LnQ2VlJcLCwiSKyrk9/vjj2LRpE7Zt24aoqCjz18PCwqDT6VBfX9/t+ss/i7CwsB4/K9Nz1Hf79u1DVVUVrrvuOigUCigUCmzfvh1/+ctfoFAoEBoays9jEIWHhyMxMbHb10aNGoWSkhIAl/57Xu1nVVhYGKqqqro939nZibq6On4e/fDMM8/g+eefx3333Yfk5GQ89NBD+M1vfoNly5YB4GdiK0xYeqFUKjF27Fjk5uaav2YwGJCbm4uMjAwJI3M+oiji8ccfx3//+1989913GDp0aLfnx44dCzc3t26fxYkTJ1BSUmL+LDIyMlBUVNTtB8A333wDHx+fK37Y09VNnToVRUVFKCwsND/GjRuHBx54wPzP/DwGz8SJE6/Y5n/y5EkMGTIEADB06FCEhYV1+zy0Wi12797d7fOor6/Hvn37zNd89913MBgMSE9PH4R34VxaWlogk3X/9SmXy2EwGADwM7EZqbt+7dlnn30mqlQq8cMPPxSPHj0qPvroo6Kfn1+3nQ80cAsXLhR9fX3FvLw8saKiwvxoaWkxX/PYY4+JMTEx4nfffSfu3btXzMjIEDMyMszPm7bRTps2TSwsLBS3bNkiBgcHcxutlVy+S0gU+XkMpoKCAlGhUIivv/66eOrUKfFf//qX6OHhIX7yySfma958803Rz89PXL9+vXjo0CFxzpw5PW6hHTNmjLh7925xx44d4ogRI7iFtp8efvhhMTIy0rytee3atWJQUJD47LPPmq/hZ2J9TFiu4b333hNjYmJEpVIpjh8/Xty1a5fUITkdAD0+PvjgA/M1ra2t4i9/+UvR399f9PDwEO+44w6xoqKi232Ki4vFGTNmiO7u7mJQUJD41FNPiR0dHYP8bpzT/yYs/DwG18aNG8WkpCRRpVKJCQkJ4t///vduzxsMBvGll14SQ0NDRZVKJU6dOlU8ceJEt2tqa2vF+++/X/Ty8hJ9fHzE7OxssbGxcTDfhtPQarXiE088IcbExIhqtVocNmyY+MILL3Tbss/PxPoEUbxsNB8RERGRHWIPCxEREdk9JixERERk95iwEBERkd1jwkJERER2jwkLERER2T0mLERERGT3mLAQERGR3WPCQkRERHaPCQsRERHZPSYsREREZPeYsBAREZHdY8JCREREdu//A2IqflKnk+yqAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(epoch_list, cost_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
